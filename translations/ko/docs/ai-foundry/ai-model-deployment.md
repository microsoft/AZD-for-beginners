<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6af361e2339c27aa56a9196e11b32cb7",
  "translation_date": "2025-09-17T14:32:01+00:00",
  "source_file": "docs/ai-foundry/ai-model-deployment.md",
  "language_code": "ko"
}
-->
# Azure Developer CLIë¥¼ í™œìš©í•œ AI ëª¨ë¸ ë°°í¬

**ì±•í„° íƒìƒ‰:**
- **ğŸ“š ì½”ìŠ¤ í™ˆ**: [AZD ì´ˆë³´ììš©](../../README.md)
- **ğŸ“– í˜„ì¬ ì±•í„°**: ì±•í„° 2 - AI ìš°ì„  ê°œë°œ
- **â¬…ï¸ ì´ì „**: [Azure AI Foundry í†µí•©](azure-ai-foundry-integration.md)
- **â¡ï¸ ë‹¤ìŒ**: [AI ì›Œí¬ìˆ ì‹¤ìŠµ](ai-workshop-lab.md)
- **ğŸš€ ë‹¤ìŒ ì±•í„°**: [ì±•í„° 3: êµ¬ì„±](../getting-started/configuration.md)

ì´ ê°€ì´ë“œëŠ” AZD í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ AI ëª¨ë¸ì„ ë°°í¬í•˜ëŠ” í¬ê´„ì ì¸ ì§€ì¹¨ì„ ì œê³µí•˜ë©°, ëª¨ë¸ ì„ íƒë¶€í„° í”„ë¡œë•ì…˜ ë°°í¬ íŒ¨í„´ê¹Œì§€ ë‹¤ë£¹ë‹ˆë‹¤.

## ëª©ì°¨

- [ëª¨ë¸ ì„ íƒ ì „ëµ](../../../../docs/ai-foundry)
- [AI ëª¨ë¸ì„ ìœ„í•œ AZD êµ¬ì„±](../../../../docs/ai-foundry)
- [ë°°í¬ íŒ¨í„´](../../../../docs/ai-foundry)
- [ëª¨ë¸ ê´€ë¦¬](../../../../docs/ai-foundry)
- [í”„ë¡œë•ì…˜ ê³ ë ¤ì‚¬í•­](../../../../docs/ai-foundry)
- [ëª¨ë‹ˆí„°ë§ ë° ê´€ì°°ì„±](../../../../docs/ai-foundry)

## ëª¨ë¸ ì„ íƒ ì „ëµ

### Azure OpenAI ëª¨ë¸

ì‚¬ìš© ì‚¬ë¡€ì— ì í•©í•œ ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”:

```yaml
# azure.yaml - Model configuration
services:
  ai-service:
    project: ./infra
    host: containerapp
    config:
      AZURE_OPENAI_MODELS: |
        [
          {
            "name": "gpt-4o-mini",
            "version": "2024-07-18",
            "deployment": "gpt-4o-mini",
            "capacity": 10,
            "format": "OpenAI"
          },
          {
            "name": "text-embedding-ada-002",
            "version": "2",
            "deployment": "text-embedding-ada-002", 
            "capacity": 30,
            "format": "OpenAI"
          }
        ]
```

### ëª¨ë¸ ìš©ëŸ‰ ê³„íš

| ëª¨ë¸ ìœ í˜• | ì‚¬ìš© ì‚¬ë¡€ | ê¶Œì¥ ìš©ëŸ‰ | ë¹„ìš© ê³ ë ¤ì‚¬í•­ |
|------------|----------|---------------------|-------------------|
| GPT-4o-mini | ì±„íŒ…, Q&A | 10-50 TPM | ëŒ€ë¶€ë¶„ì˜ ì›Œí¬ë¡œë“œì— ë¹„ìš© íš¨ìœ¨ì  |
| GPT-4 | ë³µì¡í•œ ì¶”ë¡  | 20-100 TPM | ë†’ì€ ë¹„ìš©, í”„ë¦¬ë¯¸ì—„ ê¸°ëŠ¥ì— ì‚¬ìš© |
| Text-embedding-ada-002 | ê²€ìƒ‰, RAG | 30-120 TPM | ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ì— í•„ìˆ˜ì  |
| Whisper | ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ | 10-50 TPM | ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì›Œí¬ë¡œë“œ |

## AI ëª¨ë¸ì„ ìœ„í•œ AZD êµ¬ì„±

### Bicep í…œí”Œë¦¿ êµ¬ì„±

Bicep í…œí”Œë¦¿ì„ í†µí•´ ëª¨ë¸ ë°°í¬ë¥¼ ìƒì„±í•˜ì„¸ìš”:

```bicep
// infra/main.bicep
@description('OpenAI model deployments')
param openAiModelDeployments array = [
  {
    name: 'gpt-4o-mini'
    model: {
      format: 'OpenAI'
      name: 'gpt-4o-mini'
      version: '2024-07-18'
    }
    sku: {
      name: 'Standard'
      capacity: 10
    }
  }
  {
    name: 'text-embedding-ada-002'
    model: {
      format: 'OpenAI'
      name: 'text-embedding-ada-002'
      version: '2'
    }
    sku: {
      name: 'Standard'
      capacity: 30
    }
  }
]

resource openAi 'Microsoft.CognitiveServices/accounts@2023-05-01' = {
  name: openAiAccountName
  location: location
  kind: 'OpenAI'
  properties: {
    customSubDomainName: openAiAccountName
    networkAcls: {
      defaultAction: 'Allow'
    }
    publicNetworkAccess: 'Enabled'
  }
  sku: {
    name: 'S0'
  }
}

@batchSize(1)
resource deployment 'Microsoft.CognitiveServices/accounts/deployments@2023-05-01' = [for deployment in openAiModelDeployments: {
  parent: openAi
  name: deployment.name
  properties: {
    model: deployment.model
  }
  sku: deployment.sku
}]
```

### í™˜ê²½ ë³€ìˆ˜

ì• í”Œë¦¬ì¼€ì´ì…˜ í™˜ê²½ì„ êµ¬ì„±í•˜ì„¸ìš”:

```bash
# .env configuration
AZURE_OPENAI_ENDPOINT=https://your-openai-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-02-15-preview
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o-mini
AZURE_OPENAI_EMBED_DEPLOYMENT=text-embedding-ada-002
```

## ë°°í¬ íŒ¨í„´

### íŒ¨í„´ 1: ë‹¨ì¼ ì§€ì—­ ë°°í¬

```yaml
# azure.yaml - Single region
services:
  ai-app:
    project: ./src
    host: containerapp
    config:
      AZURE_OPENAI_ENDPOINT: ${AZURE_OPENAI_ENDPOINT}
      AZURE_OPENAI_CHAT_DEPLOYMENT: gpt-4o-mini
```

ì í•©í•œ ê²½ìš°:
- ê°œë°œ ë° í…ŒìŠ¤íŠ¸
- ë‹¨ì¼ ì‹œì¥ ì• í”Œë¦¬ì¼€ì´ì…˜
- ë¹„ìš© ìµœì í™”

### íŒ¨í„´ 2: ë‹¤ì¤‘ ì§€ì—­ ë°°í¬

```bicep
// Multi-region deployment
param regions array = ['eastus2', 'westus2', 'francecentral']

resource openAiMultiRegion 'Microsoft.CognitiveServices/accounts@2023-05-01' = [for region in regions: {
  name: '${openAiAccountName}-${region}'
  location: region
  // ... configuration
}]
```

ì í•©í•œ ê²½ìš°:
- ê¸€ë¡œë²Œ ì• í”Œë¦¬ì¼€ì´ì…˜
- ë†’ì€ ê°€ìš©ì„± ìš”êµ¬ì‚¬í•­
- ë¶€í•˜ ë¶„ì‚°

### íŒ¨í„´ 3: í•˜ì´ë¸Œë¦¬ë“œ ë°°í¬

Azure OpenAIì™€ ë‹¤ë¥¸ AI ì„œë¹„ìŠ¤ë¥¼ ê²°í•©í•˜ì„¸ìš”:

```bicep
// Hybrid AI services
resource cognitiveServices 'Microsoft.CognitiveServices/accounts@2023-05-01' = {
  name: cognitiveServicesName
  location: location
  kind: 'CognitiveServices'
  properties: {
    customSubDomainName: cognitiveServicesName
  }
  sku: {
    name: 'S0'
  }
}

resource documentIntelligence 'Microsoft.CognitiveServices/accounts@2023-05-01' = {
  name: documentIntelligenceName
  location: location
  kind: 'FormRecognizer'
  properties: {
    customSubDomainName: documentIntelligenceName
  }
  sku: {
    name: 'S0'
  }
}
```

## ëª¨ë¸ ê´€ë¦¬

### ë²„ì „ ê´€ë¦¬

AZD êµ¬ì„±ì—ì„œ ëª¨ë¸ ë²„ì „ì„ ì¶”ì í•˜ì„¸ìš”:

```json
{
  "models": {
    "chat": {
      "name": "gpt-4o-mini",
      "version": "2024-07-18",
      "fallback": "gpt-35-turbo"
    },
    "embedding": {
      "name": "text-embedding-ada-002",
      "version": "2"
    }
  }
}
```

### ëª¨ë¸ ì—…ë°ì´íŠ¸

AZD í›…ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”:

```bash
#!/bin/bash
# hooks/predeploy.sh

echo "Checking model availability..."
az cognitiveservices account list-models \
  --name $AZURE_OPENAI_ACCOUNT_NAME \
  --resource-group $AZURE_RESOURCE_GROUP \
  --query "[?name=='gpt-4o-mini']"
```

### A/B í…ŒìŠ¤íŠ¸

ì—¬ëŸ¬ ëª¨ë¸ ë²„ì „ì„ ë°°í¬í•˜ì„¸ìš”:

```bicep
param enableABTesting bool = false

resource chatDeployment 'Microsoft.CognitiveServices/accounts/deployments@2023-05-01' = {
  parent: openAi
  name: 'gpt-4o-mini-${enableABTesting ? 'v1' : 'prod'}'
  properties: {
    model: {
      format: 'OpenAI'
      name: 'gpt-4o-mini'
      version: '2024-07-18'
    }
  }
  sku: {
    name: 'Standard'
    capacity: enableABTesting ? 5 : 10
  }
}
```

## í”„ë¡œë•ì…˜ ê³ ë ¤ì‚¬í•­

### ìš©ëŸ‰ ê³„íš

ì‚¬ìš© íŒ¨í„´ì— ë”°ë¼ í•„ìš”í•œ ìš©ëŸ‰ì„ ê³„ì‚°í•˜ì„¸ìš”:

```python
# Capacity calculation example
def calculate_required_capacity(
    requests_per_minute: int,
    avg_prompt_tokens: int,
    avg_completion_tokens: int,
    safety_margin: float = 0.2
) -> int:
    """Calculate required TPM capacity."""
    total_tokens_per_request = avg_prompt_tokens + avg_completion_tokens
    total_tpm = requests_per_minute * total_tokens_per_request
    return int(total_tpm * (1 + safety_margin))

# Example usage
required_capacity = calculate_required_capacity(
    requests_per_minute=10,
    avg_prompt_tokens=500,
    avg_completion_tokens=200,
    safety_margin=0.3
)
print(f"Required capacity: {required_capacity} TPM")
```

### ìë™ í™•ì¥ êµ¬ì„±

Container Appsì— ëŒ€í•œ ìë™ í™•ì¥ì„ êµ¬ì„±í•˜ì„¸ìš”:

```bicep
resource containerApp 'Microsoft.App/containerApps@2024-03-01' = {
  name: containerAppName
  properties: {
    template: {
      scale: {
        minReplicas: 1
        maxReplicas: 10
        rules: [
          {
            name: 'http-rule'
            http: {
              metadata: {
                concurrentRequests: '10'
              }
            }
          }
          {
            name: 'cpu-rule'
            custom: {
              type: 'cpu'
              metadata: {
                type: 'Utilization'
                value: '70'
              }
            }
          }
        ]
      }
    }
  }
}
```

### ë¹„ìš© ìµœì í™”

ë¹„ìš© í†µì œë¥¼ êµ¬í˜„í•˜ì„¸ìš”:

```bicep
@description('Enable cost management alerts')
param enableCostAlerts bool = true

resource budgetAlert 'Microsoft.Consumption/budgets@2023-05-01' = if (enableCostAlerts) {
  name: 'ai-budget-alert'
  properties: {
    timePeriod: {
      startDate: '2024-01-01'
      endDate: '2024-12-31'
    }
    timeGrain: 'Monthly'
    amount: 1000
    category: 'Cost'
    notifications: {
      Actual_GreaterThan_80_Percent: {
        enabled: true
        operator: 'GreaterThan'
        threshold: 80
        contactEmails: [
          'admin@yourcompany.com'
        ]
      }
    }
  }
}
```

## ëª¨ë‹ˆí„°ë§ ë° ê´€ì°°ì„±

### Application Insights í†µí•©

AI ì›Œí¬ë¡œë“œì— ëŒ€í•œ ëª¨ë‹ˆí„°ë§ì„ êµ¬ì„±í•˜ì„¸ìš”:

```bicep
resource applicationInsights 'Microsoft.Insights/components@2020-02-02' = {
  name: applicationInsightsName
  location: location
  kind: 'web'
  properties: {
    Application_Type: 'web'
    WorkspaceResourceId: logAnalyticsWorkspace.id
  }
}

// Custom metrics for AI models
resource aiMetrics 'Microsoft.Insights/components/analyticsItems@2020-02-02' = {
  parent: applicationInsights
  name: 'ai-model-metrics'
  properties: {
    content: '''
      customEvents
      | where name == "AI_Model_Request"
      | extend model = tostring(customDimensions.model)
      | extend tokens = toint(customDimensions.tokens)
      | extend latency = toint(customDimensions.latency_ms)
      | summarize 
          requests = count(),
          avg_tokens = avg(tokens),
          avg_latency = avg(latency)
        by model, bin(timestamp, 5m)
    '''
    type: 'query'
    scope: 'shared'
  }
}
```

### ì‚¬ìš©ì ì •ì˜ ë©”íŠ¸ë¦­

AI íŠ¹í™” ë©”íŠ¸ë¦­ì„ ì¶”ì í•˜ì„¸ìš”:

```python
# Custom telemetry for AI models
import logging
from applicationinsights import TelemetryClient

class AITelemetry:
    def __init__(self, instrumentation_key: str):
        self.client = TelemetryClient(instrumentation_key)
    
    def track_model_request(self, model: str, tokens: int, latency_ms: int, success: bool):
        """Track AI model request metrics."""
        self.client.track_event(
            'AI_Model_Request',
            {
                'model': model,
                'tokens': str(tokens),
                'latency_ms': str(latency_ms),
                'success': str(success)
            }
        )
        
    def track_model_error(self, model: str, error_type: str, error_message: str):
        """Track AI model errors."""
        self.client.track_exception(
            type=error_type,
            value=error_message,
            properties={
                'model': model,
                'component': 'ai_model'
            }
        )
```

### ìƒíƒœ í™•ì¸

AI ì„œë¹„ìŠ¤ ìƒíƒœ ëª¨ë‹ˆí„°ë§ì„ êµ¬í˜„í•˜ì„¸ìš”:

```python
# Health check endpoints
from fastapi import FastAPI, HTTPException
import httpx

app = FastAPI()

@app.get("/health/ai-models")
async def check_ai_models():
    """Check AI model availability."""
    try:
        # Test OpenAI connection
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"{AZURE_OPENAI_ENDPOINT}/openai/deployments",
                headers={"api-key": AZURE_OPENAI_API_KEY}
            )
            
        if response.status_code == 200:
            return {"status": "healthy", "models": response.json()}
        else:
            raise HTTPException(status_code=503, detail="AI models unavailable")
            
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"Health check failed: {str(e)}")
```

## ë‹¤ìŒ ë‹¨ê³„

1. **[Azure AI Foundry í†µí•© ê°€ì´ë“œ](azure-ai-foundry-integration.md)**ë¥¼ ê²€í† í•˜ì—¬ ì„œë¹„ìŠ¤ í†µí•© íŒ¨í„´ì„ í™•ì¸í•˜ì„¸ìš”
2. **[AI ì›Œí¬ìˆ ì‹¤ìŠµ](ai-workshop-lab.md)**ì„ ì™„ë£Œí•˜ì—¬ ì‹¤ìŠµ ê²½í—˜ì„ ìŒ“ìœ¼ì„¸ìš”
3. **[í”„ë¡œë•ì…˜ AI ì‹¤ë¬´](production-ai-practices.md)**ë¥¼ êµ¬í˜„í•˜ì—¬ ì—”í„°í”„ë¼ì´ì¦ˆ ë°°í¬ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”
4. **[AI ë¬¸ì œ í•´ê²° ê°€ì´ë“œ](../troubleshooting/ai-troubleshooting.md)**ë¥¼ íƒìƒ‰í•˜ì—¬ ì¼ë°˜ì ì¸ ë¬¸ì œë¥¼ í•´ê²°í•˜ì„¸ìš”

## ë¦¬ì†ŒìŠ¤

- [Azure OpenAI ëª¨ë¸ ê°€ìš©ì„±](https://learn.microsoft.com/azure/ai-services/openai/concepts/models)
- [Azure Developer CLI ë¬¸ì„œ](https://learn.microsoft.com/azure/developer/azure-developer-cli/)
- [Container Apps í™•ì¥](https://learn.microsoft.com/azure/container-apps/scale-app)
- [AI ëª¨ë¸ ë¹„ìš© ìµœì í™”](https://learn.microsoft.com/azure/ai-services/openai/how-to/manage-costs)

---

**ì±•í„° íƒìƒ‰:**
- **ğŸ“š ì½”ìŠ¤ í™ˆ**: [AZD ì´ˆë³´ììš©](../../README.md)
- **ğŸ“– í˜„ì¬ ì±•í„°**: ì±•í„° 2 - AI ìš°ì„  ê°œë°œ
- **â¬…ï¸ ì´ì „**: [Azure AI Foundry í†µí•©](azure-ai-foundry-integration.md)
- **â¡ï¸ ë‹¤ìŒ**: [AI ì›Œí¬ìˆ ì‹¤ìŠµ](ai-workshop-lab.md)
- **ğŸš€ ë‹¤ìŒ ì±•í„°**: [ì±•í„° 3: êµ¬ì„±](../getting-started/configuration.md)

---

**ë©´ì±… ì¡°í•­**:  
ì´ ë¬¸ì„œëŠ” AI ë²ˆì—­ ì„œë¹„ìŠ¤ [Co-op Translator](https://github.com/Azure/co-op-translator)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë²ˆì—­ë˜ì—ˆìŠµë‹ˆë‹¤. ì •í™•ì„±ì„ ìœ„í•´ ìµœì„ ì„ ë‹¤í•˜ê³  ìˆìœ¼ë‚˜, ìë™ ë²ˆì—­ì—ëŠ” ì˜¤ë¥˜ë‚˜ ë¶€ì •í™•ì„±ì´ í¬í•¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì›ë³¸ ë¬¸ì„œì˜ ì›ì–´ ë²„ì „ì„ ê¶Œìœ„ ìˆëŠ” ì¶œì²˜ë¡œ ê°„ì£¼í•´ì•¼ í•©ë‹ˆë‹¤. ì¤‘ìš”í•œ ì •ë³´ì˜ ê²½ìš°, ì „ë¬¸ì ì¸ ì¸ê°„ ë²ˆì—­ì„ ê¶Œì¥í•©ë‹ˆë‹¤. ì´ ë²ˆì—­ ì‚¬ìš©ìœ¼ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ì˜¤í•´ë‚˜ ì˜ëª»ëœ í•´ì„ì— ëŒ€í•´ ì±…ì„ì„ ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤.