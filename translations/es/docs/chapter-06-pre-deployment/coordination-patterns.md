# Patrones de Coordinaci√≥n Multi-Agente

‚è±Ô∏è **Tiempo estimado**: 60-75 minutos | üí∞ **Costo estimado**: ~$100-300/mes | ‚≠ê **Complejidad**: Avanzado

**üìö Ruta de aprendizaje:**
- ‚Üê Anterior: [Planificaci√≥n de Capacidad](capacity-planning.md) - Dimensionamiento de recursos y estrategias de escalado
- üéØ **Est√°s aqu√≠**: Patrones de Coordinaci√≥n Multi-Agente (Orquestaci√≥n, comunicaci√≥n, gesti√≥n de estado)
- ‚Üí Siguiente: [Selecci√≥n de SKU](sku-selection.md) - Elegir los servicios de Azure adecuados
- üè† [Inicio del curso](../../README.md)

---

## Qu√© aprender√°s

Al completar esta lecci√≥n, t√∫:
- Entender√°s los **patrones de arquitectura multi-agente** y cu√°ndo usarlos
- Implementar√°s **patrones de orquestaci√≥n** (centralizada, descentralizada, jer√°rquica)
- Dise√±ar√°s **estrategias de comunicaci√≥n entre agentes** (s√≠ncrona, as√≠ncrona, orientada a eventos)
- Gestionar√°s el **estado compartido** entre agentes distribuidos
- Desplegar√°s **sistemas multi-agente** en Azure con AZD
- Aplicar√°s **patrones de coordinaci√≥n** para escenarios reales de IA
- Monitorear√°s y depurar√°s sistemas de agentes distribuidos

## Por qu√© importa la coordinaci√≥n multi-agente

### La evoluci√≥n: de un solo agente a multi-agente

**Agente √∫nico (Simple):**
```
User ‚Üí Agent ‚Üí Response
```
- ‚úÖ F√°cil de entender e implementar
- ‚úÖ R√°pido para tareas simples
- ‚ùå Limitado por las capacidades de un solo modelo
- ‚ùå No puede paralelizar tareas complejas
- ‚ùå Sin especializaci√≥n

**Sistema multi-agente (Avanzado):**
```
           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ Orchestrator‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ         ‚îÇ         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇAgent1‚îÇ  ‚îÇAgent2‚îÇ  ‚îÇAgent3 ‚îÇ
    ‚îÇ(Plan)‚îÇ  ‚îÇ(Code)‚îÇ  ‚îÇ(Review)‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```
- ‚úÖ Agentes especializados para tareas espec√≠ficas
- ‚úÖ Ejecuci√≥n en paralelo para mayor velocidad
- ‚úÖ Modular y mantenible
- ‚úÖ Mejor para flujos de trabajo complejos
- ‚ö†Ô∏è Requiere l√≥gica de coordinaci√≥n

**Analog√≠a**: Un agente √∫nico es como una persona que hace todas las tareas. Multi-agente es como un equipo donde cada miembro tiene habilidades especializadas (investigador, programador, revisor, redactor) trabajando juntos.

---

## Patrones centrales de coordinaci√≥n

### Patr√≥n 1: Coordinaci√≥n secuencial (Cadena de responsabilidad)

**Cu√°ndo usar**: Las tareas deben completarse en un orden espec√≠fico, cada agente se basa en la salida anterior.

```mermaid
sequenceDiagram
    participant User as Usuario
    participant Orchestrator as Orquestador
    participant Agent1 as Agente de Investigaci√≥n
    participant Agent2 as Agente Escritor
    participant Agent3 as Agente Editor
    
    User->>Orchestrator: "Escribe un art√≠culo sobre IA"
    Orchestrator->>Agent1: Investigar tema
    Agent1-->>Orchestrator: Resultados de la investigaci√≥n
    Orchestrator->>Agent2: Escribir borrador (usando la investigaci√≥n)
    Agent2-->>Orchestrator: Borrador del art√≠culo
    Orchestrator->>Agent3: Editar y mejorar
    Agent3-->>Orchestrator: Art√≠culo final
    Orchestrator-->>User: Art√≠culo pulido
    
    Note over User,Agent3: Secuencial: Cada paso espera al anterior
```
**Beneficios:**
- ‚úÖ Flujo de datos claro
- ‚úÖ F√°cil de depurar
- ‚úÖ Orden de ejecuci√≥n predecible

**Limitaciones:**
- ‚ùå M√°s lento (sin paralelismo)
- ‚ùå Una falla bloquea toda la cadena
- ‚ùå No puede manejar tareas interdependientes

**Casos de uso de ejemplo:**
- Canal de creaci√≥n de contenido (investigaci√≥n ‚Üí escribir ‚Üí editar ‚Üí publicar)
- Generaci√≥n de c√≥digo (plan ‚Üí implementar ‚Üí probar ‚Üí desplegar)
- Generaci√≥n de informes (recolecci√≥n de datos ‚Üí an√°lisis ‚Üí visualizaci√≥n ‚Üí resumen)

---

### Patr√≥n 2: Coordinaci√≥n en paralelo (Fan-Out/Fan-In)

**Cu√°ndo usar**: Tareas independientes pueden ejecutarse simult√°neamente, los resultados se combinan al final.

```mermaid
graph TB
    User[Solicitud de Usuario]
    Orchestrator[Orquestador]
    Agent1[Agente de An√°lisis]
    Agent2[Agente de Investigaci√≥n]
    Agent3[Agente de Datos]
    Aggregator[Agregador de Resultados]
    Response[Respuesta Combinada]
    
    User --> Orchestrator
    Orchestrator --> Agent1
    Orchestrator --> Agent2
    Orchestrator --> Agent3
    Agent1 --> Aggregator
    Agent2 --> Aggregator
    Agent3 --> Aggregator
    Aggregator --> Response
    
    style Orchestrator fill:#2196F3,stroke:#1976D2,stroke-width:3px,color:#fff
    style Aggregator fill:#4CAF50,stroke:#388E3C,stroke-width:3px,color:#fff
```
**Beneficios:**
- ‚úÖ R√°pido (ejecuci√≥n en paralelo)
- ‚úÖ Tolerante a fallos (resultados parciales aceptables)
- ‚úÖ Escala horizontalmente

**Limitaciones:**
- ‚ö†Ô∏è Los resultados pueden llegar fuera de orden
- ‚ö†Ô∏è Se necesita l√≥gica de agregaci√≥n
- ‚ö†Ô∏è Gesti√≥n de estado compleja

**Casos de uso de ejemplo:**
- Recolecci√≥n de datos desde m√∫ltiples fuentes (APIs + bases de datos + scraping web)
- An√°lisis competitivo (m√∫ltiples modelos generan soluciones, se selecciona la mejor)
- Servicios de traducci√≥n (traducir a m√∫ltiples idiomas simult√°neamente)

---

### Patr√≥n 3: Coordinaci√≥n jer√°rquica (Manager-Worker)

**Cu√°ndo usar**: Flujos de trabajo complejos con sub-tareas, se necesita delegaci√≥n.

```mermaid
graph TB
    Master[Orquestador Maestro]
    Manager1[Gerente de Investigaci√≥n]
    Manager2[Gerente de Contenidos]
    W1[Raspador web]
    W2[Analizador de art√≠culos]
    W3[Redactor]
    W4[Editor]
    
    Master --> Manager1
    Master --> Manager2
    Manager1 --> W1
    Manager1 --> W2
    Manager2 --> W3
    Manager2 --> W4
    
    style Master fill:#FF9800,stroke:#F57C00,stroke-width:3px,color:#fff
    style Manager1 fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff
    style Manager2 fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff
```
**Beneficios:**
- ‚úÖ Maneja flujos de trabajo complejos
- ‚úÖ Modular y mantenible
- ‚úÖ L√≠mites de responsabilidad claros

**Limitaciones:**
- ‚ö†Ô∏è Arquitectura m√°s compleja
- ‚ö†Ô∏è Mayor latencia (m√∫ltiples capas de coordinaci√≥n)
- ‚ö†Ô∏è Requiere orquestaci√≥n sofisticada

**Casos de uso de ejemplo:**
- Procesamiento de documentos empresariales (clasificar ‚Üí enrutar ‚Üí procesar ‚Üí archivar)
- Pipelines de datos multietapa (ingest ‚Üí limpiar ‚Üí transformar ‚Üí analizar ‚Üí reportar)
- Flujos de trabajo de automatizaci√≥n complejos (planificaci√≥n ‚Üí asignaci√≥n de recursos ‚Üí ejecuci√≥n ‚Üí monitoreo)

---

### Patr√≥n 4: Coordinaci√≥n basada en eventos (Publicar-Suscribir)

**Cu√°ndo usar**: Los agentes necesitan reaccionar a eventos, se desea acoplamiento d√©bil.

```mermaid
sequenceDiagram
    participant Agent1 as Recolector de datos
    participant EventBus as Bus de servicios de Azure
    participant Agent2 as Analizador
    participant Agent3 as Notificador
    participant Agent4 as Archivador
    
    Agent1->>EventBus: Publicar "DatosRecibidos" evento
    EventBus->>Agent2: Suscribir: Analizar datos
    EventBus->>Agent3: Suscribir: Enviar notificaci√≥n
    EventBus->>Agent4: Suscribir: Archivar datos
    
    Note over Agent1,Agent4: Todos los suscriptores procesan de forma independiente
    
    Agent2->>EventBus: Publicar "An√°lisisCompleto" evento
    EventBus->>Agent3: Suscribir: Enviar informe de an√°lisis
```
**Beneficios:**
- ‚úÖ Acoplamiento d√©bil entre agentes
- ‚úÖ F√°cil a√±adir nuevos agentes (solo suscribirse)
- ‚úÖ Procesamiento as√≠ncrono
- ‚úÖ Resiliente (persistencia de mensajes)

**Limitaciones:**
- ‚ö†Ô∏è Consistencia eventual
- ‚ö†Ô∏è Depuraci√≥n compleja
- ‚ö†Ô∏è Desaf√≠os de ordenamiento de mensajes

**Casos de uso de ejemplo:**
- Sistemas de monitoreo en tiempo real (alertas, dashboards, logs)
- Notificaciones multicanal (email, SMS, push, Slack)
- Pipelines de procesamiento de datos (m√∫ltiples consumidores de los mismos datos)

---

### Patr√≥n 5: Coordinaci√≥n basada en consenso (Votaci√≥n/Quorum)

**Cu√°ndo usar**: Se necesita acuerdo de m√∫ltiples agentes antes de proceder.

```mermaid
graph TB
    Input[Tarea de entrada]
    Agent1[Agente 1: GPT-4]
    Agent2[Agente 2: Claude]
    Agent3[Agente 3: Gemini]
    Voter[Votante de consenso]
    Output[Salida acordada]
    
    Input --> Agent1
    Input --> Agent2
    Input --> Agent3
    Agent1 --> Voter
    Agent2 --> Voter
    Agent3 --> Voter
    Voter --> Output
    
    style Voter fill:#9C27B0,stroke:#7B1FA2,stroke-width:3px,color:#fff
```
**Beneficios:**
- ‚úÖ Mayor precisi√≥n (m√∫ltiples opiniones)
- ‚úÖ Tolerante a fallos (fallas en la minor√≠a aceptables)
- ‚úÖ Aseguramiento de calidad incorporado

**Limitaciones:**
- ‚ùå Costoso (m√∫ltiples llamadas a modelos)
- ‚ùå M√°s lento (esperar a todos los agentes)
- ‚ö†Ô∏è Se necesita resoluci√≥n de conflictos

**Casos de uso de ejemplo:**
- Moderaci√≥n de contenido (m√∫ltiples modelos revisan el contenido)
- Revisi√≥n de c√≥digo (m√∫ltiples linters/analizadores)
- Diagn√≥stico m√©dico (m√∫ltiples modelos de IA, validaci√≥n de expertos)

---

## Resumen arquitect√≥nico

### Sistema multi-agente completo en Azure

```mermaid
graph TB
    User[Usuario/Cliente de API]
    APIM[Azure Administraci√≥n de API]
    Orchestrator[Servicio Orquestador<br/>Aplicaci√≥n de Contenedor]
    ServiceBus[Azure Service Bus<br/>Hub de Eventos]
    
    Agent1[Agente de Investigaci√≥n<br/>Aplicaci√≥n de Contenedor]
    Agent2[Agente Escritor<br/>Aplicaci√≥n de Contenedor]
    Agent3[Agente Analista<br/>Aplicaci√≥n de Contenedor]
    Agent4[Agente Revisor<br/>Aplicaci√≥n de Contenedor]
    
    CosmosDB[(Cosmos DB<br/>Estado Compartido)]
    Storage[Azure Storage<br/>Artefactos]
    AppInsights[Application Insights<br/>Monitorizaci√≥n]
    
    User --> APIM
    APIM --> Orchestrator
    
    Orchestrator --> ServiceBus
    ServiceBus --> Agent1
    ServiceBus --> Agent2
    ServiceBus --> Agent3
    ServiceBus --> Agent4
    
    Agent1 --> CosmosDB
    Agent2 --> CosmosDB
    Agent3 --> CosmosDB
    Agent4 --> CosmosDB
    
    Agent1 --> Storage
    Agent2 --> Storage
    Agent3 --> Storage
    Agent4 --> Storage
    
    Orchestrator -.-> AppInsights
    Agent1 -.-> AppInsights
    Agent2 -.-> AppInsights
    Agent3 -.-> AppInsights
    Agent4 -.-> AppInsights
    
    style Orchestrator fill:#FF9800,stroke:#F57C00,stroke-width:3px,color:#fff
    style ServiceBus fill:#9C27B0,stroke:#7B1FA2,stroke-width:3px,color:#fff
    style CosmosDB fill:#4CAF50,stroke:#388E3C,stroke-width:3px,color:#fff
```
**Componentes clave:**

| Component | Purpose | Azure Service |
|-----------|---------|---------------|
| **API Gateway** | Punto de entrada, limitaci√≥n de tasa, autenticaci√≥n | API Management |
| **Orchestrator** | Coordina los flujos de trabajo de los agentes | Container Apps |
| **Message Queue** | Comunicaci√≥n as√≠ncrona | Service Bus / Event Hubs |
| **Agents** | Trabajadores de IA especializados | Container Apps / Functions |
| **State Store** | Estado compartido, seguimiento de tareas | Cosmos DB |
| **Artifact Storage** | Documentos, resultados, logs | Blob Storage |
| **Monitoring** | Trazado distribuido, logs | Application Insights |

---

## Requisitos previos

### Herramientas requeridas

```bash
# Verificar Azure Developer CLI
azd version
# ‚úÖ Esperado: azd versi√≥n 1.0.0 o superior

# Verificar Azure CLI
az --version
# ‚úÖ Esperado: azure-cli 2.50.0 o superior

# Verificar Docker (para pruebas locales)
docker --version
# ‚úÖ Esperado: Docker versi√≥n 20.10 o superior
```

### Requisitos de Azure

- Suscripci√≥n activa de Azure
- Permisos para crear:
  - Container Apps
  - Service Bus namespaces
  - Cosmos DB accounts
  - Storage accounts
  - Application Insights

### Conocimientos previos

Deber√≠as haber completado:
- [Configuration Management](../chapter-03-configuration/configuration.md)
- [Authentication & Security](../chapter-03-configuration/authsecurity.md)
- [Microservices Example](../../../../examples/microservices)

---

## Gu√≠a de implementaci√≥n

### Estructura del proyecto

```
multi-agent-system/
‚îú‚îÄ‚îÄ azure.yaml                    # AZD configuration
‚îú‚îÄ‚îÄ infra/
‚îÇ   ‚îú‚îÄ‚îÄ main.bicep               # Main infrastructure
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ servicebus.bicep     # Message queue
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cosmos.bicep         # State store
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ storage.bicep        # Artifact storage
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ monitoring.bicep     # Application Insights
‚îÇ   ‚îî‚îÄ‚îÄ app/
‚îÇ       ‚îú‚îÄ‚îÄ orchestrator.bicep   # Orchestrator service
‚îÇ       ‚îî‚îÄ‚îÄ agent.bicep          # Agent template
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ orchestrator/            # Orchestration logic
    ‚îÇ   ‚îú‚îÄ‚îÄ app.py
    ‚îÇ   ‚îú‚îÄ‚îÄ workflows.py
    ‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
    ‚îú‚îÄ‚îÄ agents/
    ‚îÇ   ‚îú‚îÄ‚îÄ research/            # Research agent
    ‚îÇ   ‚îú‚îÄ‚îÄ writer/              # Writer agent
    ‚îÇ   ‚îú‚îÄ‚îÄ analyst/             # Analyst agent
    ‚îÇ   ‚îî‚îÄ‚îÄ reviewer/            # Reviewer agent
    ‚îî‚îÄ‚îÄ shared/
        ‚îú‚îÄ‚îÄ state_manager.py     # Shared state logic
        ‚îî‚îÄ‚îÄ message_handler.py   # Message handling
```

---

## Lecci√≥n 1: Patr√≥n de Coordinaci√≥n Secuencial

### Implementaci√≥n: Canal de creaci√≥n de contenido

Construyamos un pipeline secuencial: Investigaci√≥n ‚Üí Escribir ‚Üí Editar ‚Üí Publicar

### 1. Configuraci√≥n de AZD

**Archivo: `azure.yaml`**

```yaml
name: content-pipeline
metadata:
  template: multi-agent-sequential@1.0.0

services:
  orchestrator:
    project: ./src/orchestrator
    language: python
    host: containerapp
  
  research-agent:
    project: ./src/agents/research
    language: python
    host: containerapp
  
  writer-agent:
    project: ./src/agents/writer
    language: python
    host: containerapp
  
  editor-agent:
    project: ./src/agents/editor
    language: python
    host: containerapp
```

### 2. Infraestructura: Service Bus para coordinaci√≥n

**Archivo: `infra/core/servicebus.bicep`**

```bicep
param name string
param location string
param tags object = {}

resource serviceBusNamespace 'Microsoft.ServiceBus/namespaces@2022-10-01-preview' = {
  name: name
  location: location
  tags: tags
  sku: {
    name: 'Standard'
    tier: 'Standard'
  }
  properties: {
    minimumTlsVersion: '1.2'
  }
}

// Queue for orchestrator ‚Üí research agent
resource researchQueue 'Microsoft.ServiceBus/namespaces/queues@2022-10-01-preview' = {
  parent: serviceBusNamespace
  name: 'research-tasks'
  properties: {
    maxDeliveryCount: 3
    lockDuration: 'PT5M'
    deadLetteringOnMessageExpiration: true
  }
}

// Queue for research agent ‚Üí writer agent
resource writerQueue 'Microsoft.ServiceBus/namespaces/queues@2022-10-01-preview' = {
  parent: serviceBusNamespace
  name: 'writer-tasks'
  properties: {
    maxDeliveryCount: 3
    lockDuration: 'PT5M'
  }
}

// Queue for writer agent ‚Üí editor agent
resource editorQueue 'Microsoft.ServiceBus/namespaces/queues@2022-10-01-preview' = {
  parent: serviceBusNamespace
  name: 'editor-tasks'
  properties: {
    maxDeliveryCount: 3
    lockDuration: 'PT5M'
  }
}

output namespace string = serviceBusNamespace.name
output connectionString string = listKeys('${serviceBusNamespace.id}/AuthorizationRules/RootManageSharedAccessKey', serviceBusNamespace.apiVersion).primaryConnectionString
```

### 3. Gestor de estado compartido

**Archivo: `src/shared/state_manager.py`**

```python
from azure.cosmos import CosmosClient, PartitionKey
from datetime import datetime
import os

class StateManager:
    """Manages shared state across agents using Cosmos DB"""
    
    def __init__(self):
        endpoint = os.environ['COSMOS_ENDPOINT']
        key = os.environ['COSMOS_KEY']
        
        self.client = CosmosClient(endpoint, key)
        self.database = self.client.get_database_client('agent-state')
        self.container = self.database.get_container_client('tasks')
    
    def create_task(self, task_id: str, task_type: str, input_data: dict):
        """Create a new task"""
        task = {
            'id': task_id,
            'type': task_type,
            'status': 'pending',
            'input': input_data,
            'created_at': datetime.utcnow().isoformat(),
            'steps': []
        }
        self.container.create_item(task)
        return task
    
    def update_task_step(self, task_id: str, step_name: str, result: dict):
        """Update task with completed step"""
        task = self.container.read_item(task_id, partition_key=task_id)
        
        task['steps'].append({
            'name': step_name,
            'completed_at': datetime.utcnow().isoformat(),
            'result': result
        })
        
        self.container.replace_item(task_id, task)
        return task
    
    def complete_task(self, task_id: str, final_result: dict):
        """Mark task as complete"""
        task = self.container.read_item(task_id, partition_key=task_id)
        task['status'] = 'completed'
        task['result'] = final_result
        task['completed_at'] = datetime.utcnow().isoformat()
        self.container.replace_item(task_id, task)
        return task
    
    def get_task(self, task_id: str):
        """Retrieve task state"""
        return self.container.read_item(task_id, partition_key=task_id)
```

### 4. Servicio orquestador

**Archivo: `src/orchestrator/app.py`**

```python
from flask import Flask, request, jsonify
from azure.servicebus import ServiceBusClient, ServiceBusMessage
import json
import uuid
import os
from shared.state_manager import StateManager

app = Flask(__name__)
state_manager = StateManager()

# Conexi√≥n al Service Bus
servicebus_connection_str = os.environ['SERVICEBUS_CONNECTION_STRING']
servicebus_client = ServiceBusClient.from_connection_string(servicebus_connection_str)

@app.route('/health', methods=['GET'])
def health():
    return jsonify({'status': 'healthy', 'service': 'orchestrator'})

@app.route('/create-content', methods=['POST'])
def create_content():
    """
    Sequential workflow: Research ‚Üí Write ‚Üí Edit ‚Üí Publish
    """
    data = request.json
    topic = data.get('topic')
    
    if not topic:
        return jsonify({'error': 'Topic required'}), 400
    
    # Crear tarea en el almac√©n de estado
    task_id = str(uuid.uuid4())
    task = state_manager.create_task(
        task_id=task_id,
        task_type='content_creation',
        input_data={'topic': topic}
    )
    
    # Enviar mensaje al agente de investigaci√≥n (primer paso)
    sender = servicebus_client.get_queue_sender('research-tasks')
    message = ServiceBusMessage(
        body=json.dumps({
            'task_id': task_id,
            'topic': topic,
            'next_queue': 'writer-tasks'  # D√≥nde enviar los resultados
        }),
        content_type='application/json'
    )
    
    with sender:
        sender.send_messages(message)
    
    return jsonify({
        'task_id': task_id,
        'status': 'started',
        'workflow': 'sequential',
        'steps': ['research', 'write', 'edit', 'publish'],
        'message': 'Content creation pipeline initiated'
    }), 202

@app.route('/task/<task_id>', methods=['GET'])
def get_task_status(task_id):
    """Check task status"""
    try:
        task = state_manager.get_task(task_id)
        return jsonify(task)
    except Exception as e:
        return jsonify({'error': str(e)}), 404

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
```

### 5. Agente de investigaci√≥n

**Archivo: `src/agents/research/app.py`**

```python
from azure.servicebus import ServiceBusClient, ServiceBusMessage
from openai import AzureOpenAI
import json
import os
import time
from shared.state_manager import StateManager

# Inicializar clientes
state_manager = StateManager()
servicebus_client = ServiceBusClient.from_connection_string(
    os.environ['SERVICEBUS_CONNECTION_STRING']
)

openai_client = AzureOpenAI(
    api_key=os.environ['AZURE_OPENAI_API_KEY'],
    api_version="2024-02-01",
    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT']
)

def process_research_task(message_data):
    """Process research request and pass to writer"""
    task_id = message_data['task_id']
    topic = message_data['topic']
    next_queue = message_data['next_queue']
    
    print(f"üî¨ Researching: {topic}")
    
    # Llamar a Azure OpenAI para investigaci√≥n
    response = openai_client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are a research assistant. Provide comprehensive research on the given topic."},
            {"role": "user", "content": f"Research this topic thoroughly: {topic}"}
        ],
        max_tokens=1500
    )
    
    research_results = response.choices[0].message.content
    
    # Actualizar estado
    state_manager.update_task_step(
        task_id=task_id,
        step_name='research',
        result={'research': research_results}
    )
    
    # Enviar al siguiente agente (escritor)
    sender = servicebus_client.get_queue_sender(next_queue)
    message = ServiceBusMessage(
        body=json.dumps({
            'task_id': task_id,
            'topic': topic,
            'research': research_results,
            'next_queue': 'editor-tasks'
        }),
        content_type='application/json'
    )
    
    with sender:
        sender.send_messages(message)
    
    print(f"‚úÖ Research complete for task {task_id}")

def main():
    """Listen to research queue"""
    receiver = servicebus_client.get_queue_receiver('research-tasks')
    
    print("üî¨ Research Agent started, listening for tasks...")
    
    with receiver:
        while True:
            messages = receiver.receive_messages(max_wait_time=5)
            for message in messages:
                try:
                    message_data = json.loads(str(message))
                    process_research_task(message_data)
                    receiver.complete_message(message)
                except Exception as e:
                    print(f"‚ùå Error processing message: {e}")
                    receiver.abandon_message(message)

if __name__ == '__main__':
    main()
```

### 6. Agente escritor

**Archivo: `src/agents/writer/app.py`**

```python
from azure.servicebus import ServiceBusClient, ServiceBusMessage
from openai import AzureOpenAI
import json
import os
from shared.state_manager import StateManager

state_manager = StateManager()
servicebus_client = ServiceBusClient.from_connection_string(
    os.environ['SERVICEBUS_CONNECTION_STRING']
)

openai_client = AzureOpenAI(
    api_key=os.environ['AZURE_OPENAI_API_KEY'],
    api_version="2024-02-01",
    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT']
)

def process_writing_task(message_data):
    """Write article based on research"""
    task_id = message_data['task_id']
    topic = message_data['topic']
    research = message_data['research']
    next_queue = message_data['next_queue']
    
    print(f"‚úçÔ∏è Writing article: {topic}")
    
    # Llamar a Azure OpenAI para escribir el art√≠culo
    response = openai_client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are a professional writer. Write engaging, well-structured articles."},
            {"role": "user", "content": f"Based on this research:\n\n{research}\n\nWrite a comprehensive article about: {topic}"}
        ],
        max_tokens=2000
    )
    
    article_draft = response.choices[0].message.content
    
    # Actualizar el estado
    state_manager.update_task_step(
        task_id=task_id,
        step_name='writing',
        result={'draft': article_draft}
    )
    
    # Enviar al editor
    sender = servicebus_client.get_queue_sender(next_queue)
    message = ServiceBusMessage(
        body=json.dumps({
            'task_id': task_id,
            'topic': topic,
            'draft': article_draft
        }),
        content_type='application/json'
    )
    
    with sender:
        sender.send_messages(message)
    
    print(f"‚úÖ Article draft complete for task {task_id}")

def main():
    """Listen to writer queue"""
    receiver = servicebus_client.get_queue_receiver('writer-tasks')
    
    print("‚úçÔ∏è Writer Agent started, listening for tasks...")
    
    with receiver:
        while True:
            messages = receiver.receive_messages(max_wait_time=5)
            for message in messages:
                try:
                    message_data = json.loads(str(message))
                    process_writing_task(message_data)
                    receiver.complete_message(message)
                except Exception as e:
                    print(f"‚ùå Error: {e}")
                    receiver.abandon_message(message)

if __name__ == '__main__':
    main()
```

### 7. Agente editor

**Archivo: `src/agents/editor/app.py`**

```python
from azure.servicebus import ServiceBusClient
from openai import AzureOpenAI
import json
import os
from shared.state_manager import StateManager

state_manager = StateManager()
servicebus_client = ServiceBusClient.from_connection_string(
    os.environ['SERVICEBUS_CONNECTION_STRING']
)

openai_client = AzureOpenAI(
    api_key=os.environ['AZURE_OPENAI_API_KEY'],
    api_version="2024-02-01",
    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT']
)

def process_editing_task(message_data):
    """Edit and finalize article"""
    task_id = message_data['task_id']
    topic = message_data['topic']
    draft = message_data['draft']
    
    print(f"üìù Editing article: {topic}")
    
    # Llamar a Azure OpenAI para editar
    response = openai_client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are an expert editor. Improve grammar, clarity, and structure."},
            {"role": "user", "content": f"Edit and improve this article:\n\n{draft}"}
        ],
        max_tokens=2000
    )
    
    final_article = response.choices[0].message.content
    
    # Marcar la tarea como completada
    state_manager.complete_task(
        task_id=task_id,
        final_result={
            'topic': topic,
            'final_article': final_article,
            'word_count': len(final_article.split())
        }
    )
    
    print(f"‚úÖ Article finalized for task {task_id}")

def main():
    """Listen to editor queue"""
    receiver = servicebus_client.get_queue_receiver('editor-tasks')
    
    print("üìù Editor Agent started, listening for tasks...")
    
    with receiver:
        while True:
            messages = receiver.receive_messages(max_wait_time=5)
            for message in messages:
                try:
                    message_data = json.loads(str(message))
                    process_editing_task(message_data)
                    receiver.complete_message(message)
                except Exception as e:
                    print(f"‚ùå Error: {e}")
                    receiver.abandon_message(message)

if __name__ == '__main__':
    main()
```

### 8. Desplegar y probar

```bash
# Inicializar y desplegar
azd init
azd up

# Obtener la URL del orquestador
ORCHESTRATOR_URL=$(azd env get-values | grep ORCHESTRATOR_URL | cut -d '=' -f2 | tr -d '"')

# Crear contenido
curl -X POST $ORCHESTRATOR_URL/create-content \
  -H "Content-Type: application/json" \
  -d '{"topic": "The Future of AI in Healthcare"}'
```

**‚úÖ Salida esperada:**
```json
{
  "task_id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "status": "started",
  "workflow": "sequential",
  "steps": ["research", "write", "edit", "publish"],
  "message": "Content creation pipeline initiated"
}
```

**Comprobar progreso de la tarea:**
```bash
TASK_ID="a1b2c3d4-e5f6-7890-abcd-ef1234567890"
curl $ORCHESTRATOR_URL/task/$TASK_ID
```

**‚úÖ Salida esperada (completado):**
```json
{
  "id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "type": "content_creation",
  "status": "completed",
  "steps": [
    {
      "name": "research",
      "completed_at": "2025-11-19T10:30:00Z",
      "result": {"research": "..."}
    },
    {
      "name": "writing",
      "completed_at": "2025-11-19T10:32:00Z",
      "result": {"draft": "..."}
    }
  ],
  "result": {
    "topic": "The Future of AI in Healthcare",
    "final_article": "...",
    "word_count": 1500
  }
}
```

---

## Lecci√≥n 2: Patr√≥n de Coordinaci√≥n en Paralelo

### Implementaci√≥n: Agregador de investigaci√≥n multi-fuente

Construyamos un sistema paralelo que re√∫na informaci√≥n de m√∫ltiples fuentes simult√°neamente.

### Orquestador paralelo

**Archivo: `src/orchestrator/parallel_workflow.py`**

```python
from flask import Flask, request, jsonify
from azure.servicebus import ServiceBusClient, ServiceBusMessage
import json
import uuid
import os
from shared.state_manager import StateManager

app = Flask(__name__)
state_manager = StateManager()

servicebus_client = ServiceBusClient.from_connection_string(
    os.environ['SERVICEBUS_CONNECTION_STRING']
)

@app.route('/research-parallel', methods=['POST'])
def research_parallel():
    """
    Parallel workflow: Multiple agents work simultaneously
    """
    data = request.json
    query = data.get('query')
    
    task_id = str(uuid.uuid4())
    task = state_manager.create_task(
        task_id=task_id,
        task_type='parallel_research',
        input_data={
            'query': query,
            'agents': ['web', 'academic', 'news', 'social']
        }
    )
    
    # Difusi√≥n: Enviar a todos los agentes simult√°neamente
    agents = [
        ('web-research-queue', 'web'),
        ('academic-research-queue', 'academic'),
        ('news-research-queue', 'news'),
        ('social-research-queue', 'social')
    ]
    
    for queue_name, agent_type in agents:
        sender = servicebus_client.get_queue_sender(queue_name)
        message = ServiceBusMessage(
            body=json.dumps({
                'task_id': task_id,
                'query': query,
                'agent_type': agent_type,
                'result_queue': 'aggregation-queue'
            }),
            content_type='application/json'
        )
        
        with sender:
            sender.send_messages(message)
    
    return jsonify({
        'task_id': task_id,
        'status': 'started',
        'workflow': 'parallel',
        'agents_dispatched': 4,
        'message': 'Parallel research initiated'
    }), 202

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
```

### L√≥gica de agregaci√≥n

**Archivo: `src/agents/aggregator/app.py`**

```python
from azure.servicebus import ServiceBusClient
import json
import os
from collections import defaultdict
from shared.state_manager import StateManager

state_manager = StateManager()
servicebus_client = ServiceBusClient.from_connection_string(
    os.environ['SERVICEBUS_CONNECTION_STRING']
)

# Rastrear resultados por tarea
task_results = defaultdict(list)
expected_agents = 4  # web, acad√©mico, noticias, social

def process_result(message_data):
    """Aggregate results from parallel agents"""
    task_id = message_data['task_id']
    agent_type = message_data['agent_type']
    result = message_data['result']
    
    # Almacenar resultado
    task_results[task_id].append({
        'agent': agent_type,
        'data': result
    })
    
    print(f"üìä Received result from {agent_type} agent ({len(task_results[task_id])}/{expected_agents})")
    
    # Comprobar si todos los agentes han completado (fan-in)
    if len(task_results[task_id]) == expected_agents:
        print(f"‚úÖ All agents completed for task {task_id}. Aggregating...")
        
        # Combinar resultados
        aggregated = {
            'query': message_data['query'],
            'sources': task_results[task_id],
            'summary': generate_summary(task_results[task_id])
        }
        
        # Marcar como completado
        state_manager.complete_task(task_id, aggregated)
        
        # Limpiar
        del task_results[task_id]
        
        print(f"‚úÖ Aggregation complete for task {task_id}")

def generate_summary(results):
    """Generate summary from all sources"""
    summaries = [r['data'].get('summary', '') for r in results]
    return '\n\n'.join(summaries)

def main():
    """Listen to aggregation queue"""
    receiver = servicebus_client.get_queue_receiver('aggregation-queue')
    
    print("üìä Aggregator started, listening for results...")
    
    with receiver:
        while True:
            messages = receiver.receive_messages(max_wait_time=5)
            for message in messages:
                try:
                    message_data = json.loads(str(message))
                    process_result(message_data)
                    receiver.complete_message(message)
                except Exception as e:
                    print(f"‚ùå Error: {e}")
                    receiver.abandon_message(message)

if __name__ == '__main__':
    main()
```

**Beneficios del patr√≥n paralelo:**
- ‚ö° **4x m√°s r√°pido** (los agentes se ejecutan simult√°neamente)
- üîÑ **Tolerante a fallos** (resultados parciales aceptables)
- üìà **Escalable** (a√±adir m√°s agentes f√°cilmente)

---

## Ejercicios pr√°cticos

### Ejercicio 1: A√±adir manejo de timeouts ‚≠ê‚≠ê (Medio)

**Objetivo**: Implementar l√≥gica de timeout para que el agregador no espere indefinidamente a agentes lentos.

**Pasos**:

1. **A√±adir seguimiento de timeout al agregador:**

```python
from datetime import datetime, timedelta

task_timeouts = {}  # task_id -> expiration_time

def process_result(message_data):
    task_id = message_data['task_id']
    
    # Establecer tiempo de espera para el primer resultado
    if task_id not in task_timeouts:
        task_timeouts[task_id] = datetime.utcnow() + timedelta(seconds=30)
    
    task_results[task_id].append({
        'agent': message_data['agent_type'],
        'data': message_data['result']
    })
    
    # Comprobar si est√° completo O si se agot√≥ el tiempo
    if len(task_results[task_id]) == expected_agents or \
       datetime.utcnow() > task_timeouts[task_id]:
        
        print(f"üìä Aggregating with {len(task_results[task_id])}/{expected_agents} results")
        
        aggregated = {
            'query': message_data['query'],
            'sources': task_results[task_id],
            'completed_agents': len(task_results[task_id]),
            'timed_out': len(task_results[task_id]) < expected_agents
        }
        
        state_manager.complete_task(task_id, aggregated)
        
        # Limpieza
        del task_results[task_id]
        del task_timeouts[task_id]
```

2. **Probar con retrasos artificiales:**

```python
# En un agente, agregar retraso para simular procesamiento lento
import time
time.sleep(35)  # Supera el tiempo de espera de 30 segundos
```

3. **Desplegar y verificar:**

```bash
azd deploy aggregator

# Enviar tarea
curl -X POST $ORCHESTRATOR_URL/research-parallel \
  -H "Content-Type: application/json" \
  -d '{"query": "AI safety research"}'

# Comprobar resultados despu√©s de 30 segundos
curl $ORCHESTRATOR_URL/task/$TASK_ID
```

**‚úÖ Criterios de √©xito:**
- ‚úÖ La tarea se completa despu√©s de 30 segundos incluso si los agentes est√°n incompletos
- ‚úÖ La respuesta indica resultados parciales (`"timed_out": true`)
- ‚úÖ Se devuelven los resultados disponibles (3 de 4 agentes)

**Tiempo**: 20-25 minutos

---

### Ejercicio 2: Implementar l√≥gica de reintentos ‚≠ê‚≠ê‚≠ê (Avanzado)

**Objetivo**: Reintentar autom√°ticamente tareas de agentes fallidos antes de rendirse.

**Pasos**:

1. **A√±adir seguimiento de reintentos al orquestador:**

```python
from dataclasses import dataclass
from typing import Dict

@dataclass
class RetryConfig:
    max_retries: int = 3
    backoff_seconds: int = 5

retry_counts: Dict[str, int] = {}  # message_id -> retry_count

def send_with_retry(queue_name: str, message_data: dict, retry_config: RetryConfig):
    """Send message with retry metadata"""
    message_id = message_data.get('message_id', str(uuid.uuid4()))
    message_data['message_id'] = message_id
    message_data['retry_count'] = retry_counts.get(message_id, 0)
    message_data['max_retries'] = retry_config.max_retries
    
    sender = servicebus_client.get_queue_sender(queue_name)
    message = ServiceBusMessage(
        body=json.dumps(message_data),
        content_type='application/json',
        message_id=message_id
    )
    
    with sender:
        sender.send_messages(message)
```

2. **A√±adir manejador de reintentos a los agentes:**

```python
def process_with_retry(message, receiver, process_func):
    """Process message with automatic retry on failure"""
    try:
        message_data = json.loads(str(message))
        
        # Procesar el mensaje
        process_func(message_data)
        
        # √âxito - completado
        receiver.complete_message(message)
        
    except Exception as e:
        message_id = message.message_id
        retry_count = message_data.get('retry_count', 0)
        max_retries = message_data.get('max_retries', 3)
        
        if retry_count < max_retries:
            # Reintentar: abandonar y volver a encolar con el contador incrementado
            print(f"‚ö†Ô∏è Retry {retry_count + 1}/{max_retries} for message {message_id}")
            
            message_data['retry_count'] = retry_count + 1
            
            # Enviar de nuevo a la misma cola con retraso
            time.sleep(5 * (retry_count + 1))  # Espera exponencial
            send_with_retry(queue_name, message_data, RetryConfig())
            
            receiver.complete_message(message)  # Eliminar el original
        else:
            # N√∫mero m√°ximo de reintentos excedido - mover a la cola de mensajes no entregados
            print(f"‚ùå Max retries exceeded for message {message_id}")
            receiver.dead_letter_message(
                message,
                reason="MaxRetriesExceeded",
                error_description=str(e)
            )
```

3. **Monitorear la dead letter queue:**

```python
def monitor_dead_letters():
    """Check dead letter queue for failed messages"""
    receiver = servicebus_client.get_queue_receiver(
        'research-queue',
        sub_queue='deadletter'
    )
    
    with receiver:
        messages = receiver.receive_messages(max_wait_time=5)
        for message in messages:
            print(f"‚ò†Ô∏è Dead letter: {message.message_id}")
            print(f"Reason: {message.dead_letter_reason}")
            print(f"Description: {message.dead_letter_error_description}")
```

**‚úÖ Criterios de √©xito:**
- ‚úÖ Las tareas fallidas se reintentan autom√°ticamente (hasta 3 veces)
- ‚úÖ Backoff exponencial entre reintentos (5s, 10s, 15s)
- ‚úÖ Despu√©s de los reintentos m√°ximos, los mensajes van a la dead letter queue
- ‚úÖ La dead letter queue puede ser monitorizada y reenviada

**Tiempo**: 30-40 minutos

---

### Ejercicio 3: Implementar Circuit Breaker ‚≠ê‚≠ê‚≠ê (Avanzado)

**Objetivo**: Prevenir fallos en cascada deteniendo las solicitudes a agentes que fallan.

**Pasos**:

1. **Crear clase de circuit breaker:**

```python
from enum import Enum
from datetime import datetime, timedelta

class CircuitState(Enum):
    CLOSED = "closed"      # Operaci√≥n normal
    OPEN = "open"          # Fallo, rechazar solicitudes
    HALF_OPEN = "half_open"  # Comprobando si se ha recuperado

class CircuitBreaker:
    def __init__(self, failure_threshold=5, timeout_seconds=60):
        self.failure_threshold = failure_threshold
        self.timeout_seconds = timeout_seconds
        self.failure_count = 0
        self.last_failure_time = None
        self.state = CircuitState.CLOSED
    
    def call(self, func):
        """Execute function with circuit breaker protection"""
        if self.state == CircuitState.OPEN:
            # Comprobar si el tiempo de espera ha expirado
            if datetime.utcnow() - self.last_failure_time > timedelta(seconds=self.timeout_seconds):
                self.state = CircuitState.HALF_OPEN
                print("üîÑ Circuit breaker: HALF_OPEN (testing)")
            else:
                raise Exception(f"Circuit breaker OPEN for agent. Try again in {self.timeout_seconds}s")
        
        try:
            result = func()
            
            # √âxito
            if self.state == CircuitState.HALF_OPEN:
                self.state = CircuitState.CLOSED
                self.failure_count = 0
                print("‚úÖ Circuit breaker: CLOSED (recovered)")
            
            return result
            
        except Exception as e:
            self.failure_count += 1
            self.last_failure_time = datetime.utcnow()
            
            if self.failure_count >= self.failure_threshold:
                self.state = CircuitState.OPEN
                print(f"üî¥ Circuit breaker: OPEN (too many failures)")
            
            raise e
```

2. **Aplicar a llamadas a agentes:**

```python
# En el orquestador
agent_circuits = {
    'web': CircuitBreaker(failure_threshold=5, timeout_seconds=60),
    'academic': CircuitBreaker(failure_threshold=5, timeout_seconds=60),
    'news': CircuitBreaker(failure_threshold=5, timeout_seconds=60),
    'social': CircuitBreaker(failure_threshold=5, timeout_seconds=60)
}

def send_to_agent(agent_type, message_data):
    """Send with circuit breaker protection"""
    circuit = agent_circuits[agent_type]
    
    try:
        circuit.call(lambda: send_message(agent_type, message_data))
    except Exception as e:
        print(f"‚ö†Ô∏è Skipping {agent_type} agent: {e}")
        # Continuar con otros agentes
```

3. **Probar el circuit breaker:**

```bash
# Simular fallos repetidos (detener un agente)
az containerapp stop --name web-research-agent --resource-group rg-agents

# Enviar m√∫ltiples solicitudes
for i in {1..10}; do
  curl -X POST $ORCHESTRATOR_URL/research-parallel \
    -H "Content-Type: application/json" \
    -d '{"query": "test query '$i'"}'
  sleep 2
done

# Comprobar los registros - deber√≠a ver el circuito abierto despu√©s de 5 fallos
# Usar Azure CLI para los registros de Container App:
az containerapp logs show --name orchestrator --resource-group $RG_NAME --tail 50
```

**‚úÖ Criterios de √©xito:**
- ‚úÖ Tras 5 fallos, el circuito se abre (rechaza solicitudes)
- ‚úÖ Tras 60 segundos, el circuito pasa a semi-abierto (prueba recuperaci√≥n)
- ‚úÖ Otros agentes contin√∫an funcionando normalmente
- ‚úÖ El circuito se cierra autom√°ticamente cuando el agente se recupera

**Tiempo**: 40-50 minutos

---

## Monitoreo y depuraci√≥n

### Trazado distribuido con Application Insights

**Archivo: `src/shared/tracing.py`**

```python
from opencensus.ext.azure.log_exporter import AzureLogHandler
from opencensus.ext.azure.trace_exporter import AzureExporter
from opencensus.trace import config_integration
from opencensus.trace.tracer import Tracer
from opencensus.trace.samplers import AlwaysOnSampler
import logging
import os

# Configurar el trazado
config_integration.trace_integrations(['requests', 'logging'])

connection_string = os.environ.get('APPLICATIONINSIGHTS_CONNECTION_STRING')

# Crear trazador
tracer = Tracer(
    exporter=AzureExporter(connection_string=connection_string),
    sampler=AlwaysOnSampler()
)

# Configurar el registro
logger = logging.getLogger(__name__)
logger.addHandler(AzureLogHandler(connection_string=connection_string))
logger.setLevel(logging.INFO)

def trace_agent_call(agent_name, task_id, operation):
    """Trace agent operations"""
    with tracer.span(name=f'{agent_name}.{operation}') as span:
        span.add_attribute('agent', agent_name)
        span.add_attribute('task_id', task_id)
        span.add_attribute('operation', operation)
        
        try:
            result = operation()
            span.add_attribute('status', 'success')
            return result
        except Exception as e:
            span.add_attribute('status', 'error')
            span.add_attribute('error', str(e))
            raise
```

### Consultas de Application Insights

**Rastrear flujos de trabajo multi-agente:**

```kusto
// Trace complete workflow for a task
traces
| where customDimensions.task_id == "a1b2c3d4-..."
| project timestamp, message, customDimensions.agent, customDimensions.operation
| order by timestamp asc
```

**Comparaci√≥n de rendimiento de agentes:**

```kusto
// Compare agent execution times
dependencies
| where name contains "agent"
| summarize 
    avg_duration = avg(duration),
    p95_duration = percentile(duration, 95),
    count = count()
  by agent = tostring(customDimensions.agent)
| order by avg_duration desc
```

**An√°lisis de fallos:**

```kusto
// Find which agents fail most
exceptions
| where customDimensions.agent != ""
| summarize 
    failure_count = count(),
    unique_errors = dcount(outerMessage)
  by agent = tostring(customDimensions.agent)
| order by failure_count desc
```

---

## An√°lisis de costos

### Costos del sistema multi-agente (Estimaciones mensuales)

| Component | Configuration | Cost |
|-----------|--------------|------|
| **Orchestrator** | 1 Container App (1 vCPU, 2GB) | $30-50 |
| **4 Agents** | 4 Container Apps (0.5 vCPU, 1GB each) | $60-120 |
| **Service Bus** | Standard tier, 10M messages | $10-20 |
| **Cosmos DB** | Serverless, 5GB storage, 1M RUs | $25-50 |
| **Blob Storage** | 10GB storage, 100K operations | $5-10 |
| **Application Insights** | 5GB ingestion | $10-15 |
| **Azure OpenAI** | GPT-4, 10M tokens | $100-300 |
| **Total** | | **$240-565/month** |

### Estrategias de optimizaci√≥n de costos

1. **Usar serverless cuando sea posible:**
   ```bicep
   // Cosmos DB serverless (no minimum cost)
   properties: {
     databaseAccountOfferType: 'Standard'
     capabilities: [{ name: 'EnableServerless' }]
   }
   ```

2. **Escalar agentes a cero cuando est√©n inactivos:**
   ```bicep
   scale: {
     minReplicas: 0  // Scale to zero when no messages
     maxReplicas: 10
   }
   ```

3. **Usar batching para Service Bus:**
   ```python
   # Enviar mensajes en lotes (m√°s barato)
   sender.send_messages([message1, message2, message3])
   ```

4. **Cachear resultados usados con frecuencia:**
   ```python
   # Usar Azure Cache para Redis
   if cache.exists(query_hash):
       return cache.get(query_hash)
   ```

---

## Buenas pr√°cticas

### ‚úÖ HACER:

1. **Usar operaciones idempotentes**
   ```python
   # El agente puede procesar de forma segura el mismo mensaje varias veces
   def process_task(task_id):
       if state_manager.task_exists(task_id):
           print(f"Task {task_id} already processed, skipping")
           return
       # Procesar tarea...
   ```

2. **Implementar registro (logging) exhaustivo**
   ```python
   logger.info(f"Agent: {agent_name}, Task: {task_id}, Action: {action}")
   ```

3. **Usar IDs de correlaci√≥n**
   ```python
   # Pasar task_id a trav√©s de todo el flujo de trabajo
   message_data = {
       'task_id': task_id,  # ID de correlaci√≥n
       'timestamp': datetime.utcnow().isoformat()
   }
   ```

4. **Establecer TTL en mensajes (time-to-live)**
   ```bicep
   properties: {
     defaultMessageTimeToLive: 'PT1H'  // 1 hour max
   }
   ```

5. **Monitorear las dead letter queues**
   ```python
   # Monitoreo regular de mensajes fallidos
   monitor_dead_letters()
   ```

### ‚ùå NO HACER:

1. **No crear dependencias circulares**
   ```python
   # ‚ùå MALO: Agente A ‚Üí Agente B ‚Üí Agente A (bucle infinito)
   # ‚úÖ BUENO: Define un grafo ac√≠clico dirigido claro (DAG)
   ```

2. **No bloquear hilos de agentes**
   ```python
   # ‚ùå MALO: Espera sincr√≥nica
   while not task_complete:
       time.sleep(1)
   
   # ‚úÖ BUENO: Usar callbacks de la cola de mensajes
   ```

3. **No ignorar fallos parciales**
   ```python
   # ‚ùå MALO: Hacer que todo el flujo de trabajo falle si un agente falla
   # ‚úÖ BUENO: Devolver resultados parciales con indicadores de error
   ```

4. **No usar reintentos infinitos**
   ```python
   # ‚ùå MALO: reintentar indefinidamente
   # ‚úÖ BUENO: max_retries = 3, luego a la cola de mensajes muertos
   ```

---
## Gu√≠a de soluci√≥n de problemas

### Problema: Mensajes atascados en la cola

**S√≠ntomas:**
- Los mensajes se acumulan en la cola
- Los agentes no procesan
- El estado de la tarea queda atascado en "pending"

**Diagn√≥stico:**
```bash
# Comprobar la profundidad de la cola
az servicebus queue show \
  --namespace-name mybus \
  --name research-tasks \
  --query "countDetails"

# Verificar los registros del agente usando Azure CLI
az containerapp logs show --name research-agent --resource-group $RG_NAME --tail 50
```

**Soluciones:**

1. **Aumentar r√©plicas de agente:**
   ```bash
   az containerapp update \
     --name research-agent \
     --min-replicas 3 \
     --max-replicas 10
   ```

2. **Comprobar la cola de mensajes muertos:**
   ```bash
   az servicebus queue show \
     --namespace-name mybus \
     --name research-tasks \
     --query "countDetails.deadLetterMessageCount"
   ```

---

### Problema: Tiempo de espera de la tarea / nunca se completa

**S√≠ntomas:**
- El estado de la tarea permanece en "in_progress"
- Algunos agentes terminan, otros no
- No hay mensajes de error

**Diagn√≥stico:**
```bash
# Comprobar el estado de la tarea
curl $ORCHESTRATOR_URL/task/$TASK_ID

# Comprobar Application Insights
# Ejecutar la consulta: traces | where customDimensions.task_id == "..."
```

**Soluciones:**

1. **Implementar un tiempo de espera en el agregador (Ejercicio 1)**

2. **Verificar fallos de agentes usando Azure Monitor:**
   ```bash
   # Ver registros mediante azd monitor
   azd monitor --logs
   
   # O usa Azure CLI para consultar los registros de una aplicaci√≥n de contenedor espec√≠fica
   az containerapp logs show --name <agent-name> --resource-group $RG_NAME --follow | grep "ERROR\|FAIL"
   ```

3. **Verificar que todos los agentes est√©n en ejecuci√≥n:**
   ```bash
   az containerapp list \
     --resource-group rg-agents \
     --query "[].{name:name, status:properties.runningStatus}"
   ```

---

## M√°s informaci√≥n

### Documentaci√≥n oficial
- [Azure Service Bus](https://learn.microsoft.com/azure/service-bus-messaging/service-bus-messaging-overview)
- [Cosmos DB](https://learn.microsoft.com/azure/cosmos-db/introduction)
- [Container Apps DAPR](https://learn.microsoft.com/azure/container-apps/dapr-overview)
- [Multi-Agent Design Patterns](https://learn.microsoft.com/azure/architecture/guide/ai/multi-agent-systems)

### Siguientes pasos en este curso
- ‚Üê Anterior: [Planificaci√≥n de capacidad](capacity-planning.md)
- ‚Üí Siguiente: [Selecci√≥n de SKU](sku-selection.md)
- üè† [Inicio del curso](../../README.md)

### Ejemplos relacionados
- [Ejemplo de microservicios](../../../../examples/microservices) - Patrones de comunicaci√≥n entre servicios
- [Ejemplo de Azure OpenAI](../../../../examples/azure-openai-chat) - Integraci√≥n de IA

---

## Resumen

**Has aprendido:**
- ‚úÖ Cinco patrones de coordinaci√≥n (secuencial, paralelo, jer√°rquico, orientado a eventos, consenso)
- ‚úÖ Arquitectura multiagente en Azure (Service Bus, Cosmos DB, Container Apps)
- ‚úÖ Gesti√≥n de estado a trav√©s de agentes distribuidos
- ‚úÖ Manejo de tiempos de espera, reintentos y circuit breakers
- ‚úÖ Monitorizaci√≥n y depuraci√≥n de sistemas distribuidos
- ‚úÖ Estrategias de optimizaci√≥n de costos

**Puntos clave:**
1. **Elige el patr√≥n adecuado** - Secuencial para flujos de trabajo ordenados, paralelo para velocidad, orientado a eventos para flexibilidad
2. **Gestiona el estado con cuidado** - Usa Cosmos DB o similar para estado compartido
3. **Maneja los fallos con gracia** - Tiempos de espera, reintentos, circuit breakers, colas de mensajes muertos
4. **Monitoriza todo** - El trazado distribuido es esencial para depurar
5. **Optimiza costos** - Escala a cero, usa serverless, implementa cach√©

**Pr√≥ximos pasos:**
1. Completa los ejercicios pr√°cticos
2. Construye un sistema multiagente para tu caso de uso
3. Estudia [Selecci√≥n de SKU](sku-selection.md) para optimizar rendimiento y costos

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Descargo de responsabilidad**:
Este documento ha sido traducido mediante el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por la exactitud, tenga en cuenta que las traducciones automatizadas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por un traductor humano. No nos hacemos responsables de ning√∫n malentendido o interpretaci√≥n err√≥nea que surja del uso de esta traducci√≥n.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->