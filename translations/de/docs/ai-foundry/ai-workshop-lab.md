<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8b26783231714a00efafee3aca8b233c",
  "translation_date": "2025-11-19T23:01:39+00:00",
  "source_file": "docs/ai-foundry/ai-workshop-lab.md",
  "language_code": "de"
}
-->
# AI Workshop Lab: Ihre KI-L√∂sungen AZD-bereit machen

**Kapitel√ºbersicht:**
- **üìö Kurs√ºbersicht**: [AZD f√ºr Einsteiger](../../README.md)
- **üìñ Aktuelles Kapitel**: Kapitel 2 - KI-First-Entwicklung
- **‚¨ÖÔ∏è Vorheriges**: [KI-Modellbereitstellung](ai-model-deployment.md)
- **‚û°Ô∏è N√§chstes**: [Best Practices f√ºr produktive KI](production-ai-practices.md)
- **üöÄ N√§chstes Kapitel**: [Kapitel 3: Konfiguration](../getting-started/configuration.md)

## Workshop-√úbersicht

Dieses praktische Lab f√ºhrt Entwickler durch den Prozess, eine bestehende KI-Vorlage zu nehmen und sie mit dem Azure Developer CLI (AZD) bereitzustellen. Sie lernen wesentliche Muster f√ºr produktive KI-Bereitstellungen mit Microsoft Foundry-Diensten kennen.

**Dauer:** 2-3 Stunden  
**Level:** Mittelstufe  
**Voraussetzungen:** Grundkenntnisse in Azure, Vertrautheit mit KI/ML-Konzepten

## üéì Lernziele

Am Ende dieses Workshops werden Sie in der Lage sein:
- ‚úÖ Eine bestehende KI-Anwendung in AZD-Vorlagen umzuwandeln
- ‚úÖ Microsoft Foundry-Dienste mit AZD zu konfigurieren
- ‚úÖ Sichere Anmeldeinformationen f√ºr KI-Dienste zu implementieren
- ‚úÖ Produktionsreife KI-Anwendungen mit Monitoring bereitzustellen
- ‚úÖ H√§ufige Probleme bei der KI-Bereitstellung zu beheben

## Voraussetzungen

### Erforderliche Tools
- [Azure Developer CLI](https://learn.microsoft.com/azure/developer/azure-developer-cli/install-azd) installiert
- [Azure CLI](https://docs.microsoft.com/cli/azure/install-azure-cli) installiert
- [Git](https://git-scm.com/) installiert
- Code-Editor (VS Code empfohlen)

### Azure-Ressourcen
- Azure-Abonnement mit Mitwirkendenzugriff
- Zugriff auf Azure OpenAI-Dienste (oder die M√∂glichkeit, Zugriff zu beantragen)
- Berechtigungen zur Erstellung von Ressourcengruppen

### Wissensvoraussetzungen
- Grundlegendes Verst√§ndnis von Azure-Diensten
- Vertrautheit mit Kommandozeilenschnittstellen
- Grundlegende KI/ML-Konzepte (APIs, Modelle, Prompts)

## Lab-Vorbereitung

### Schritt 1: Vorbereitung der Umgebung

1. **√úberpr√ºfen Sie die Installation der Tools:**
```bash
# √úberpr√ºfen Sie die AZD-Installation
azd version

# √úberpr√ºfen Sie die Azure CLI
az --version

# Melden Sie sich bei Azure an
az login
azd auth login
```

2. **Klonen Sie das Workshop-Repository:**
```bash
git clone https://github.com/Azure-Samples/azure-search-openai-demo
cd azure-search-openai-demo
```

## Modul 1: Verst√§ndnis der AZD-Struktur f√ºr KI-Anwendungen

### Aufbau einer KI-AZD-Vorlage

Erkunden Sie die wichtigsten Dateien in einer KI-bereiten AZD-Vorlage:

```
azure-search-openai-demo/
‚îú‚îÄ‚îÄ azure.yaml              # AZD configuration
‚îú‚îÄ‚îÄ infra/                   # Infrastructure as Code
‚îÇ   ‚îú‚îÄ‚îÄ main.bicep          # Main infrastructure template
‚îÇ   ‚îú‚îÄ‚îÄ main.parameters.json # Environment parameters
‚îÇ   ‚îî‚îÄ‚îÄ modules/            # Reusable Bicep modules
‚îÇ       ‚îú‚îÄ‚îÄ openai.bicep    # Azure OpenAI configuration
‚îÇ       ‚îú‚îÄ‚îÄ search.bicep    # Cognitive Search setup
‚îÇ       ‚îî‚îÄ‚îÄ webapp.bicep    # Web app configuration
‚îú‚îÄ‚îÄ app/                    # Application code
‚îú‚îÄ‚îÄ scripts/               # Deployment scripts
‚îî‚îÄ‚îÄ .azure/               # AZD environment files
```

### **Lab-√úbung 1.1: Konfiguration erkunden**

1. **Untersuchen Sie die Datei azure.yaml:**
```bash
cat azure.yaml
```

**Worauf Sie achten sollten:**
- Dienstdefinitionen f√ºr KI-Komponenten
- Zuordnungen von Umgebungsvariablen
- Host-Konfigurationen

2. **√úberpr√ºfen Sie die Infrastruktur main.bicep:**
```bash
cat infra/main.bicep
```

**Wichtige KI-Muster, die Sie identifizieren sollten:**
- Bereitstellung des Azure OpenAI-Dienstes
- Integration von Cognitive Search
- Sicheres Schl√ºsselmanagement
- Netzwerksicherheitskonfigurationen

### **Diskussionspunkt:** Warum diese Muster f√ºr KI wichtig sind

- **Dienstabh√§ngigkeiten**: KI-Anwendungen erfordern oft mehrere koordinierte Dienste
- **Sicherheit**: API-Schl√ºssel und Endpunkte m√ºssen sicher verwaltet werden
- **Skalierbarkeit**: KI-Workloads haben einzigartige Skalierungsanforderungen
- **Kostenmanagement**: KI-Dienste k√∂nnen teuer sein, wenn sie nicht richtig konfiguriert werden

## Modul 2: Ihre erste KI-Anwendung bereitstellen

### Schritt 2.1: Die Umgebung initialisieren

1. **Erstellen Sie eine neue AZD-Umgebung:**
```bash
azd env new myai-workshop
```

2. **Erforderliche Parameter festlegen:**
```bash
# Legen Sie Ihre bevorzugte Azure-Region fest
azd env set AZURE_LOCATION eastus

# Optional: Spezifisches OpenAI-Modell festlegen
azd env set AZURE_OPENAI_MODEL gpt-35-turbo
```

### Schritt 2.2: Infrastruktur und Anwendung bereitstellen

1. **Bereitstellung mit AZD:**
```bash
azd up
```

**Was w√§hrend `azd up` passiert:**
- ‚úÖ Bereitstellung des Azure OpenAI-Dienstes
- ‚úÖ Erstellung des Cognitive Search-Dienstes
- ‚úÖ Einrichtung des App Service f√ºr die Webanwendung
- ‚úÖ Konfiguration von Netzwerk und Sicherheit
- ‚úÖ Bereitstellung des Anwendungscodes
- ‚úÖ Einrichtung von Monitoring und Protokollierung

2. **√úberwachen Sie den Fortschritt der Bereitstellung** und notieren Sie die erstellten Ressourcen.

### Schritt 2.3: √úberpr√ºfen Sie Ihre Bereitstellung

1. **√úberpr√ºfen Sie die bereitgestellten Ressourcen:**
```bash
azd show
```

2. **√ñffnen Sie die bereitgestellte Anwendung:**
```bash
azd show --output json | grep "webAppUrl"
```

3. **Testen Sie die KI-Funktionalit√§t:**
   - Navigieren Sie zur Webanwendung
   - Probieren Sie Beispielabfragen aus
   - √úberpr√ºfen Sie, ob die KI-Antworten funktionieren

### **Lab-√úbung 2.1: Fehlerbehebung √ºben**

**Szenario**: Ihre Bereitstellung war erfolgreich, aber die KI reagiert nicht.

**H√§ufige Probleme, die Sie √ºberpr√ºfen sollten:**
1. **OpenAI-API-Schl√ºssel**: √úberpr√ºfen Sie, ob sie korrekt gesetzt sind
2. **Modellverf√ºgbarkeit**: Pr√ºfen Sie, ob Ihr Modell in der Region unterst√ºtzt wird
3. **Netzwerkverbindung**: Stellen Sie sicher, dass die Dienste kommunizieren k√∂nnen
4. **RBAC-Berechtigungen**: √úberpr√ºfen Sie, ob die App auf OpenAI zugreifen kann

**Debugging-Befehle:**
```bash
# √úberpr√ºfen Sie Umgebungsvariablen
azd env get-values

# Bereitstellungsprotokolle anzeigen
az webapp log tail --name YOUR_APP_NAME --resource-group YOUR_RG

# √úberpr√ºfen Sie den Bereitstellungsstatus von OpenAI
az cognitiveservices account deployment list --name YOUR_OPENAI_NAME --resource-group YOUR_RG
```

## Modul 3: KI-Anwendungen an Ihre Bed√ºrfnisse anpassen

### Schritt 3.1: Die KI-Konfiguration √§ndern

1. **Aktualisieren Sie das OpenAI-Modell:**
```bash
# Wechseln Sie zu einem anderen Modell (falls in Ihrer Region verf√ºgbar)
azd env set AZURE_OPENAI_MODEL gpt-4

# Erneut bereitstellen mit der neuen Konfiguration
azd deploy
```

2. **F√ºgen Sie zus√§tzliche KI-Dienste hinzu:**

Bearbeiten Sie `infra/main.bicep`, um Document Intelligence hinzuzuf√ºgen:

```bicep
// Add to main.bicep
resource documentIntelligence 'Microsoft.CognitiveServices/accounts@2023-05-01' = {
  name: 'doc-intel-${uniqueString(resourceGroup().id)}'
  location: location
  kind: 'FormRecognizer'
  sku: {
    name: 'F0'  // Free tier for workshop
  }
  properties: {
    customSubDomainName: 'doc-intel-${uniqueString(resourceGroup().id)}'
  }
}
```

### Schritt 3.2: Umgebungsspezifische Konfigurationen

**Best Practice**: Unterschiedliche Konfigurationen f√ºr Entwicklung und Produktion.

1. **Erstellen Sie eine Produktionsumgebung:**
```bash
azd env new myai-production
```

2. **Setzen Sie produktspezifische Parameter:**
```bash
# Die Produktion verwendet typischerweise h√∂here SKUs
azd env set AZURE_OPENAI_SKU S0
azd env set AZURE_SEARCH_SKU standard

# Zus√§tzliche Sicherheitsfunktionen aktivieren
azd env set ENABLE_PRIVATE_ENDPOINTS true
```

### **Lab-√úbung 3.1: Kostenoptimierung**

**Herausforderung**: Konfigurieren Sie die Vorlage f√ºr eine kosteng√ºnstige Entwicklung.

**Aufgaben:**
1. Identifizieren Sie, welche SKUs auf kostenlose/basische Stufen gesetzt werden k√∂nnen
2. Konfigurieren Sie Umgebungsvariablen f√ºr minimale Kosten
3. Stellen Sie bereit und vergleichen Sie die Kosten mit der Produktionskonfiguration

**L√∂sungshinweise:**
- Verwenden Sie die F0 (kostenlose) Stufe f√ºr Cognitive Services, wenn m√∂glich
- Verwenden Sie die Basic-Stufe f√ºr den Suchdienst in der Entwicklung
- Ziehen Sie den Verbrauchsplan f√ºr Funktionen in Betracht

## Modul 4: Sicherheit und Best Practices f√ºr die Produktion

### Schritt 4.1: Sicheres Anmeldeinformationsmanagement

**Aktuelle Herausforderung**: Viele KI-Apps codieren API-Schl√ºssel hart oder verwenden unsichere Speicherorte.

**AZD-L√∂sung**: Managed Identity + Key Vault-Integration.

1. **√úberpr√ºfen Sie die Sicherheitskonfiguration in Ihrer Vorlage:**
```bash
# Suchen Sie nach Key Vault- und Managed Identity-Konfiguration
grep -r "keyVault\|managedIdentity" infra/
```

2. **√úberpr√ºfen Sie, ob Managed Identity funktioniert:**
```bash
# √úberpr√ºfen Sie, ob die Webanwendung die richtige Identit√§tskonfiguration hat
az webapp identity show --name YOUR_APP_NAME --resource-group YOUR_RG
```

### Schritt 4.2: Netzwerksicherheit

1. **Private Endpunkte aktivieren** (falls noch nicht konfiguriert):

F√ºgen Sie Ihrer Bicep-Vorlage hinzu:
```bicep
// Private endpoint for OpenAI
resource openAIPrivateEndpoint 'Microsoft.Network/privateEndpoints@2023-04-01' = {
  name: 'pe-openai-${uniqueString(resourceGroup().id)}'
  location: location
  properties: {
    subnet: {
      id: vnet.properties.subnets[0].id
    }
    privateLinkServiceConnections: [
      {
        name: 'openai-connection'
        properties: {
          privateLinkServiceId: openAIAccount.id
          groupIds: ['account']
        }
      }
    ]
  }
}
```

### Schritt 4.3: Monitoring und Beobachtbarkeit

1. **Application Insights konfigurieren:**
```bash
# Application Insights sollte automatisch konfiguriert werden
# √úberpr√ºfen Sie die Konfiguration:
az monitor app-insights component show --app YOUR_APP_NAME --resource-group YOUR_RG
```

2. **KI-spezifisches Monitoring einrichten:**

F√ºgen Sie benutzerdefinierte Metriken f√ºr KI-Operationen hinzu:
```bicep
// In your web app configuration
resource webApp 'Microsoft.Web/sites@2023-01-01' = {
  properties: {
    siteConfig: {
      appSettings: [
        {
          name: 'APPLICATIONINSIGHTS_CONNECTION_STRING'
          value: applicationInsights.properties.ConnectionString
        }
        {
          name: 'OPENAI_MONITOR_ENABLED'
          value: 'true'
        }
      ]
    }
  }
}
```

### **Lab-√úbung 4.1: Sicherheitspr√ºfung**

**Aufgabe**: √úberpr√ºfen Sie Ihre Bereitstellung auf Sicherheits-Best-Practices.

**Checkliste:**
- [ ] Keine hartcodierten Geheimnisse im Code oder in der Konfiguration
- [ ] Managed Identity f√ºr die Authentifizierung zwischen Diensten verwendet
- [ ] Key Vault speichert sensible Konfigurationen
- [ ] Netzwerkzugriff ist ordnungsgem√§√ü eingeschr√§nkt
- [ ] Monitoring und Protokollierung sind aktiviert

## Modul 5: Ihre eigene KI-Anwendung konvertieren

### Schritt 5.1: Bewertungsbogen

**Bevor Sie Ihre App konvertieren**, beantworten Sie diese Fragen:

1. **Anwendungsarchitektur:**
   - Welche KI-Dienste verwendet Ihre App?
   - Welche Rechenressourcen ben√∂tigt sie?
   - Ben√∂tigt sie eine Datenbank?
   - Welche Abh√§ngigkeiten bestehen zwischen den Diensten?

2. **Sicherheitsanforderungen:**
   - Welche sensiblen Daten verarbeitet Ihre App?
   - Welche Compliance-Anforderungen haben Sie?
   - Ben√∂tigen Sie ein privates Netzwerk?

3. **Skalierungsanforderungen:**
   - Welche Last wird erwartet?
   - Ben√∂tigen Sie Auto-Scaling?
   - Gibt es regionale Anforderungen?

### Schritt 5.2: Erstellen Sie Ihre AZD-Vorlage

**Folgen Sie diesem Muster, um Ihre App zu konvertieren:**

1. **Erstellen Sie die Grundstruktur:**
```bash
mkdir my-ai-app-azd
cd my-ai-app-azd

# AZD-Vorlage initialisieren
azd init --template minimal
```

2. **Erstellen Sie azure.yaml:**
```yaml
# Metadata
name: my-ai-app
metadata:
  template: my-ai-app-template@0.0.1-beta

# Services definition
services:
  api:
    project: ./api
    host: containerapp
  web:
    project: ./web
    host: staticwebapp
    
# Hooks for custom deployment logic  
hooks:
  predeploy:
    shell: sh
    run: echo "Preparing AI models..."
```

3. **Erstellen Sie Infrastrukturvorlagen:**

**infra/main.bicep** - Hauptvorlage:
```bicep
@description('Primary location for all resources')
param location string = resourceGroup().location

@description('Name of the OpenAI service')
param openAIServiceName string = 'openai-${uniqueString(resourceGroup().id)}'

// Your AI services here
module openAI 'modules/openai.bicep' = {
  name: 'openai'
  params: {
    name: openAIServiceName
    location: location
  }
}
```

**infra/modules/openai.bicep** - OpenAI-Modul:
```bicep
@description('Name of the OpenAI service')
param name string

@description('Location for the OpenAI service')
param location string

resource openAIAccount 'Microsoft.CognitiveServices/accounts@2023-05-01' = {
  name: name
  location: location
  kind: 'OpenAI'
  sku: {
    name: 'S0'
  }
  properties: {
    customSubDomainName: name
  }
}

output endpoint string = openAIAccount.properties.endpoint
output name string = openAIAccount.name
```

### **Lab-√úbung 5.1: Vorlagenerstellungs-Herausforderung**

**Herausforderung**: Erstellen Sie eine AZD-Vorlage f√ºr eine Dokumentenverarbeitungs-KI-App.

**Anforderungen:**
- Azure OpenAI f√ºr Inhaltsanalyse
- Document Intelligence f√ºr OCR
- Speicherkonto f√ºr Dokumenten-Uploads
- Function App f√ºr Verarbeitungslogik
- Web-App f√ºr Benutzeroberfl√§che

**Bonuspunkte:**
- F√ºgen Sie eine ordnungsgem√§√üe Fehlerbehandlung hinzu
- Integrieren Sie eine Kostensch√§tzung
- Richten Sie Monitoring-Dashboards ein

## Modul 6: H√§ufige Probleme beheben

### H√§ufige Bereitstellungsprobleme

#### Problem 1: OpenAI-Dienstkontingent √ºberschritten
**Symptome:** Bereitstellung schl√§gt mit Kontingentfehler fehl
**L√∂sungen:**
```bash
# √úberpr√ºfen Sie die aktuellen Kontingente
az cognitiveservices usage list --location eastus

# Fordern Sie eine Kontingenterh√∂hung an oder versuchen Sie eine andere Region
azd env set AZURE_LOCATION westus2
azd up
```

#### Problem 2: Modell in Region nicht verf√ºgbar
**Symptome:** KI-Antworten schlagen fehl oder Modellbereitstellungsfehler
**L√∂sungen:**
```bash
# Verf√ºgbarkeit des Modells nach Region pr√ºfen
az cognitiveservices model list --location eastus

# Auf verf√ºgbares Modell aktualisieren
azd env set AZURE_OPENAI_MODEL gpt-35-turbo-16k
azd deploy
```

#### Problem 3: Berechtigungsprobleme
**Symptome:** 403 Forbidden-Fehler beim Aufrufen von KI-Diensten
**L√∂sungen:**
```bash
# √úberpr√ºfen Sie die Rollenverteilungen
az role assignment list --scope /subscriptions/YOUR_SUB/resourceGroups/YOUR_RG

# Fehlende Rollen hinzuf√ºgen
az role assignment create \
  --assignee YOUR_PRINCIPAL_ID \
  --role "Cognitive Services OpenAI User" \
  --scope /subscriptions/YOUR_SUB/resourceGroups/YOUR_RG
```

### Leistungsprobleme

#### Problem 4: Langsame KI-Antworten
**Untersuchungsschritte:**
1. √úberpr√ºfen Sie Application Insights auf Leistungsmetriken
2. √úberpr√ºfen Sie OpenAI-Dienstmetriken im Azure-Portal
3. √úberpr√ºfen Sie Netzwerkverbindung und Latenz

**L√∂sungen:**
- Implementieren Sie Caching f√ºr h√§ufige Abfragen
- Verwenden Sie ein geeignetes OpenAI-Modell f√ºr Ihren Anwendungsfall
- Ziehen Sie Lese-Replikate f√ºr Szenarien mit hoher Last in Betracht

### **Lab-√úbung 6.1: Debugging-Herausforderung**

**Szenario**: Ihre Bereitstellung war erfolgreich, aber die Anwendung gibt 500-Fehler zur√ºck.

**Debugging-Aufgaben:**
1. √úberpr√ºfen Sie Anwendungsprotokolle
2. √úberpr√ºfen Sie die Dienstkonnektivit√§t
3. Testen Sie die Authentifizierung
4. √úberpr√ºfen Sie die Konfiguration

**Zu verwendende Tools:**
- `azd show` f√ºr eine √úbersicht der Bereitstellung
- Azure-Portal f√ºr detaillierte Dienstprotokolle
- Application Insights f√ºr Anwendungstelemetrie

## Modul 7: Monitoring und Optimierung

### Schritt 7.1: Umfassendes Monitoring einrichten

1. **Erstellen Sie benutzerdefinierte Dashboards:**

Navigieren Sie zum Azure-Portal und erstellen Sie ein Dashboard mit:
- OpenAI-Anfrageanzahl und Latenz
- Anwendungsfehlerraten
- Ressourcenauslastung
- Kosten√ºberwachung

2. **Richten Sie Warnungen ein:**
```bash
# Warnung bei hoher Fehlerquote
az monitor metrics alert create \
  --name "AI-App-High-Error-Rate" \
  --resource-group YOUR_RG \
  --target-resource-id YOUR_APP_ID \
  --condition "avg Http5xx greater than 10" \
  --description "Alert when error rate is high"
```

### Schritt 7.2: Kostenoptimierung

1. **Analysieren Sie die aktuellen Kosten:**
```bash
# Verwenden Sie Azure CLI, um Kostendaten abzurufen
az consumption usage list --start-date 2024-01-01 --end-date 2024-01-31
```

2. **Implementieren Sie Kostenkontrollen:**
- Richten Sie Budgetwarnungen ein
- Verwenden Sie Auto-Scaling-Richtlinien
- Implementieren Sie Anfrage-Caching
- √úberwachen Sie die Token-Nutzung f√ºr OpenAI

### **Lab-√úbung 7.1: Leistungsoptimierung**

**Aufgabe**: Optimieren Sie Ihre KI-Anwendung sowohl f√ºr Leistung als auch f√ºr Kosten.

**Zu verbessernde Metriken:**
- Reduzieren Sie die durchschnittliche Antwortzeit um 20 %
- Senken Sie die monatlichen Kosten um 15 %
- Halten Sie eine Verf√ºgbarkeit von 99,9 % aufrecht

**Strategien zum Ausprobieren:**
- Implementieren Sie Antwort-Caching
- Optimieren Sie Prompts f√ºr Token-Effizienz
- Verwenden Sie geeignete Compute-SKUs
- Richten Sie ein korrektes Auto-Scaling ein

## Abschlussherausforderung: End-to-End-Implementierung

### Herausforderungsszenario

Sie sind beauftragt, einen produktionsreifen KI-gest√ºtzten Kundenservice-Chatbot mit folgenden Anforderungen zu erstellen:

**Funktionale Anforderungen:**
- Weboberfl√§che f√ºr Kundeninteraktionen
- Integration mit Azure OpenAI f√ºr Antworten
- Dokumentensuche mit Cognitive Search
- Integration mit bestehender Kundendatenbank
- Mehrsprachige Unterst√ºtzung

**Nicht-funktionale Anforderungen:**
- Bew√§ltigung von 1000 gleichzeitigen Benutzern
- 99,9 % Verf√ºgbarkeits-SLA
- SOC 2-Konformit√§t
- Kosten unter 500 $/Monat
- Bereitstellung in mehreren Umgebungen (Entwicklung, Staging, Produktion)

### Implementierungsschritte

1. **Entwerfen Sie die Architektur**
2. **Erstellen Sie die AZD-Vorlage**
3. **Implementieren Sie Sicherheitsma√ünahmen**
4. **Richten Sie Monitoring und Warnungen ein**
5. **Erstellen Sie Bereitstellungspipelines**
6. **Dokumentieren Sie die L√∂sung**

### Bewertungskriterien

- ‚úÖ **Funktionalit√§t**: Werden alle Anforderungen erf√ºllt?
- ‚úÖ **Sicherheit**: Werden Best Practices umgesetzt?
- ‚úÖ **Skalierbarkeit**: Kann die L√∂sung die Last bew√§ltigen?
- ‚úÖ **Wartbarkeit**: Ist der Code und die Infrastruktur gut organisiert?
- ‚úÖ **Kosten**: Bleibt die L√∂sung im Budget?

## Zus√§tzliche Ressourcen

### Microsoft-Dokumentation
- [Azure Developer CLI-Dokumentation](https://learn.microsoft.com/azure/developer/azure-developer-cli/)
- [Azure OpenAI-Dienst-Dokumentation](https://learn.microsoft.com/azure/cognitive-services/openai/)
- [Microsoft Foundry-Dokumentation](https://learn.microsoft.com/azure/ai-studio/)

### Beispielvorlagen
- [Azure OpenAI Chat App](https://github.com/Azure-Samples/azure-search-openai-demo)
- [OpenAI Chat App Quickstart](https://github.com/Azure-Samples/openai-chat-app-quickstart)
- [Contoso Chat](https://github.com/Azure-Samples/contoso-chat)

### Community-Ressourcen
- [Microsoft Foundry Discord](https://discord.gg/microsoft-azure)
- [Azure Developer CLI GitHub](https://github.com/Azure/azure-dev)
- [Awesome AZD Templates](https://azure.github.io/awesome-azd/)

## üéì Abschlusszertifikat
Herzlichen Gl√ºckwunsch! Sie haben das AI Workshop Lab abgeschlossen. Sie sollten nun in der Lage sein:

- ‚úÖ Bestehende KI-Anwendungen in AZD-Vorlagen umzuwandeln
- ‚úÖ Produktionsreife KI-Anwendungen bereitzustellen
- ‚úÖ Sicherheitsbest Practices f√ºr KI-Workloads umzusetzen
- ‚úÖ Die Leistung von KI-Anwendungen zu √ºberwachen und zu optimieren
- ‚úÖ H√§ufige Bereitstellungsprobleme zu beheben

### N√§chste Schritte
1. Wenden Sie diese Muster auf Ihre eigenen KI-Projekte an
2. Tragen Sie Vorlagen zur Community bei
3. Treten Sie dem Microsoft Foundry Discord bei, um fortlaufende Unterst√ºtzung zu erhalten
4. Erkunden Sie fortgeschrittene Themen wie Multi-Region-Bereitstellungen

---

**Workshop-Feedback**: Helfen Sie uns, diesen Workshop zu verbessern, indem Sie Ihre Erfahrungen im [Microsoft Foundry Discord #Azure-Kanal](https://discord.gg/microsoft-azure) teilen.

---

**Kapitel√ºbersicht:**
- **üìö Kurs√ºbersicht**: [AZD f√ºr Einsteiger](../../README.md)
- **üìñ Aktuelles Kapitel**: Kapitel 2 - KI-First-Entwicklung
- **‚¨ÖÔ∏è Vorheriges**: [Bereitstellung von KI-Modellen](ai-model-deployment.md)
- **‚û°Ô∏è N√§chstes**: [Best Practices f√ºr Produktions-KI](production-ai-practices.md)
- **üöÄ N√§chstes Kapitel**: [Kapitel 3: Konfiguration](../getting-started/configuration.md)

**Brauchen Sie Hilfe?** Treten Sie unserer Community bei, um Unterst√ºtzung und Diskussionen zu AZD und KI-Bereitstellungen zu erhalten.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-√úbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, beachten Sie bitte, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache sollte als ma√ügebliche Quelle betrachtet werden. F√ºr kritische Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die aus der Nutzung dieser √úbersetzung entstehen.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->