# KI-Workshop Labor: Machen Sie Ihre KI-L√∂sungen AZD-bereitstellbar

**Chapter Navigation:**
- **üìö Course Home**: [AZD For Beginners](../../README.md)
- **üìñ Current Chapter**: Kapitel 2 - KI-First-Entwicklung
- **‚¨ÖÔ∏è Previous**: [AI Model Deployment](ai-model-deployment.md)
- **‚û°Ô∏è Next**: [Production AI Best Practices](production-ai-practices.md)
- **üöÄ Next Chapter**: [Chapter 3: Configuration](../chapter-03-configuration/configuration.md)

## Workshop Overview

Dieses praktische Labor f√ºhrt Entwickler durch den Prozess, eine vorhandene KI-Vorlage zu √ºbernehmen und sie mit Azure Developer CLI (AZD) bereitzustellen. Sie lernen grundlegende Muster f√ºr produktionsreife KI-Bereitstellungen mit Microsoft Foundry-Diensten kennen.

**Dauer:** 2-3 Stunden  
**Level:** Mittelstufe  
**Voraussetzungen:** Grundlegende Azure-Kenntnisse, Vertrautheit mit KI/ML-Konzepten

## üéì Lernziele

Am Ende dieses Workshops werden Sie in der Lage sein:
- ‚úÖ Eine vorhandene KI-Anwendung in AZD-Vorlagen zu konvertieren
- ‚úÖ Microsoft Foundry-Dienste mit AZD zu konfigurieren
- ‚úÖ Sichere Anmeldeinformationsverwaltung f√ºr KI-Dienste zu implementieren
- ‚úÖ Produktionsreife KI-Anwendungen mit Monitoring bereitzustellen
- ‚úÖ H√§ufige Probleme bei KI-Bereitstellungen zu beheben

## Voraussetzungen

### Erforderliche Werkzeuge
- [Azure Developer CLI](https://learn.microsoft.com/azure/developer/azure-developer-cli/install-azd) installiert
- [Azure CLI](https://docs.microsoft.com/cli/azure/install-azure-cli) installiert
- [Git](https://git-scm.com/) installiert
- Code-Editor (VS Code empfohlen)

### Azure-Ressourcen
- Azure-Abonnement mit Contributor-Berechtigungen
- Zugang zu Azure OpenAI-Diensten (oder M√∂glichkeit, Zugang anzufordern)
- Berechtigung zum Erstellen von Ressourcengruppen

### Fachliche Voraussetzungen
- Grundlegendes Verst√§ndnis der Azure-Dienste
- Vertrautheit mit Kommandozeilenoberfl√§chen
- Grundlegende KI/ML-Konzepte (APIs, Modelle, Prompts)

## Labor-Einrichtung

### Schritt 1: Umgebung vorbereiten

1. **√úberpr√ºfen Sie die Tool-Installationen:**
```bash
# √úberpr√ºfe die AZD-Installation
azd version

# √úberpr√ºfe die Azure CLI
az --version

# Bei Azure anmelden
az login
azd auth login
```

2. **Klonen Sie das Workshop-Repository:**
```bash
git clone https://github.com/Azure-Samples/azure-search-openai-demo
cd azure-search-openai-demo
```

## Modul 1: Verst√§ndnis der AZD-Struktur f√ºr KI-Anwendungen

### Aufbau einer KI-AZD-Vorlage

Erkunden Sie die Schl√ºsseldokumente in einer KI-fertigen AZD-Vorlage:

```
azure-search-openai-demo/
‚îú‚îÄ‚îÄ azure.yaml              # AZD configuration
‚îú‚îÄ‚îÄ infra/                   # Infrastructure as Code
‚îÇ   ‚îú‚îÄ‚îÄ main.bicep          # Main infrastructure template
‚îÇ   ‚îú‚îÄ‚îÄ main.parameters.json # Environment parameters
‚îÇ   ‚îî‚îÄ‚îÄ modules/            # Reusable Bicep modules
‚îÇ       ‚îú‚îÄ‚îÄ openai.bicep    # Azure OpenAI configuration
‚îÇ       ‚îú‚îÄ‚îÄ search.bicep    # Cognitive Search setup
‚îÇ       ‚îî‚îÄ‚îÄ webapp.bicep    # Web app configuration
‚îú‚îÄ‚îÄ app/                    # Application code
‚îú‚îÄ‚îÄ scripts/               # Deployment scripts
‚îî‚îÄ‚îÄ .azure/               # AZD environment files
```

### **Labor√ºbung 1.1: Erkunden der Konfiguration**

1. **Untersuchen Sie die azure.yaml Datei:**
```bash
cat azure.yaml
```

**Worauf Sie achten sollten:**
- Dienstdefinitionen f√ºr KI-Komponenten
- Zuordnungen von Umgebungsvariablen
- Host-Konfigurationen

2. **√úberpr√ºfen Sie die main.bicep Infrastruktur:**
```bash
cat infra/main.bicep
```

**Wichtige KI-Muster zu identifizieren:**
- Bereitstellung des Azure OpenAI-Dienstes
- Integration von Cognitive Search
- Sichere Schl√ºsselverwaltung
- Netzwerk-Sicherheitskonfigurationen

### **Diskussionspunkt:** Warum diese Muster f√ºr KI wichtig sind

- **Dienstabh√§ngigkeiten**: KI-Apps ben√∂tigen oft mehrere koordinierte Dienste
- **Sicherheit**: API-Schl√ºssel und Endpunkte m√ºssen sicher verwaltet werden
- **Skalierbarkeit**: KI-Workloads haben besondere Skalierungsanforderungen
- **Kostenmanagement**: KI-Dienste k√∂nnen teuer werden, wenn sie nicht richtig konfiguriert sind

## Modul 2: Bereiten Sie Ihre erste KI-Anwendung bereit

### Schritt 2.1: Umgebung initialisieren

1. **Erstellen Sie eine neue AZD-Umgebung:**
```bash
azd env new myai-workshop
```

2. **Setzen Sie die erforderlichen Parameter:**
```bash
# Legen Sie Ihre bevorzugte Azure-Region fest
azd env set AZURE_LOCATION eastus

# Optional: Legen Sie ein bestimmtes OpenAI-Modell fest
azd env set AZURE_OPENAI_MODEL gpt-35-turbo
```

### Schritt 2.2: Infrastruktur und Anwendung bereitstellen

1. **Bereitstellen mit AZD:**
```bash
azd up
```

**Was w√§hrend `azd up` passiert:**
- ‚úÖ Stellt den Azure OpenAI-Dienst bereit
- ‚úÖ Erstellt den Cognitive Search-Dienst
- ‚úÖ Richtet einen App Service f√ºr die Webanwendung ein
- ‚úÖ Konfiguriert Netzwerk und Sicherheit
- ‚úÖ Stellt Anwendungscode bereit
- ‚úÖ Richtet Monitoring und Protokollierung ein

2. **√úberwachen Sie den Bereitstellungsfortschritt** und notieren Sie die erstellten Ressourcen.

### Schritt 2.3: Verifizieren Sie Ihre Bereitstellung

1. **Pr√ºfen Sie die bereitgestellten Ressourcen:**
```bash
azd show
```

2. **√ñffnen Sie die bereitgestellte Anwendung:**
```bash
azd show --output json | grep "webAppUrl"
```

3. **Testen Sie die KI-Funktionalit√§t:**
   - Navigieren Sie zur Webanwendung
   - Probieren Sie Beispielanfragen aus
   - Verifizieren Sie, dass KI-Antworten funktionieren

### **Labor√ºbung 2.1: Fehlerbehebungs√ºbung**

**Szenario**: Ihre Bereitstellung war erfolgreich, aber die KI antwortet nicht.

**H√§ufige Probleme, die Sie √ºberpr√ºfen sollten:**
1. **OpenAI API-Schl√ºssel**: √úberpr√ºfen Sie, ob sie korrekt gesetzt sind
2. **Modellverf√ºgbarkeit**: Pr√ºfen Sie, ob Ihre Region das Modell unterst√ºtzt
3. **Netzwerkkonnektivit√§t**: Stellen Sie sicher, dass die Dienste kommunizieren k√∂nnen
4. **RBAC-Berechtigungen**: √úberpr√ºfen Sie, ob die App auf OpenAI zugreifen kann

**Debugging-Befehle:**
```bash
# Umgebungsvariablen pr√ºfen
azd env get-values

# Bereitstellungsprotokolle anzeigen
az webapp log tail --name YOUR_APP_NAME --resource-group YOUR_RG

# OpenAI-Bereitstellungsstatus pr√ºfen
az cognitiveservices account deployment list --name YOUR_OPENAI_NAME --resource-group YOUR_RG
```

## Modul 3: Anpassen von KI-Anwendungen an Ihre Anforderungen

### Schritt 3.1: √Ñndern der KI-Konfiguration

1. **Aktualisieren Sie das OpenAI-Modell:**
```bash
# Wechseln Sie zu einem anderen Modell (falls in Ihrer Region verf√ºgbar)
azd env set AZURE_OPENAI_MODEL gpt-4

# Mit der neuen Konfiguration erneut bereitstellen
azd deploy
```

2. **F√ºgen Sie zus√§tzliche KI-Dienste hinzu:**

Bearbeiten Sie `infra/main.bicep`, um Document Intelligence hinzuzuf√ºgen:

```bicep
// Add to main.bicep
resource documentIntelligence 'Microsoft.CognitiveServices/accounts@2023-05-01' = {
  name: 'doc-intel-${uniqueString(resourceGroup().id)}'
  location: location
  kind: 'FormRecognizer'
  sku: {
    name: 'F0'  // Free tier for workshop
  }
  properties: {
    customSubDomainName: 'doc-intel-${uniqueString(resourceGroup().id)}'
  }
}
```

### Schritt 3.2: Umgebungsbezogene Konfigurationen

**Best Practice**: Unterschiedliche Konfigurationen f√ºr Entwicklung vs Produktion.

1. **Erstellen Sie eine Produktionsumgebung:**
```bash
azd env new myai-production
```

2. **Setzen Sie produktionsspezifische Parameter:**
```bash
# In der Produktion werden typischerweise h√∂here SKUs verwendet.
azd env set AZURE_OPENAI_SKU S0
azd env set AZURE_SEARCH_SKU standard

# Zus√§tzliche Sicherheitsfunktionen aktivieren
azd env set ENABLE_PRIVATE_ENDPOINTS true
```

### **Labor√ºbung 3.1: Kostenoptimierung**

**Herausforderung**: Konfigurieren Sie die Vorlage f√ºr kosteneffektive Entwicklung.

**Aufgaben:**
1. Identifizieren Sie, welche SKUs auf kostenlose/Basic-Stufen gesetzt werden k√∂nnen
2. Konfigurieren Sie Umgebungsvariablen f√ºr minimale Kosten
3. Bereitstellen und Kosten mit der Produktionskonfiguration vergleichen

**Hinweise zur L√∂sung:**
- Verwenden Sie nach M√∂glichkeit die F0 (kostenlose) Stufe f√ºr Cognitive Services
- Verwenden Sie die Basic-Stufe f√ºr den Search-Dienst in der Entwicklung
- Erw√§gen Sie die Verwendung des Consumption-Plans f√ºr Functions

## Modul 4: Sicherheit und Produktions-Best Practices

### Schritt 4.1: Sichere Anmeldeinformationsverwaltung

**Aktuelle Herausforderung**: Viele KI-Apps kodieren API-Schl√ºssel hart oder verwenden unsichere Speicher.

**AZD-L√∂sung**: Managed Identity + Key Vault-Integration.

1. **√úberpr√ºfen Sie die Sicherheitskonfiguration in Ihrer Vorlage:**
```bash
# Nach Key Vault- und Managed Identity-Konfiguration suchen
grep -r "keyVault\|managedIdentity" infra/
```

2. **Verifizieren Sie, dass Managed Identity funktioniert:**
```bash
# √úberpr√ºfen Sie, ob die Webanwendung die richtige Identit√§tskonfiguration hat
az webapp identity show --name YOUR_APP_NAME --resource-group YOUR_RG
```

### Schritt 4.2: Netzwerksicherheit

1. **Aktivieren Sie private Endpunkte** (falls noch nicht konfiguriert):

F√ºgen Sie Ihrem Bicep-Template hinzu:
```bicep
// Private endpoint for OpenAI
resource openAIPrivateEndpoint 'Microsoft.Network/privateEndpoints@2023-04-01' = {
  name: 'pe-openai-${uniqueString(resourceGroup().id)}'
  location: location
  properties: {
    subnet: {
      id: vnet.properties.subnets[0].id
    }
    privateLinkServiceConnections: [
      {
        name: 'openai-connection'
        properties: {
          privateLinkServiceId: openAIAccount.id
          groupIds: ['account']
        }
      }
    ]
  }
}
```

### Schritt 4.3: Monitoring und Beobachtbarkeit

1. **Konfigurieren Sie Application Insights:**
```bash
# Application Insights sollte automatisch konfiguriert werden
# √úberpr√ºfen Sie die Konfiguration:
az monitor app-insights component show --app YOUR_APP_NAME --resource-group YOUR_RG
```

2. **Richten Sie KI-spezifisches Monitoring ein:**

F√ºgen Sie benutzerdefinierte Metriken f√ºr KI-Operationen hinzu:
```bicep
// In your web app configuration
resource webApp 'Microsoft.Web/sites@2023-01-01' = {
  properties: {
    siteConfig: {
      appSettings: [
        {
          name: 'APPLICATIONINSIGHTS_CONNECTION_STRING'
          value: applicationInsights.properties.ConnectionString
        }
        {
          name: 'OPENAI_MONITOR_ENABLED'
          value: 'true'
        }
      ]
    }
  }
}
```

### **Labor√ºbung 4.1: Sicherheitspr√ºfung**

**Aufgabe**: √úberpr√ºfen Sie Ihre Bereitstellung auf Sicherheits-Best Practices.

**Checkliste:**
- [ ] Keine hartkodierten Geheimnisse im Code oder in der Konfiguration
- [ ] Managed Identity f√ºr Service-zu-Service-Authentifizierung verwendet
- [ ] Key Vault speichert sensitive Konfiguration
- [ ] Netzwerkzugriff ist angemessen eingeschr√§nkt
- [ ] Monitoring und Protokollierung sind aktiviert

## Modul 5: Konvertierung Ihrer eigenen KI-Anwendung

### Schritt 5.1: Bewertungs-Arbeitsblatt

**Bevor Sie Ihre App konvertieren**, beantworten Sie diese Fragen:

1. **Anwendungsarchitektur:**
   - Welche KI-Dienste verwendet Ihre App?
   - Welche Compute-Ressourcen ben√∂tigt sie?
   - Ben√∂tigt sie eine Datenbank?
   - Welche Abh√§ngigkeiten bestehen zwischen den Diensten?

2. **Sicherheitsanforderungen:**
   - Mit welchen sensiblen Daten arbeitet Ihre App?
   - Welche Compliance-Anforderungen haben Sie?
   - Ben√∂tigen Sie privates Networking?

3. **Skalierungsanforderungen:**
   - Wie hoch ist die erwartete Last?
   - Ben√∂tigen Sie Auto-Scaling?
   - Gibt es regionale Anforderungen?

### Schritt 5.2: Erstellen Sie Ihre AZD-Vorlage

**Folgen Sie diesem Muster, um Ihre App zu konvertieren:**

1. **Erstellen Sie die Grundstruktur:**
```bash
mkdir my-ai-app-azd
cd my-ai-app-azd

# AZD-Vorlage initialisieren
azd init --template minimal
```

2. **Erstellen Sie azure.yaml:**
```yaml
# Metadata
name: my-ai-app
metadata:
  template: my-ai-app-template@0.0.1-beta

# Services definition
services:
  api:
    project: ./api
    host: containerapp
  web:
    project: ./web
    host: staticwebapp
    
# Hooks for custom deployment logic  
hooks:
  predeploy:
    shell: sh
    run: echo "Preparing AI models..."
```

3. **Erstellen Sie Infrastrukturvorlagen:**

**infra/main.bicep** - Haupttemplate:
```bicep
@description('Primary location for all resources')
param location string = resourceGroup().location

@description('Name of the OpenAI service')
param openAIServiceName string = 'openai-${uniqueString(resourceGroup().id)}'

// Your AI services here
module openAI 'modules/openai.bicep' = {
  name: 'openai'
  params: {
    name: openAIServiceName
    location: location
  }
}
```

**infra/modules/openai.bicep** - OpenAI-Modul:
```bicep
@description('Name of the OpenAI service')
param name string

@description('Location for the OpenAI service')
param location string

resource openAIAccount 'Microsoft.CognitiveServices/accounts@2023-05-01' = {
  name: name
  location: location
  kind: 'OpenAI'
  sku: {
    name: 'S0'
  }
  properties: {
    customSubDomainName: name
  }
}

output endpoint string = openAIAccount.properties.endpoint
output name string = openAIAccount.name
```

### **Labor√ºbung 5.1: Template-Erstellungs-Herausforderung**

**Herausforderung**: Erstellen Sie eine AZD-Vorlage f√ºr eine Dokumentenverarbeitungs-KI-App.

**Anforderungen:**
- Azure OpenAI f√ºr Inhaltsanalyse
- Document Intelligence f√ºr OCR
- Storage Account f√ºr Dokument-Uploads
- Function App f√ºr Verarbeitungslogik
- Web-App f√ºr die Benutzeroberfl√§che

**Bonuspunkte:**
- F√ºgen Sie eine ordnungsgem√§√üe Fehlerbehandlung hinzu
- Einschlie√ülich Kostensch√§tzung
- Einrichten von Monitoring-Dashboards

## Modul 6: Fehlerbehebung bei h√§ufigen Problemen

### H√§ufige Bereitstellungsprobleme

#### Problem 1: OpenAI-Service-Quota √ºberschritten
**Symptome:** Bereitstellung schl√§gt mit Quota-Fehler fehl
**L√∂sungen:**
```bash
# Aktuelle Kontingente pr√ºfen
az cognitiveservices usage list --location eastus

# Kontingenterh√∂hung anfordern oder eine andere Region ausprobieren
azd env set AZURE_LOCATION westus2
azd up
```

#### Problem 2: Modell nicht in Region verf√ºgbar
**Symptome:** KI-Antworten schlagen fehl oder Modellbereitstellung meldet Fehler
**L√∂sungen:**
```bash
# Modellverf√ºgbarkeit nach Region pr√ºfen
az cognitiveservices model list --location eastus

# Auf verf√ºgbares Modell aktualisieren
azd env set AZURE_OPENAI_MODEL gpt-35-turbo-16k
azd deploy
```

#### Problem 3: Berechtigungsprobleme
**Symptome:** 403 Forbidden-Fehler beim Aufrufen von KI-Diensten
**L√∂sungen:**
```bash
# Rollenzuweisungen √ºberpr√ºfen
az role assignment list --scope /subscriptions/YOUR_SUB/resourceGroups/YOUR_RG

# Fehlende Rollen hinzuf√ºgen
az role assignment create \
  --assignee YOUR_PRINCIPAL_ID \
  --role "Cognitive Services OpenAI User" \
  --scope /subscriptions/YOUR_SUB/resourceGroups/YOUR_RG
```

### Performance-Probleme

#### Problem 4: Langsame KI-Antworten
**Untersuchungsschritte:**
1. √úberpr√ºfen Sie Application Insights auf Performance-Metriken
2. Pr√ºfen Sie OpenAI-Dienstmetriken im Azure-Portal
3. Verifizieren Sie Netzwerkverbindung und Latenz

**L√∂sungen:**
- Implementieren Sie Caching f√ºr h√§ufige Anfragen
- Verwenden Sie das geeignete OpenAI-Modell f√ºr Ihren Anwendungsfall
- Erw√§gen Sie Read-Replicas f√ºr hochbelastete Szenarien

### **Labor√ºbung 6.1: Debugging-Herausforderung**

**Szenario**: Ihre Bereitstellung war erfolgreich, aber die Anwendung gibt 500-Fehler zur√ºck.

**Debugging-Aufgaben:**
1. Pr√ºfen Sie Anwendungsprotokolle
2. Verifizieren Sie Dienstkonnektivit√§t
3. Testen Sie die Authentifizierung
4. √úberpr√ºfen Sie die Konfiguration

**Tools zur Verwendung:**
- `azd show` f√ºr Bereitstellungs√ºbersicht
- Azure-Portal f√ºr detaillierte Dienstprotokolle
- Application Insights f√ºr Anwendungs-Telemetrie

## Modul 7: Monitoring und Optimierung

### Schritt 7.1: Umfassendes Monitoring einrichten

1. **Erstellen Sie benutzerdefinierte Dashboards:**

Navigieren Sie zum Azure-Portal und erstellen Sie ein Dashboard mit:
- Anzahl und Latenz der OpenAI-Anfragen
- Anwendungsfehlerquoten
- Ressourcenauslastung
- Kostenverfolgung

2. **Richten Sie Alerts ein:**
```bash
# Alarm bei hoher Fehlerrate
az monitor metrics alert create \
  --name "AI-App-High-Error-Rate" \
  --resource-group YOUR_RG \
  --target-resource-id YOUR_APP_ID \
  --condition "avg Http5xx greater than 10" \
  --description "Alert when error rate is high"
```

### Schritt 7.2: Kostenoptimierung

1. **Analysieren Sie die aktuellen Kosten:**
```bash
# Verwenden Sie die Azure CLI, um Kostendaten abzurufen
az consumption usage list --start-date 2024-01-01 --end-date 2024-01-31
```

2. **Implementieren Sie Kostenkontrollen:**
- Richten Sie Budgetwarnungen ein
- Verwenden Sie Auto-Scaling-Richtlinien
- Implementieren Sie Request-Caching
- √úberwachen Sie Token-Nutzung f√ºr OpenAI

### **Labor√ºbung 7.1: Performance-Optimierung**

**Aufgabe**: Optimieren Sie Ihre KI-Anwendung sowohl f√ºr Leistung als auch f√ºr Kosten.

**Metriken zu verbessern:**
- Durchschnittliche Antwortzeit um 20% reduzieren
- Monatliche Kosten um 15% senken
- 99,9% Verf√ºgbarkeit beibehalten

**Strategien zum Ausprobieren:**
- Implementieren Sie Response-Caching
- Optimieren Sie Prompts f√ºr Token-Effizienz
- Verwenden Sie geeignete Compute-SKUs
- Richten Sie korrektes Auto-Scaling ein

## Abschlussherausforderung: Ende-zu-Ende-Implementierung

### Szenario der Herausforderung

Sie sollen einen produktionsreifen, KI-gest√ºtzten Kundenservice-Chatbot erstellen mit folgenden Anforderungen:

**Funktionale Anforderungen:**
- Weboberfl√§che f√ºr Kundeninteraktionen
- Integration mit Azure OpenAI f√ºr Antworten
- Dokumentensuche mit Cognitive Search
- Integration mit bestehender Kundendatenbank
- Mehrsprachige Unterst√ºtzung

**Nicht-funktionale Anforderungen:**
- Verarbeitung von 1000 gleichzeitigen Nutzern
- 99,9% Uptime-SLA
- SOC 2-Konformit√§t
- Kosten unter $500/Monat
- Bereitstellung in mehreren Umgebungen (dev, staging, prod)

### Implementierungsschritte

1. **Architektur entwerfen**
2. **AZD-Vorlage erstellen**
3. **Sicherheitsma√ünahmen implementieren**
4. **Monitoring und Alerting einrichten**
5. **Bereitstellungspipelines erstellen**
6. **L√∂sung dokumentieren**

### Bewertungskriterien

- ‚úÖ **Funktionalit√§t**: Erf√ºllt es alle Anforderungen?
- ‚úÖ **Sicherheit**: Sind Best Practices implementiert?
- ‚úÖ **Skalierbarkeit**: Kann es die Last bew√§ltigen?
- ‚úÖ **Wartbarkeit**: Ist Code und Infrastruktur gut organisiert?
- ‚úÖ **Kosten**: Bleibt es im Budget?

## Zus√§tzliche Ressourcen

### Microsoft-Dokumentation
- [Azure Developer CLI Documentation](https://learn.microsoft.com/azure/developer/azure-developer-cli/)
- [Azure OpenAI Service Documentation](https://learn.microsoft.com/azure/cognitive-services/openai/)
- [Microsoft Foundry Documentation](https://learn.microsoft.com/azure/ai-studio/)

### Beispielvorlagen
- [Azure OpenAI Chat App](https://github.com/Azure-Samples/azure-search-openai-demo)
- [OpenAI Chat App Quickstart](https://github.com/Azure-Samples/openai-chat-app-quickstart)
- [Contoso Chat](https://github.com/Azure-Samples/contoso-chat)

### Community-Ressourcen
- [Microsoft Foundry Discord](https://discord.gg/microsoft-azure)
- [Azure Developer CLI GitHub](https://github.com/Azure/azure-dev)
- [Awesome AZD Templates](https://azure.github.io/awesome-azd/)

## üéì Abschlusszertifikat
Herzlichen Gl√ºckwunsch! Sie haben das AI Workshop Lab abgeschlossen. Sie sollten jetzt in der Lage sein:

- ‚úÖ Vorhandene KI-Anwendungen in AZD-Vorlagen umwandeln
- ‚úÖ Produktionsreife KI-Anwendungen bereitstellen
- ‚úÖ Beste Sicherheitspraktiken f√ºr KI-Workloads implementieren
- ‚úÖ Die Leistung von KI-Anwendungen √ºberwachen und optimieren
- ‚úÖ H√§ufige Bereitstellungsprobleme beheben

### N√§chste Schritte
1. Wenden Sie diese Muster in Ihren eigenen KI-Projekten an
2. Teilen Sie Vorlagen mit der Community
3. Treten Sie dem Microsoft Foundry Discord f√ºr fortlaufende Unterst√ºtzung bei
4. Erkunden Sie fortgeschrittene Themen wie mehrregionale Bereitstellungen

---

**Workshop-Feedback**: Helfen Sie uns, diesen Workshop zu verbessern, indem Sie Ihre Erfahrungen im [Microsoft Foundry Discord #Azure-Kanal](https://discord.gg/microsoft-azure) teilen.

---

**Kapitel-Navigation:**
- **üìö Kurs√ºbersicht**: [AZD f√ºr Einsteiger](../../README.md)
- **üìñ Aktuelles Kapitel**: Kapitel 2 - KI-zentrierte Entwicklung
- **‚¨ÖÔ∏è Zur√ºck**: [Bereitstellung von KI-Modellen](ai-model-deployment.md)
- **‚û°Ô∏è Weiter**: [Best Practices f√ºr Produktions-KI](production-ai-practices.md)
- **üöÄ N√§chstes Kapitel**: [Kapitel 3: Konfiguration](../chapter-03-configuration/configuration.md)

**Ben√∂tigen Sie Hilfe?** Treten Sie unserer Community bei f√ºr Unterst√ºtzung und Diskussionen √ºber AZD- und KI-Bereitstellungen.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
Haftungsausschluss:
Dieses Dokument wurde mithilfe des KI-√úbersetzungsdienstes Co-op Translator (https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir um Genauigkeit bem√ºht sind, beachten Sie bitte, dass automatische √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache ist als ma√ügebliche Quelle zu betrachten. Bei wichtigen Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die sich aus der Verwendung dieser √úbersetzung ergeben.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->