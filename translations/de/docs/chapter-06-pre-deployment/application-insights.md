# Application Insights-Integration mit AZD

‚è±Ô∏è **Gesch√§tzte Zeit**: 40‚Äì50 Minuten | üí∞ **Kostenwirkung**: ~5‚Äì15 $/Monat | ‚≠ê **Komplexit√§t**: Mittel

**üìö Lernpfad:**
- ‚Üê Vorherige: [Vorabpr√ºfungen](preflight-checks.md) - Vorbereitungspr√ºfungen vor der Bereitstellung
- üéØ **Sie sind hier**: Application Insights-Integration (Monitoring, Telemetrie, Debugging)
- ‚Üí N√§chste: [Bereitstellungsanleitung](../chapter-04-infrastructure/deployment-guide.md) - In Azure bereitstellen
- üè† [Kurs√ºbersicht](../../README.md)

---

## Was Sie lernen werden

Durch Abschluss dieser Lektion werden Sie:
- Application Insights automatisch in AZD-Projekte integrieren
- Verteiltes Tracing f√ºr Microservices konfigurieren
- Benutzerdefinierte Telemetrie implementieren (Metriken, Ereignisse, Abh√§ngigkeiten)
- Live Metrics f√ºr Echtzeit√ºberwachung einrichten
- Alarme und Dashboards aus AZD-Bereitstellungen erstellen
- Produktionsprobleme mit Telemetrieabfragen debuggen
- Kosten- und Sampling-Strategien optimieren
- AI/LLM-Anwendungen √ºberwachen (Tokens, Latenz, Kosten)

## Warum Application Insights mit AZD wichtig ist

### Die Herausforderung: Observability in der Produktion

**Ohne Application Insights:**
```
‚ùå No visibility into production behavior
‚ùå Manual log aggregation across services
‚ùå Reactive debugging (wait for customer complaints)
‚ùå No performance metrics
‚ùå Cannot trace requests across services
‚ùå Unknown failure rates and bottlenecks
```

**Mit Application Insights + AZD:**
```
‚úÖ Automatic telemetry collection
‚úÖ Centralized logs from all services
‚úÖ Proactive issue detection
‚úÖ End-to-end request tracing
‚úÖ Performance metrics and insights
‚úÖ Real-time dashboards
‚úÖ AZD provisions everything automatically
```

**Analogie**: Application Insights ist wie ein "Black-Box"-Flugschreiber + Cockpit-Dashboard f√ºr Ihre Anwendung. Sie sehen in Echtzeit alles, was passiert, und k√∂nnen jeden Vorfall rekonstruieren.

---

## Architektur√ºberblick

### Application Insights in der AZD-Architektur

```mermaid
graph TB
    User[Benutzer/Client]
    App1[Container-App 1<br/>API-Gateway]
    App2[Container-App 2<br/>Produktservice]
    App3[Container-App 3<br/>Bestellservice]
    
    AppInsights[Application Insights<br/>Telemetrie-Hub]
    LogAnalytics[(Log Analytics<br/>Arbeitsbereich)]
    
    Portal[Azure-Portal<br/>Dashboards & Warnungen]
    Query[Kusto-Abfragen<br/>Benutzerdefinierte Analyse]
    
    User --> App1
    App1 --> App2
    App2 --> App3
    
    App1 -.->|Automatische Instrumentierung| AppInsights
    App2 -.->|Automatische Instrumentierung| AppInsights
    App3 -.->|Automatische Instrumentierung| AppInsights
    
    AppInsights --> LogAnalytics
    LogAnalytics --> Portal
    LogAnalytics --> Query
    
    style AppInsights fill:#9C27B0,stroke:#7B1FA2,stroke-width:3px,color:#fff
    style LogAnalytics fill:#4CAF50,stroke:#388E3C,stroke-width:3px,color:#fff
```
### Was automatisch √ºberwacht wird

| Telemetrie-Typ | Was er erfasst | Anwendungsfall |
|----------------|----------------|----------------|
| **Requests** | HTTP-Anfragen, Statuscodes, Dauer | API-Leistungs√ºberwachung |
| **Dependencies** | Externe Aufrufe (DB, APIs, Storage) | Engp√§sse identifizieren |
| **Exceptions** | Nicht abgefangene Fehler mit Stacktraces | Fehlerbehebung |
| **Custom Events** | Business-Ereignisse (Signup, Kauf) | Analytics und Funnels |
| **Metrics** | Performance-Counter, benutzerdefinierte Metriken | Kapazit√§tsplanung |
| **Traces** | Lognachrichten mit Schweregrad | Debugging und Auditing |
| **Availability** | Uptime- und Antwortzeit-Tests | SLA-√úberwachung |

---

## Voraussetzungen

### Erforderliche Tools

```bash
# Azure Developer CLI √ºberpr√ºfen
azd version
# ‚úÖ Erwartet: azd Version 1.0.0 oder h√∂her

# Azure CLI √ºberpr√ºfen
az --version
# ‚úÖ Erwartet: azure-cli 2.50.0 oder h√∂her
```

### Azure-Anforderungen

- Aktives Azure-Abonnement
- Berechtigungen zum Erstellen von:
  - Application Insights-Ressourcen
  - Log Analytics-Arbeitsbereichen
  - Container Apps
  - Ressourcengruppen

### Fachliche Voraussetzungen

Sie sollten abgeschlossen haben:
- [AZD Basics](../chapter-01-foundation/azd-basics.md) - Kernkonzepte von AZD
- [Configuration](../chapter-03-configuration/configuration.md) - Umgebungskonfiguration
- [First Project](../chapter-01-foundation/first-project.md) - Basisbereitstellung

---

## Lektion 1: Automatische Application Insights mit AZD

### Wie AZD Application Insights bereitstellt

AZD erstellt und konfiguriert Application Insights automatisch beim Deploy. Sehen wir uns an, wie das funktioniert.

### Projektstruktur

```
monitored-app/
‚îú‚îÄ‚îÄ azure.yaml                     # AZD configuration
‚îú‚îÄ‚îÄ infra/
‚îÇ   ‚îú‚îÄ‚îÄ main.bicep                # Main infrastructure
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ monitoring.bicep      # Application Insights + Log Analytics
‚îÇ   ‚îî‚îÄ‚îÄ app/
‚îÇ       ‚îî‚îÄ‚îÄ api.bicep             # Container App with monitoring
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ app.py                    # Application with telemetry
    ‚îú‚îÄ‚îÄ requirements.txt
    ‚îî‚îÄ‚îÄ Dockerfile
```

---

### Schritt 1: AZD konfigurieren (azure.yaml)

**Datei: `azure.yaml`**

```yaml
name: monitored-app
metadata:
  template: monitored-app@1.0.0

services:
  api:
    project: ./src
    language: python
    host: containerapp

# AZD automatically provisions monitoring!
```

**Das war's!** AZD erstellt Application Insights standardm√§√üig. F√ºr grundlegendes Monitoring ist keine zus√§tzliche Konfiguration erforderlich.

---

### Schritt 2: Monitoring-Infrastruktur (Bicep)

**Datei: `infra/core/monitoring.bicep`**

```bicep
param logAnalyticsName string
param applicationInsightsName string
param location string = resourceGroup().location
param tags object = {}

// Log Analytics Workspace (required for Application Insights)
resource logAnalytics 'Microsoft.OperationalInsights/workspaces@2022-10-01' = {
  name: logAnalyticsName
  location: location
  tags: tags
  properties: {
    sku: {
      name: 'PerGB2018'  // Pay-as-you-go pricing
    }
    retentionInDays: 30  // Keep logs for 30 days
    features: {
      enableLogAccessUsingOnlyResourcePermissions: true
    }
  }
}

// Application Insights
resource applicationInsights 'Microsoft.Insights/components@2020-02-02' = {
  name: applicationInsightsName
  location: location
  tags: tags
  kind: 'web'
  properties: {
    Application_Type: 'web'
    WorkspaceResourceId: logAnalytics.id
    IngestionMode: 'LogAnalytics'
    publicNetworkAccessForIngestion: 'Enabled'
    publicNetworkAccessForQuery: 'Enabled'
  }
}

// Outputs for Container Apps
output logAnalyticsWorkspaceId string = logAnalytics.id
output logAnalyticsWorkspaceName string = logAnalytics.name
output applicationInsightsConnectionString string = applicationInsights.properties.ConnectionString
output applicationInsightsInstrumentationKey string = applicationInsights.properties.InstrumentationKey
output applicationInsightsName string = applicationInsights.name
```

---

### Schritt 3: Container App mit Application Insights verbinden

**Datei: `infra/app/api.bicep`**

```bicep
param name string
param location string
param tags object = {}
param containerAppsEnvironmentName string
param applicationInsightsConnectionString string

resource containerApp 'Microsoft.App/containerApps@2023-05-01' = {
  name: name
  location: location
  tags: tags
  properties: {
    configuration: {
      ingress: {
        external: true
        targetPort: 8000
      }
      secrets: [
        {
          name: 'appinsights-connection-string'
          value: applicationInsightsConnectionString
        }
      ]
    }
    template: {
      containers: [
        {
          name: 'api'
          image: 'myregistry.azurecr.io/api:latest'
          resources: {
            cpu: json('0.5')
            memory: '1Gi'
          }
          env: [
            {
              name: 'APPLICATIONINSIGHTS_CONNECTION_STRING'
              secretRef: 'appinsights-connection-string'
            }
            {
              name: 'APPLICATIONINSIGHTS_ENABLED'
              value: 'true'
            }
          ]
        }
      ]
    }
  }
}

output uri string = 'https://${containerApp.properties.configuration.ingress.fqdn}'
```

---

### Schritt 4: Anwendungs-Code mit Telemetrie

**Datei: `src/app.py`**

```python
from flask import Flask, request, jsonify
from opencensus.ext.azure.log_exporter import AzureLogHandler
from opencensus.ext.azure.trace_exporter import AzureExporter
from opencensus.ext.flask.flask_middleware import FlaskMiddleware
from opencensus.trace.samplers import ProbabilitySampler
import logging
import os

app = Flask(__name__)

# Application Insights-Verbindungszeichenfolge abrufen
connection_string = os.environ.get('APPLICATIONINSIGHTS_CONNECTION_STRING')

if connection_string:
    # Verteiltes Tracing konfigurieren
    middleware = FlaskMiddleware(
        app,
        exporter=AzureExporter(connection_string=connection_string),
        sampler=ProbabilitySampler(rate=1.0)  # 100% Sampling f√ºr die Entwicklung
    )
    
    # Protokollierung konfigurieren
    logger = logging.getLogger(__name__)
    logger.addHandler(AzureLogHandler(connection_string=connection_string))
    logger.setLevel(logging.INFO)
    
    print("‚úÖ Application Insights enabled")
else:
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)
    print("‚ö†Ô∏è Application Insights not configured")

@app.route('/health')
def health():
    logger.info('Health check endpoint called')
    return jsonify({'status': 'healthy', 'monitoring': 'enabled'})

@app.route('/api/products')
def get_products():
    logger.info('Fetching products')
    
    # Datenbankaufruf simulieren (wird automatisch als Abh√§ngigkeit verfolgt)
    products = [
        {'id': 1, 'name': 'Laptop', 'price': 999.99},
        {'id': 2, 'name': 'Mouse', 'price': 29.99},
        {'id': 3, 'name': 'Keyboard', 'price': 79.99}
    ]
    
    logger.info(f'Returned {len(products)} products')
    return jsonify(products)

@app.route('/api/error-test')
def error_test():
    """Test error tracking"""
    logger.error('Testing error tracking')
    try:
        raise ValueError('This is a test exception')
    except Exception as e:
        logger.exception('Exception occurred in error-test endpoint')
        return jsonify({'error': str(e)}), 500

@app.route('/api/slow')
def slow_endpoint():
    """Test performance tracking"""
    import time
    logger.info('Slow endpoint called')
    time.sleep(3)  # Langsame Operation simulieren
    logger.warning('Endpoint took 3 seconds to respond')
    return jsonify({'message': 'Slow operation completed'})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8000)
```

**Datei: `src/requirements.txt`**

```txt
Flask==3.0.0
opencensus-ext-azure==1.1.13
opencensus-ext-flask==0.8.1
gunicorn==21.2.0
```

---

### Schritt 5: Bereitstellen und Verifizieren

```bash
# AZD initialisieren
azd init

# Bereitstellen (richtet Application Insights automatisch ein)
azd up

# App-URL abrufen
APP_URL=$(azd env get-values | grep API_URL | cut -d '=' -f2 | tr -d '"')

# Telemetrie generieren
curl $APP_URL/health
curl $APP_URL/api/products
curl $APP_URL/api/error-test
curl $APP_URL/api/slow
```

**‚úÖ Erwartete Ausgabe:**
```json
{
  "status": "healthy",
  "monitoring": "enabled"
}
```

---

### Schritt 6: Telemetrie im Azure-Portal ansehen

```bash
# Details zu Application Insights abrufen
azd env get-values | grep APPLICATIONINSIGHTS

# Im Azure-Portal √∂ffnen
az monitor app-insights component show \
  --app $(azd env get-values | grep APPLICATIONINSIGHTS_NAME | cut -d '=' -f2 | tr -d '"') \
  --resource-group $(azd env get-values | grep AZURE_RESOURCE_GROUP | cut -d '=' -f2 | tr -d '"') \
  --query "appId" -o tsv
```

**Navigieren Sie im Azure-Portal ‚Üí Application Insights ‚Üí Transaktionssuche**

Sie sollten sehen:
- ‚úÖ HTTP-Anfragen mit Statuscodes
- ‚úÖ Anfragedauer (3+ Sekunden f√ºr `/api/slow`)
- ‚úÖ Ausnahmedetails von `/api/error-test`
- ‚úÖ Benutzerdefinierte Lognachrichten

---

## Lektion 2: Benutzerdefinierte Telemetrie und Ereignisse

### Gesch√§ftsereignisse erfassen

F√ºgen wir benutzerdefinierte Telemetrie f√ºr gesch√§ftskritische Ereignisse hinzu.

**Datei: `src/telemetry.py`**

```python
from opencensus.ext.azure import metrics_exporter
from opencensus.stats import aggregation as aggregation_module
from opencensus.stats import measure as measure_module
from opencensus.stats import stats as stats_module
from opencensus.stats import view as view_module
from opencensus.tags import tag_map as tag_map_module
from opencensus.ext.azure.log_exporter import AzureLogHandler
from opencensus.ext.azure.trace_exporter import AzureExporter
from opencensus.trace import tracer as tracer_module
import logging
import os

class TelemetryClient:
    """Custom telemetry client for Application Insights"""
    
    def __init__(self, connection_string=None):
        self.connection_string = connection_string or os.environ.get('APPLICATIONINSIGHTS_CONNECTION_STRING')
        
        if not self.connection_string:
            print("‚ö†Ô∏è Application Insights connection string not found")
            return
        
        # Logger einrichten
        self.logger = logging.getLogger(__name__)
        self.logger.addHandler(AzureLogHandler(connection_string=self.connection_string))
        self.logger.setLevel(logging.INFO)
        
        # Metrik-Exporter einrichten
        self.stats = stats_module.stats
        self.view_manager = self.stats.view_manager
        self.stats_recorder = self.stats.stats_recorder
        
        exporter = metrics_exporter.new_metrics_exporter(
            connection_string=self.connection_string
        )
        self.view_manager.register_exporter(exporter)
        
        # Tracer einrichten
        self.tracer = tracer_module.Tracer(
            exporter=AzureExporter(connection_string=self.connection_string)
        )
        
        print("‚úÖ Custom telemetry client initialized")
    
    def track_event(self, event_name: str, properties: dict = None):
        """Track custom business event"""
        properties = properties or {}
        self.logger.info(
            f"CustomEvent: {event_name}",
            extra={
                'custom_dimensions': {
                    'event_name': event_name,
                    **properties
                }
            }
        )
    
    def track_metric(self, metric_name: str, value: float, properties: dict = None):
        """Track custom metric"""
        properties = properties or {}
        self.logger.info(
            f"CustomMetric: {metric_name} = {value}",
            extra={
                'custom_dimensions': {
                    'metric_name': metric_name,
                    'value': value,
                    **properties
                }
            }
        )
    
    def track_dependency(self, name: str, dependency_type: str, duration: float, success: bool):
        """Track external dependency call"""
        with self.tracer.span(name=name) as span:
            span.add_attribute('dependency.type', dependency_type)
            span.add_attribute('duration', duration)
            span.add_attribute('success', success)

# Globaler Telemetrie-Client
telemetry = TelemetryClient()
```

### Anwendung mit benutzerdefinierten Ereignissen aktualisieren

**Datei: `src/app.py` (erweitert)**

```python
from flask import Flask, request, jsonify
from telemetry import telemetry
import time
import random

app = Flask(__name__)

@app.route('/api/purchase', methods=['POST'])
def purchase():
    """Track purchase event with custom telemetry"""
    data = request.json
    product_id = data.get('product_id')
    quantity = data.get('quantity', 1)
    price = data.get('price', 0)
    
    # Gesch√§ftsereignis verfolgen
    telemetry.track_event('Purchase', {
        'product_id': product_id,
        'quantity': quantity,
        'total_amount': price * quantity,
        'user_id': request.headers.get('X-User-Id', 'anonymous')
    })
    
    # Umsatzkennzahl verfolgen
    telemetry.track_metric('Revenue', price * quantity, {
        'product_id': product_id,
        'currency': 'USD'
    })
    
    return jsonify({
        'order_id': f'ORD-{random.randint(1000, 9999)}',
        'status': 'confirmed',
        'total': price * quantity
    })

@app.route('/api/search')
def search():
    """Track search queries"""
    query = request.args.get('q', '')
    
    start_time = time.time()
    
    # Suche simulieren (w√§re eine echte Datenbankabfrage)
    results = [{'id': 1, 'name': f'Result for {query}'}]
    
    duration = (time.time() - start_time) * 1000  # In ms umrechnen
    
    # Suchereignis verfolgen
    telemetry.track_event('Search', {
        'query': query,
        'results_count': len(results),
        'duration_ms': duration
    })
    
    # Leistungskennzahl der Suche verfolgen
    telemetry.track_metric('SearchDuration', duration, {
        'query_length': len(query)
    })
    
    return jsonify({'results': results, 'count': len(results)})

@app.route('/api/external-call')
def external_call():
    """Track external API dependency"""
    import requests
    
    start_time = time.time()
    success = True
    
    try:
        # Externe API-Anfrage simulieren
        response = requests.get('https://api.example.com/data', timeout=5)
        result = response.json()
    except Exception as e:
        success = False
        result = {'error': str(e)}
    
    duration = (time.time() - start_time) * 1000
    
    # Abh√§ngigkeit verfolgen
    telemetry.track_dependency(
        name='ExternalAPI',
        dependency_type='HTTP',
        duration=duration,
        success=success
    )
    
    return jsonify(result)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8000)
```

### Benutzerdefinierte Telemetrie testen

```bash
# Kaufereignis verfolgen
curl -X POST $APP_URL/api/purchase \
  -H "Content-Type: application/json" \
  -H "X-User-Id: user123" \
  -d '{"product_id": 1, "quantity": 2, "price": 29.99}'

# Suchereignis verfolgen
curl "$APP_URL/api/search?q=laptop"

# Externe Abh√§ngigkeit verfolgen
curl $APP_URL/api/external-call
```

**Im Azure-Portal anzeigen:**

Navigieren Sie zu Application Insights ‚Üí Logs und f√ºhren Sie dann aus:

```kusto
// View purchase events
traces
| where customDimensions.event_name == "Purchase"
| project 
    timestamp,
    product_id = tostring(customDimensions.product_id),
    total_amount = todouble(customDimensions.total_amount),
    user_id = tostring(customDimensions.user_id)
| order by timestamp desc

// View revenue metrics
traces
| where customDimensions.metric_name == "Revenue"
| summarize TotalRevenue = sum(todouble(customDimensions.value)) by bin(timestamp, 1h)
| render timechart

// View search performance
traces
| where customDimensions.event_name == "Search"
| summarize 
    AvgDuration = avg(todouble(customDimensions.duration_ms)),
    SearchCount = count()
  by bin(timestamp, 5m)
| render timechart
```

---

## Lektion 3: Verteiltes Tracing f√ºr Microservices

### Cross-Service Tracing aktivieren

F√ºr Microservices korreliert Application Insights Anfragen √ºber Services hinweg automatisch.

**Datei: `infra/main.bicep`**

```bicep
targetScope = 'subscription'

param environmentName string
param location string = 'eastus'

var tags = { 'azd-env-name': environmentName }

resource rg 'Microsoft.Resources/resourceGroups@2021-04-01' = {
  name: 'rg-${environmentName}'
  location: location
  tags: tags
}

// Monitoring (shared by all services)
module monitoring './core/monitoring.bicep' = {
  name: 'monitoring'
  scope: rg
  params: {
    logAnalyticsName: 'log-${environmentName}'
    applicationInsightsName: 'appi-${environmentName}'
    location: location
    tags: tags
  }
}

// API Gateway
module apiGateway './app/api-gateway.bicep' = {
  name: 'api-gateway'
  scope: rg
  params: {
    name: 'ca-gateway-${environmentName}'
    location: location
    tags: union(tags, { 'azd-service-name': 'gateway' })
    applicationInsightsConnectionString: monitoring.outputs.applicationInsightsConnectionString
  }
}

// Product Service
module productService './app/product-service.bicep' = {
  name: 'product-service'
  scope: rg
  params: {
    name: 'ca-products-${environmentName}'
    location: location
    tags: union(tags, { 'azd-service-name': 'products' })
    applicationInsightsConnectionString: monitoring.outputs.applicationInsightsConnectionString
  }
}

// Order Service
module orderService './app/order-service.bicep' = {
  name: 'order-service'
  scope: rg
  params: {
    name: 'ca-orders-${environmentName}'
    location: location
    tags: union(tags, { 'azd-service-name': 'orders' })
    applicationInsightsConnectionString: monitoring.outputs.applicationInsightsConnectionString
  }
}

output APPLICATIONINSIGHTS_CONNECTION_STRING string = monitoring.outputs.applicationInsightsConnectionString
output GATEWAY_URL string = apiGateway.outputs.uri
```

### End-to-End-Transaktion ansehen

```mermaid
sequenceDiagram
    participant User as Benutzer
    participant Gateway as API-Gateway<br/>(Trace-ID: abc123)
    participant Product as Produkt-Service<br/>(√úbergeordnete ID: abc123)
    participant Order as Bestell-Service<br/>(√úbergeordnete ID: abc123)
    participant AppInsights as Application Insights
    
    User->>Gateway: POST /api/checkout
    Note over Gateway: Trace starten: abc123
    Gateway->>AppInsights: Anfrage protokollieren (Trace-ID: abc123)
    
    Gateway->>Product: GET /products/123
    Note over Product: √úbergeordnete ID: abc123
    Product->>AppInsights: Abh√§ngigkeitsaufruf protokollieren
    Product-->>Gateway: Produktdetails
    
    Gateway->>Order: POST /orders
    Note over Order: √úbergeordnete ID: abc123
    Order->>AppInsights: Abh√§ngigkeitsaufruf protokollieren
    Order-->>Gateway: Bestellung erstellt
    
    Gateway-->>User: Checkout abgeschlossen
    Gateway->>AppInsights: Antwort protokollieren (Dauer: 450ms)
    
    Note over AppInsights: Korrelation anhand der Trace-ID
```
**End-to-End-Trace abfragen:**

```kusto
// Find complete request flow
let traceId = "abc123...";  // Get from response header
dependencies
| union requests
| where operation_Id == traceId
| project 
    timestamp,
    type = itemType,
    name,
    duration,
    success,
    cloud_RoleName
| order by timestamp asc
```

---

## Lektion 4: Live Metrics und Echtzeit√ºberwachung

### Live Metrics Stream aktivieren

Live Metrics liefert Echtzeit-Telemetrie mit <1 Sekunde Latenz.

**Zugriff auf Live Metrics:**

```bash
# Application Insights-Ressource abrufen
APPI_NAME=$(azd env get-values | grep APPLICATIONINSIGHTS_NAME | cut -d '=' -f2 | tr -d '"')

# Ressourcengruppe abrufen
RG_NAME=$(azd env get-values | grep AZURE_RESOURCE_GROUP | cut -d '=' -f2 | tr -d '"')

echo "Navigate to: Azure Portal ‚Üí Resource Groups ‚Üí $RG_NAME ‚Üí $APPI_NAME ‚Üí Live Metrics"
```

**Was Sie in Echtzeit sehen:**
- ‚úÖ Eingehende Anforderungsrate (requests/sec)
- ‚úÖ Ausgehende Abh√§ngigkeitsaufrufe
- ‚úÖ Anzahl der Ausnahmen
- ‚úÖ CPU- und Speicherverbrauch
- ‚úÖ Aktive Serveranzahl
- ‚úÖ Beispieltelemetrie

### Last zum Testen erzeugen

```bash
# Erzeugen Sie Last, um Live-Metriken zu sehen
for i in {1..100}; do
  curl $APP_URL/api/products &
  curl $APP_URL/api/search?q=test$i &
done

# Beobachten Sie Live-Metriken im Azure-Portal
# Sie sollten einen Anstieg der Anfragerate sehen
```

---

## Praktische √úbungen

### √úbung 1: Alarme einrichten ‚≠ê‚≠ê (Mittel)

**Ziel**: Erstellen Sie Alarme f√ºr hohe Fehlerraten und langsame Antworten.

**Schritte:**

1. **Alarm f√ºr Fehlerrate erstellen:**

```bash
# Application Insights-Ressourcen-ID abrufen
APPI_ID=$(az monitor app-insights component show \
  --app $APPI_NAME \
  --resource-group $RG_NAME \
  --query "id" -o tsv)

# Metrikwarnung f√ºr fehlgeschlagene Anfragen erstellen
az monitor metrics alert create \
  --name "High-Error-Rate" \
  --resource-group $RG_NAME \
  --scopes $APPI_ID \
  --condition "count requests/failed > 10" \
  --window-size 5m \
  --evaluation-frequency 1m \
  --description "Alert when error rate exceeds 10 per 5 minutes"
```

2. **Alarm f√ºr langsame Antworten erstellen:**

```bash
az monitor metrics alert create \
  --name "Slow-Responses" \
  --resource-group $RG_NAME \
  --scopes $APPI_ID \
  --condition "avg requests/duration > 3000" \
  --window-size 5m \
  --evaluation-frequency 1m \
  --description "Alert when average response time exceeds 3 seconds"
```

3. **Alarm via Bicep erstellen (bevorzugt f√ºr AZD):**

**Datei: `infra/core/alerts.bicep`**

```bicep
param applicationInsightsId string
param actionGroupId string = ''
param location string = resourceGroup().location

// High error rate alert
resource errorRateAlert 'Microsoft.Insights/metricAlerts@2018-03-01' = {
  name: 'high-error-rate'
  location: 'global'
  properties: {
    description: 'Alert when error rate exceeds threshold'
    severity: 2
    enabled: true
    scopes: [
      applicationInsightsId
    ]
    evaluationFrequency: 'PT1M'
    windowSize: 'PT5M'
    criteria: {
      'odata.type': 'Microsoft.Azure.Monitor.SingleResourceMultipleMetricCriteria'
      allOf: [
        {
          name: 'Error rate'
          metricName: 'requests/failed'
          operator: 'GreaterThan'
          threshold: 10
          timeAggregation: 'Count'
        }
      ]
    }
    actions: actionGroupId != '' ? [
      {
        actionGroupId: actionGroupId
      }
    ] : []
  }
}

// Slow response alert
resource slowResponseAlert 'Microsoft.Insights/metricAlerts@2018-03-01' = {
  name: 'slow-responses'
  location: 'global'
  properties: {
    description: 'Alert when response time is too high'
    severity: 3
    enabled: true
    scopes: [
      applicationInsightsId
    ]
    evaluationFrequency: 'PT1M'
    windowSize: 'PT5M'
    criteria: {
      'odata.type': 'Microsoft.Azure.Monitor.SingleResourceMultipleMetricCriteria'
      allOf: [
        {
          name: 'Response duration'
          metricName: 'requests/duration'
          operator: 'GreaterThan'
          threshold: 3000
          timeAggregation: 'Average'
        }
      ]
    }
  }
}

output errorAlertId string = errorRateAlert.id
output slowResponseAlertId string = slowResponseAlert.id
```

4. **Alarme testen:**

```bash
# Fehler erzeugen
for i in {1..20}; do
  curl $APP_URL/api/error-test
done

# Langsame Antworten erzeugen
for i in {1..10}; do
  curl $APP_URL/api/slow
done

# Alarmstatus pr√ºfen (5-10 Minuten warten)
az monitor metrics alert list \
  --resource-group $RG_NAME \
  --query "[].{Name:name, Enabled:enabled, State:properties.enabled}" \
  --output table
```

**‚úÖ Erfolgskriterien:**
- ‚úÖ Alarme wurden erfolgreich erstellt
- ‚úÖ Alarme l√∂sen aus, wenn Schwellwerte √ºberschritten werden
- ‚úÖ Alarmhistorie im Azure-Portal einsehbar
- ‚úÖ In AZD-Bereitstellung integriert

**Zeit**: 20‚Äì25 Minuten

---

### √úbung 2: Benutzerdefiniertes Dashboard erstellen ‚≠ê‚≠ê (Mittel)

**Ziel**: Erstellen Sie ein Dashboard mit wichtigen Anwendungsmetriken.

**Schritte:**

1. **Dashboard √ºber Azure-Portal erstellen:**

Navigieren zu: Azure-Portal ‚Üí Dashboards ‚Üí Neues Dashboard

2. **Kacheln f√ºr Schl√ºsselmetriken hinzuf√ºgen:**

- Anfrageanzahl (letzte 24 Stunden)
- Durchschnittliche Antwortzeit
- Fehlerrate
- Top 5 langsamste Operationen
- Geografische Verteilung der Nutzer

3. **Dashboard via Bicep erstellen:**

**Datei: `infra/core/dashboard.bicep`**

```bicep
param dashboardName string
param applicationInsightsId string
param location string = resourceGroup().location

resource dashboard 'Microsoft.Portal/dashboards@2020-09-01-preview' = {
  name: dashboardName
  location: location
  properties: {
    lenses: [
      {
        order: 0
        parts: [
          // Request count
          {
            position: { x: 0, y: 0, rowSpan: 4, colSpan: 6 }
            metadata: {
              type: 'Extension/Microsoft_OperationsManagementSuite_Workspace/PartType/LogsDashboardPart'
              inputs: [
                {
                  name: 'resourceId'
                  value: applicationInsightsId
                }
                {
                  name: 'query'
                  value: '''
                    requests
                    | summarize RequestCount = count() by bin(timestamp, 1h)
                    | render timechart
                  '''
                }
              ]
            }
          }
          // Error rate
          {
            position: { x: 6, y: 0, rowSpan: 4, colSpan: 6 }
            metadata: {
              type: 'Extension/Microsoft_OperationsManagementSuite_Workspace/PartType/LogsDashboardPart'
              inputs: [
                {
                  name: 'resourceId'
                  value: applicationInsightsId
                }
                {
                  name: 'query'
                  value: '''
                    requests
                    | summarize 
                        Total = count(),
                        Failed = countif(success == false)
                    | extend ErrorRate = (Failed * 100.0) / Total
                    | project ErrorRate
                  '''
                }
              ]
            }
          }
        ]
      }
    ]
  }
}

output dashboardId string = dashboard.id
```

4. **Dashboard bereitstellen:**

```bash
# Zu main.bicep hinzuf√ºgen
module dashboard './core/dashboard.bicep' = {
  name: 'dashboard'
  scope: rg
  params: {
    dashboardName: 'dashboard-${environmentName}'
    applicationInsightsId: monitoring.outputs.applicationInsightsId
    location: location
  }
}

# Bereitstellen
azd up
```

**‚úÖ Erfolgskriterien:**
- ‚úÖ Dashboard zeigt Schl√ºsselmetriken an
- ‚úÖ Kann an Azure-Portal-Startseite angeheftet werden
- ‚úÖ Aktualisiert sich in Echtzeit
- ‚úÖ Per AZD bereitstellbar

**Zeit**: 25‚Äì30 Minuten

---

### √úbung 3: AI/LLM-Anwendung √ºberwachen ‚≠ê‚≠ê‚≠ê (Fortgeschritten)

**Ziel**: Verfolgen Sie Azure OpenAI-Nutzung (Tokens, Kosten, Latenz).

**Schritte:**

1. **AI-Monitoring-Wrapper erstellen:**

**Datei: `src/ai_telemetry.py`**

```python
from telemetry import telemetry
from openai import AzureOpenAI
import time

class MonitoredAzureOpenAI:
    """Azure OpenAI client with automatic telemetry"""
    
    def __init__(self, api_key, endpoint, api_version="2024-02-01"):
        self.client = AzureOpenAI(
            api_key=api_key,
            api_version=api_version,
            azure_endpoint=endpoint
        )
    
    def chat_completion(self, model: str, messages: list, **kwargs):
        """Track chat completion with telemetry"""
        start_time = time.time()
        
        try:
            # Azure OpenAI aufrufen
            response = self.client.chat.completions.create(
                model=model,
                messages=messages,
                **kwargs
            )
            
            duration = (time.time() - start_time) * 1000  # ms
            
            # Nutzungsdaten extrahieren
            usage = response.usage
            prompt_tokens = usage.prompt_tokens
            completion_tokens = usage.completion_tokens
            total_tokens = usage.total_tokens
            
            # Kosten berechnen (GPT-4-Preise)
            prompt_cost = (prompt_tokens / 1000) * 0.03  # $0,03 pro 1K Token
            completion_cost = (completion_tokens / 1000) * 0.06  # $0,06 pro 1K Token
            total_cost = prompt_cost + completion_cost
            
            # Benutzerdefiniertes Ereignis verfolgen
            telemetry.track_event('OpenAI_Request', {
                'model': model,
                'prompt_tokens': prompt_tokens,
                'completion_tokens': completion_tokens,
                'total_tokens': total_tokens,
                'duration_ms': duration,
                'cost_usd': total_cost,
                'success': True
            })
            
            # Metriken verfolgen
            telemetry.track_metric('OpenAI_Tokens', total_tokens, {
                'model': model,
                'type': 'total'
            })
            
            telemetry.track_metric('OpenAI_Cost', total_cost, {
                'model': model,
                'currency': 'USD'
            })
            
            telemetry.track_metric('OpenAI_Duration', duration, {
                'model': model
            })
            
            return response
            
        except Exception as e:
            duration = (time.time() - start_time) * 1000
            
            telemetry.track_event('OpenAI_Request', {
                'model': model,
                'duration_ms': duration,
                'success': False,
                'error': str(e)
            })
            
            raise
```

2. **√úberwachten Client verwenden:**

```python
from flask import Flask, request, jsonify
from ai_telemetry import MonitoredAzureOpenAI
import os

app = Flask(__name__)

# √úberwachten OpenAI-Client initialisieren
openai_client = MonitoredAzureOpenAI(
    api_key=os.environ['AZURE_OPENAI_API_KEY'],
    endpoint=os.environ['AZURE_OPENAI_ENDPOINT']
)

@app.route('/api/chat', methods=['POST'])
def chat():
    data = request.json
    user_message = data.get('message')
    
    # Aufruf mit automatischer √úberwachung
    response = openai_client.chat_completion(
        model='gpt-4',
        messages=[
            {'role': 'user', 'content': user_message}
        ]
    )
    
    return jsonify({
        'response': response.choices[0].message.content,
        'tokens': response.usage.total_tokens
    })
```

3. **AI-Metriken abfragen:**

```kusto
// Total AI spend over time
traces
| where customDimensions.event_name == "OpenAI_Request"
| where customDimensions.success == "True"
| summarize TotalCost = sum(todouble(customDimensions.cost_usd)) by bin(timestamp, 1h)
| render timechart

// Token usage by model
traces
| where customDimensions.event_name == "OpenAI_Request"
| summarize 
    TotalTokens = sum(toint(customDimensions.total_tokens)),
    RequestCount = count()
  by Model = tostring(customDimensions.model)

// Average latency
traces
| where customDimensions.event_name == "OpenAI_Request"
| summarize AvgDuration = avg(todouble(customDimensions.duration_ms))
| project AvgDurationSeconds = AvgDuration / 1000

// Cost per request
traces
| where customDimensions.event_name == "OpenAI_Request"
| extend Cost = todouble(customDimensions.cost_usd)
| summarize 
    TotalCost = sum(Cost),
    RequestCount = count(),
    AvgCostPerRequest = avg(Cost)
```

**‚úÖ Erfolgskriterien:**
- ‚úÖ Jeder OpenAI-Aufruf wird automatisch verfolgt
- ‚úÖ Tokenverbrauch und Kosten sichtbar
- ‚úÖ Latenz √ºberwacht
- ‚úÖ Budgetalarme einstellbar

**Zeit**: 35‚Äì45 Minuten

---

## Kostenoptimierung

### Sampling-Strategien

Steuern Sie die Kosten durch Sampling der Telemetrie:

```python
from opencensus.trace.samplers import ProbabilitySampler

# Entwicklung: 100% Sampling
sampler = ProbabilitySampler(rate=1.0)

# Produktion: 10% Sampling (Kosten um 90% reduzieren)
sampler = ProbabilitySampler(rate=0.1)

# Adaptives Sampling (passt sich automatisch an)
from opencensus.trace.samplers import AdaptiveSampler
sampler = AdaptiveSampler()
```

**In Bicep:**

```bicep
resource applicationInsights 'Microsoft.Insights/components@2020-02-02' = {
  name: applicationInsightsName
  properties: {
    SamplingPercentage: 10  // 10% sampling
  }
}
```

### Datenaufbewahrung

```bicep
resource logAnalytics 'Microsoft.OperationalInsights/workspaces@2022-10-01' = {
  name: logAnalyticsName
  properties: {
    retentionInDays: 30  // Minimum (cheapest)
    // Options: 30, 31, 60, 90, 120, 180, 270, 365, 550, 730
  }
}
```

### Monatliche Kostensch√§tzungen

| Datenvolumen | Aufbewahrung | Monatliche Kosten |
|-------------|-----------|--------------|
| 1 GB/Monat | 30 Tage | ~2‚Äì5 $ |
| 5 GB/Monat | 30 Tage | ~10‚Äì15 $ |
| 10 GB/Monat | 90 Tage | ~25‚Äì40 $ |
| 50 GB/Monat | 90 Tage | ~100‚Äì150 $ |

**Free-Tier**: 5 GB/Monat inklusive

---

## Wissens-Checkpoint

### 1. Grundlegende Integration ‚úì

Testen Sie Ihr Verst√§ndnis:

- [ ] **Q1**: Wie provisioniert AZD Application Insights?
  - **A**: Automatisch √ºber Bicep-Templates in `infra/core/monitoring.bicep`

- [ ] **Q2**: Welche Umgebungsvariable aktiviert Application Insights?
  - **A**: `APPLICATIONINSIGHTS_CONNECTION_STRING`

- [ ] **Q3**: Welche drei Haupttelemetrietypen gibt es?
  - **A**: Requests (HTTP-Aufrufe), Dependencies (externe Aufrufe), Exceptions (Fehler)

**Hands-On-Verifikation:**
```bash
# Pr√ºfen, ob Application Insights konfiguriert ist
azd env get-values | grep APPLICATIONINSIGHTS

# Pr√ºfen, ob Telemetrie √ºbertragen wird
az monitor app-insights metrics show \
  --app $APPI_NAME \
  --resource-group $RG_NAME \
  --metric "requests/count"
```

---

### 2. Benutzerdefinierte Telemetrie ‚úì

Testen Sie Ihr Verst√§ndnis:

- [ ] **Q1**: Wie verfolgen Sie benutzerdefinierte Business-Ereignisse?
  - **A**: Verwenden Sie Logger mit `custom_dimensions` oder `TelemetryClient.track_event()`

- [ ] **Q2**: Was ist der Unterschied zwischen Events und Metriken?
  - **A**: Events sind diskrete Ereignisse, Metriken sind numerische Messwerte

- [ ] **Q3**: Wie korrelieren Sie Telemetrie √ºber Services hinweg?
  - **A**: Application Insights verwendet automatisch `operation_Id` zur Korrelation

**Hands-On-Verifikation:**
```kusto
// Verify custom events
traces
| where customDimensions.event_name != ""
| summarize count() by tostring(customDimensions.event_name)
```

---

### 3. Produktions√ºberwachung ‚úì

Testen Sie Ihr Verst√§ndnis:

- [ ] **Q1**: Was ist Sampling und warum verwendet man es?
  - **A**: Sampling reduziert das Datenvolumen (und die Kosten), indem nur ein Prozentsatz der Telemetrie erfasst wird

- [ ] **Q2**: Wie richten Sie Alarme ein?
  - **A**: Verwenden Sie Metrikalarm-Regeln in Bicep oder im Azure-Portal basierend auf Application Insights-Metriken

- [ ] **Q3**: Was ist der Unterschied zwischen Log Analytics und Application Insights?
  - **A**: Application Insights speichert Daten in einem Log Analytics-Arbeitsbereich; App Insights bietet anwendungsspezifische Ansichten

**Hands-On-Verifikation:**
```bash
# √úberpr√ºfe die Sampling-Konfiguration
az monitor app-insights component show \
  --app $APPI_NAME \
  --resource-group $RG_NAME \
  --query "properties.SamplingPercentage"
```

---

## Best Practices

### ‚úÖ TUN:

1. **Verwenden Sie Korrelation-IDs**
   ```python
   logger.info('Processing order', extra={
       'custom_dimensions': {
           'order_id': order_id,
           'user_id': user_id
       }
   })
   ```

2. **Richten Sie Alarme f√ºr kritische Metriken ein**
   ```bicep
   // Error rate, slow responses, availability
   ```

3. **Verwenden Sie strukturiertes Logging**
   ```python
   # ‚úÖ GUT: Strukturiert
   logger.info('User signup', extra={'custom_dimensions': {'user_id': 123}})
   
   # ‚ùå SCHLECHT: Unstrukturiert
   logger.info(f'User 123 signed up')
   ```

4. **√úberwachen Sie Abh√§ngigkeiten**
   ```python
   # Automatisch Datenbankaufrufe, HTTP-Anfragen usw. verfolgen.
   ```

5. **Nutzen Sie Live Metrics w√§hrend Deployments**

### ‚ùå NICHT:

1. **Keine sensiblen Daten protokollieren**
   ```python
   # ‚ùå SCHLECHT
   logger.info(f'Login: {username}:{password}')
   
   # ‚úÖ GUT
   logger.info('Login attempt', extra={'custom_dimensions': {'username': username}})
   ```

2. **Verwenden Sie nicht 100% Sampling in der Produktion**
   ```python
   # ‚ùå Teuer
   sampler = ProbabilitySampler(rate=1.0)
   
   # ‚úÖ Kosteneffizient
   sampler = ProbabilitySampler(rate=0.1)
   ```

3. **Vernachl√§ssigen Sie nicht Dead-Letter-Queues**

4. **Vergessen Sie nicht, Aufbewahrungsgrenzen f√ºr Daten zu setzen**

---

## Fehlerbehebung

### Problem: Keine Telemetrie vorhanden

**Diagnose:**
```bash
# √úberpr√ºfen, ob die Verbindungszeichenfolge gesetzt ist
azd env get-values | grep APPLICATIONINSIGHTS

# Anwendungsprotokolle √ºber Azure Monitor √ºberpr√ºfen
azd monitor --logs

# Oder die Azure CLI f√ºr Container-Apps verwenden:
az containerapp logs show --name $APP_NAME --resource-group $RG_NAME --tail 50
```

**L√∂sung:**
```bash
# √úberpr√ºfen Sie die Verbindungszeichenfolge in der Container-App
az containerapp show \
  --name $APP_NAME \
  --resource-group $RG_NAME \
  --query "properties.template.containers[0].env" \
  | grep -i applicationinsights
```

---

### Problem: Hohe Kosten

**Diagnose:**
```bash
# Datenaufnahme pr√ºfen
az monitor app-insights metrics show \
  --app $APPI_NAME \
  --resource-group $RG_NAME \
  --metric "availabilityResults/count"
```

**L√∂sung:**
- Sampling-Rate reduzieren
- Aufbewahrungszeitraum verk√ºrzen
- Ausf√ºhrliches Logging entfernen

---

## Mehr erfahren

### Offizielle Dokumentation
- [Application Insights Overview](https://learn.microsoft.com/azure/azure-monitor/app/app-insights-overview)
- [Application Insights for Python](https://learn.microsoft.com/azure/azure-monitor/app/opencensus-python)
- [Kusto Query Language](https://learn.microsoft.com/azure/data-explorer/kusto/query/)
- [AZD Monitoring](https://learn.microsoft.com/azure/developer/azure-developer-cli/monitor-your-app)

### N√§chste Schritte in diesem Kurs
- ‚Üê Vorherige: [Vorabpr√ºfungen](preflight-checks.md)
- ‚Üí N√§chste: [Bereitstellungsanleitung](../chapter-04-infrastructure/deployment-guide.md)
- üè† [Kurs√ºbersicht](../../README.md)

### Verwandte Beispiele
- [Azure OpenAI Example](../../../../examples/azure-openai-chat) - AI-Telemetrie
- [Microservices Example](../../../../examples/microservices) - Verteiltes Tracing

---

## Zusammenfassung

**Sie haben gelernt:**
- ‚úÖ Automatische Bereitstellung von Application Insights mit AZD
- ‚úÖ Benutzerdefinierte Telemetrie (Ereignisse, Metriken, Abh√§ngigkeiten)
- ‚úÖ Verteiltes Tracing √ºber Microservices
- ‚úÖ Live-Metriken und Echtzeit√ºberwachung
- ‚úÖ Warnungen und Dashboards
- ‚úÖ √úberwachung von AI/LLM-Anwendungen
- ‚úÖ Strategien zur Kostenoptimierung

**Wichtigste Erkenntnisse:**
1. **AZD richtet die √úberwachung automatisch ein** - Keine manuelle Einrichtung
2. **Verwenden Sie strukturierte Protokollierung** - Macht Abfragen einfacher
3. **Verfolgen Sie Gesch√§ftsereignisse** - Nicht nur technische Metriken
4. **√úberwachen Sie AI-Kosten** - Verfolgen Sie Token und Ausgaben
5. **Richten Sie Warnungen ein** - Seien Sie proaktiv, nicht reaktiv
6. **Optimieren Sie die Kosten** - Verwenden Sie Sampling und Aufbewahrungsgrenzen

**N√§chste Schritte:**
1. Schlie√üen Sie die praktischen √úbungen ab
2. F√ºgen Sie Application Insights zu Ihren AZD-Projekten hinzu
3. Erstellen Sie benutzerdefinierte Dashboards f√ºr Ihr Team
4. Lesen Sie die [Bereitstellungsanleitung](../chapter-04-infrastructure/deployment-guide.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Haftungsausschluss**:
Dieses Dokument wurde mit dem KI-√úbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, weisen wir darauf hin, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner Originalsprache ist als ma√ügebliche Quelle zu betrachten. F√ºr wichtige Informationen wird eine professionelle menschliche √úbersetzung empfohlen. F√ºr Missverst√§ndnisse oder Fehlinterpretationen, die sich aus der Nutzung dieser √úbersetzung ergeben, √ºbernehmen wir keine Haftung.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->