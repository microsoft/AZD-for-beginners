# Azure OpenAI Chat-Anwendung

**Lernpfad:** Mittelstufe ‚≠ê‚≠ê | **Zeit:** 35-45 Minuten | **Kosten:** $50-200/Monat

Eine vollst√§ndige Azure OpenAI Chat-Anwendung, bereitgestellt mit Azure Developer CLI (azd). Dieses Beispiel zeigt die Bereitstellung von GPT-4, sicheren API-Zugriff und eine einfache Chat-Oberfl√§che.

## üéØ Was Sie lernen werden

- Azure OpenAI Service mit GPT-4-Modell bereitstellen
- OpenAI-API-Schl√ºssel mit Key Vault sichern
- Eine einfache Chat-Oberfl√§che mit Python erstellen
- Token-Nutzung und Kosten √ºberwachen
- Ratenbegrenzung und Fehlerbehandlung implementieren

## üì¶ Was enthalten ist

‚úÖ **Azure OpenAI Service** - Bereitstellung des GPT-4-Modells  
‚úÖ **Python Chat-App** - Einfache Kommandozeilen-Chat-Oberfl√§che  
‚úÖ **Key Vault-Integration** - Sichere Speicherung von API-Schl√ºsseln  
‚úÖ **ARM-Vorlagen** - Vollst√§ndige Infrastruktur als Code  
‚úÖ **Kosten√ºberwachung** - Verfolgung der Token-Nutzung  
‚úÖ **Ratenbegrenzung** - Vermeidung von Quotenersch√∂pfung  

## Architektur

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Python Chat Application (Local/Cloud)    ‚îÇ
‚îÇ   - Command-line interface                 ‚îÇ
‚îÇ   - Conversation history                   ‚îÇ
‚îÇ   - Token usage tracking                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ HTTPS (API Key)
                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Azure OpenAI Service                      ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ   ‚îÇ   GPT-4 Model                         ‚îÇ ‚îÇ
‚îÇ   ‚îÇ   - 20K tokens/min capacity           ‚îÇ ‚îÇ
‚îÇ   ‚îÇ   - Multi-region failover (optional)  ‚îÇ ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                             ‚îÇ
‚îÇ   Managed Identity ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Azure Key Vault                           ‚îÇ
‚îÇ   - OpenAI API Key (secret)                 ‚îÇ
‚îÇ   - Endpoint URL (secret)                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Voraussetzungen

### Erforderlich

- **Azure Developer CLI (azd)** - [Installationsanleitung](https://learn.microsoft.com/azure/developer/azure-developer-cli/install-azd)
- **Azure-Abonnement** mit OpenAI-Zugriff - [Zugriff beantragen](https://aka.ms/oai/access)
- **Python 3.9+** - [Python installieren](https://www.python.org/downloads/)

### Voraussetzungen √ºberpr√ºfen

```bash
# √úberpr√ºfen Sie die azd-Version (mindestens 1.5.0 erforderlich)
azd version

# Azure-Anmeldung √ºberpr√ºfen
azd auth login

# Python-Version √ºberpr√ºfen
python --version  # oder python3 --version

# OpenAI-Zugriff √ºberpr√ºfen (im Azure-Portal pr√ºfen)
az cognitiveservices account list-skus \
  --kind OpenAI \
  --location eastus
```

> **‚ö†Ô∏è Wichtig:** Azure OpenAI erfordert eine Anwendungsfreigabe. Wenn Sie sich noch nicht beworben haben, besuchen Sie [aka.ms/oai/access](https://aka.ms/oai/access). Die Genehmigung dauert in der Regel 1-2 Werktage.

## ‚è±Ô∏è Bereitstellungszeitplan

| Phase | Dauer | Was passiert |
|-------|-------|--------------|
| √úberpr√ºfung der Voraussetzungen | 2-3 Minuten | Verf√ºgbarkeit der OpenAI-Quote √ºberpr√ºfen |
| Infrastruktur bereitstellen | 8-12 Minuten | OpenAI, Key Vault, Modellbereitstellung erstellen |
| Anwendung konfigurieren | 2-3 Minuten | Umgebung und Abh√§ngigkeiten einrichten |
| **Gesamt** | **12-18 Minuten** | Bereit zum Chatten mit GPT-4 |

**Hinweis:** Die erstmalige Bereitstellung von OpenAI kann l√§nger dauern, da das Modell bereitgestellt wird.

## Schnellstart

```bash
# Navigieren Sie zum Beispiel
cd examples/azure-openai-chat

# Umgebung initialisieren
azd env new myopenai

# Alles bereitstellen (Infrastruktur + Konfiguration)
azd up
# Sie werden aufgefordert:
# 1. Azure-Abonnement ausw√§hlen
# 2. Standort mit OpenAI-Verf√ºgbarkeit w√§hlen (z. B. eastus, eastus2, westus)
# 3. 12-18 Minuten auf die Bereitstellung warten

# Python-Abh√§ngigkeiten installieren
pip install -r requirements.txt

# Beginnen Sie mit dem Chat!
python chat.py
```

**Erwartete Ausgabe:**
```
ü§ñ Azure OpenAI Chat Application
Connected to: GPT-4 (eastus)
Type your message (or 'quit' to exit)

You: Hello! Tell me about Azure OpenAI.
Assistant: Azure OpenAI Service provides REST API access to OpenAI's powerful language models including GPT-4, GPT-3.5-Turbo, and Embeddings...

[Tokens used: 145 | Estimated cost: $0.0044]
```

## ‚úÖ Bereitstellung √ºberpr√ºfen

### Schritt 1: Azure-Ressourcen √ºberpr√ºfen

```bash
# Bereitgestellte Ressourcen anzeigen
azd show

# Erwartete Ausgabe zeigt:
# - OpenAI-Dienst: (Ressourcenname)
# - Schl√ºssel-Tresor: (Ressourcenname)
# - Bereitstellung: gpt-4
# - Standort: eastus (oder Ihre ausgew√§hlte Region)
```

### Schritt 2: OpenAI-API testen

```bash
# Abrufen des OpenAI-Endpunkts und Schl√ºssels
OPENAI_ENDPOINT=$(azd env get-value AZURE_OPENAI_ENDPOINT)
OPENAI_KEY=$(azd env get-value AZURE_OPENAI_API_KEY)

# API-Aufruf testen
curl "$OPENAI_ENDPOINT/openai/deployments/gpt-4/chat/completions?api-version=2024-08-01-preview" \
  -H "Content-Type: application/json" \
  -H "api-key: $OPENAI_KEY" \
  -d '{
    "messages": [{"role": "user", "content": "Say hello!"}],
    "max_tokens": 50
  }'
```

**Erwartete Antwort:**
```json
{
  "choices": [
    {
      "message": {
        "role": "assistant",
        "content": "Hello! How can I assist you today?"
      }
    }
  ],
  "usage": {
    "prompt_tokens": 8,
    "completion_tokens": 9,
    "total_tokens": 17
  }
}
```

### Schritt 3: Key Vault-Zugriff √ºberpr√ºfen

```bash
# Geheimnisse im Key Vault auflisten
KV_NAME=$(azd env get-value AZURE_KEY_VAULT_NAME)

az keyvault secret list \
  --vault-name $KV_NAME \
  --query "[].name" \
  --output table
```

**Erwartete Geheimnisse:**
- `openai-api-key`
- `openai-endpoint`

**Erfolgskriterien:**
- ‚úÖ OpenAI-Service mit GPT-4 bereitgestellt
- ‚úÖ API-Aufruf liefert g√ºltige Ergebnisse
- ‚úÖ Geheimnisse im Key Vault gespeichert
- ‚úÖ Token-Nutzungsverfolgung funktioniert

## Projektstruktur

```
azure-openai-chat/
‚îú‚îÄ‚îÄ README.md                   ‚úÖ This guide
‚îú‚îÄ‚îÄ azure.yaml                  ‚úÖ AZD configuration
‚îú‚îÄ‚îÄ infra/                      ‚úÖ Infrastructure as Code
‚îÇ   ‚îú‚îÄ‚îÄ main.bicep             ‚úÖ Main Bicep template
‚îÇ   ‚îú‚îÄ‚îÄ main.parameters.json   ‚úÖ Parameters
‚îÇ   ‚îî‚îÄ‚îÄ openai.bicep           ‚úÖ OpenAI resource definition
‚îú‚îÄ‚îÄ src/                        ‚úÖ Application code
‚îÇ   ‚îú‚îÄ‚îÄ chat.py                ‚úÖ Chat interface
‚îÇ   ‚îú‚îÄ‚îÄ config.py              ‚úÖ Configuration loader
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt       ‚úÖ Python dependencies
‚îî‚îÄ‚îÄ .gitignore                  ‚úÖ Git ignore rules
```

## Anwendungsfunktionen

### Chat-Oberfl√§che (`chat.py`)

Die Chat-Anwendung umfasst:

- **Gespr√§chsverlauf** - Beibehaltung des Kontexts √ºber Nachrichten hinweg
- **Token-Z√§hlung** - Verfolgung der Nutzung und Kostensch√§tzung
- **Fehlerbehandlung** - Elegante Handhabung von Ratenbegrenzungen und API-Fehlern
- **Kostenabsch√§tzung** - Echtzeit-Kostenberechnung pro Nachricht
- **Streaming-Unterst√ºtzung** - Optionale Streaming-Antworten

### Befehle

W√§hrend des Chats k√∂nnen Sie verwenden:
- `quit` oder `exit` - Sitzung beenden
- `clear` - Gespr√§chsverlauf l√∂schen
- `tokens` - Gesamte Token-Nutzung anzeigen
- `cost` - Gesch√§tzte Gesamtkosten anzeigen

### Konfiguration (`config.py`)

L√§dt Konfiguration aus Umgebungsvariablen:
```python
AZURE_OPENAI_ENDPOINT  # Aus dem Key Vault
AZURE_OPENAI_API_KEY   # Aus dem Key Vault
AZURE_OPENAI_MODEL     # Standard: gpt-4
AZURE_OPENAI_MAX_TOKENS # Standard: 800
```

## Anwendungsbeispiele

### Einfacher Chat

```bash
python chat.py
```

### Chat mit benutzerdefiniertem Modell

```bash
export AZURE_OPENAI_MODEL=gpt-35-turbo
python chat.py
```

### Chat mit Streaming

```bash
python chat.py --stream
```

### Beispielgespr√§ch

```
You: Explain Azure OpenAI Service in 3 sentences.
Assistant: Azure OpenAI Service is Microsoft Azure's cloud platform offering 
that provides access to OpenAI's powerful language models. It enables developers 
to integrate capabilities like GPT-4 into their applications with enterprise-grade 
security and compliance. The service includes features for content filtering, 
abuse monitoring, and responsible AI practices.

[Tokens used: 89 | Estimated cost: $0.0027]

You: What models are available?
Assistant: Azure OpenAI Service offers several model families including GPT-4 
(most capable), GPT-3.5-Turbo (faster and cost-effective), and Embeddings models 
for vector search. Each model has different capabilities, pricing, and token limits.

[Tokens used: 67 | Estimated cost: $0.0020]

Total session: 156 tokens | $0.0047
```

## Kostenmanagement

### Token-Preise (GPT-4)

| Modell | Eingabe (pro 1K Tokens) | Ausgabe (pro 1K Tokens) |
|--------|-------------------------|-------------------------|
| GPT-4  | $0.03                  | $0.06                  |
| GPT-3.5-Turbo | $0.0015         | $0.002                 |

### Gesch√§tzte monatliche Kosten

Basierend auf Nutzungsmustern:

| Nutzungslevel | Nachrichten/Tag | Tokens/Tag | Monatliche Kosten |
|---------------|-----------------|------------|-------------------|
| **Leicht**    | 20 Nachrichten  | 3.000 Tokens | $3-5             |
| **Mittel**    | 100 Nachrichten | 15.000 Tokens | $15-25          |
| **Hoch**      | 500 Nachrichten | 75.000 Tokens | $75-125         |

**Basis-Infrastrukturkosten:** $1-2/Monat (Key Vault + minimale Rechenleistung)

### Tipps zur Kostenoptimierung

```bash
# 1. Verwenden Sie GPT-3.5-Turbo f√ºr einfachere Aufgaben (20x g√ºnstiger)
export AZURE_OPENAI_MODEL=gpt-35-turbo

# 2. Reduzieren Sie die maximale Anzahl von Tokens f√ºr k√ºrzere Antworten
export AZURE_OPENAI_MAX_TOKENS=400

# 3. √úberwachen Sie die Token-Nutzung
python chat.py --show-tokens

# 4. Richten Sie Budgetwarnungen ein
az consumption budget create \
  --budget-name "openai-budget" \
  --amount 50 \
  --time-grain Monthly
```

## √úberwachung

### Token-Nutzung anzeigen

```bash
# Im Azure-Portal:
# OpenAI-Ressource ‚Üí Metriken ‚Üí W√§hlen Sie "Token-Transaktion"

# Oder √ºber Azure CLI:
az monitor metrics list \
  --resource $(azd env get-value AZURE_OPENAI_RESOURCE_ID) \
  --metric "TokenTransaction" \
  --start-time $(date -u -d '1 hour ago' '+%Y-%m-%dT%H:%M:%S') \
  --interval PT1M
```

### API-Protokolle anzeigen

```bash
# Diagnoseprotokolle streamen
az monitor diagnostic-settings create \
  --resource $(azd env get-value AZURE_OPENAI_RESOURCE_ID) \
  --name openai-logs \
  --logs '[{"category": "Audit", "enabled": true}]' \
  --workspace $(azd env get-value LOG_ANALYTICS_WORKSPACE_ID)

# Protokolle abfragen
az monitor log-analytics query \
  --workspace $(azd env get-value LOG_ANALYTICS_WORKSPACE_ID) \
  --analytics-query "AzureDiagnostics | where Category == 'Audit' | top 10 by TimeGenerated"
```

## Fehlerbehebung

### Problem: "Zugriff verweigert"-Fehler

**Symptome:** 403 Forbidden beim API-Aufruf

**L√∂sungen:**
```bash
# 1. √úberpr√ºfen Sie, ob der Zugriff auf OpenAI genehmigt ist
az cognitiveservices account show \
  --name $(azd env get-value AZURE_OPENAI_NAME) \
  --resource-group $(azd env get-value AZURE_RESOURCE_GROUP)

# 2. √úberpr√ºfen Sie, ob der API-Schl√ºssel korrekt ist
azd env get-value AZURE_OPENAI_API_KEY

# 3. √úberpr√ºfen Sie das Format der Endpunkt-URL
azd env get-value AZURE_OPENAI_ENDPOINT
# Sollte sein: https://[name].openai.azure.com/
```

### Problem: "Ratenbegrenzung √ºberschritten"

**Symptome:** 429 Too Many Requests

**L√∂sungen:**
```bash
# 1. √úberpr√ºfen Sie das aktuelle Kontingent
az cognitiveservices account deployment show \
  --name $(azd env get-value AZURE_OPENAI_NAME) \
  --resource-group $(azd env get-value AZURE_RESOURCE_GROUP) \
  --deployment-name gpt-4

# 2. Kontingenterh√∂hung anfordern (falls erforderlich)
# Gehen Sie zum Azure-Portal ‚Üí OpenAI-Ressource ‚Üí Kontingente ‚Üí Erh√∂hung anfordern

# 3. Implementieren Sie die Wiederholungslogik (bereits in chat.py)
# Die Anwendung versucht automatisch erneut mit exponentiellem Backoff
```

### Problem: "Modell nicht gefunden"

**Symptome:** 404-Fehler bei der Bereitstellung

**L√∂sungen:**
```bash
# 1. Verf√ºgbare Bereitstellungen auflisten
az cognitiveservices account deployment list \
  --name $(azd env get-value AZURE_OPENAI_NAME) \
  --resource-group $(azd env get-value AZURE_RESOURCE_GROUP)

# 2. Modellname in der Umgebung √ºberpr√ºfen
echo $AZURE_OPENAI_MODEL

# 3. Auf den korrekten Bereitstellungsnamen aktualisieren
export AZURE_OPENAI_MODEL=gpt-4  # oder gpt-35-turbo
```

### Problem: Hohe Latenz

**Symptome:** Langsame Antwortzeiten (>5 Sekunden)

**L√∂sungen:**
```bash
# 1. √úberpr√ºfen Sie die regionale Latenz
# In der Region bereitstellen, die den Benutzern am n√§chsten liegt

# 2. Reduzieren Sie max_tokens f√ºr schnellere Antworten
export AZURE_OPENAI_MAX_TOKENS=400

# 3. Verwenden Sie Streaming f√ºr eine bessere Benutzererfahrung
python chat.py --stream
```

## Sicherheitsbest-Practices

### 1. API-Schl√ºssel sch√ºtzen

```bash
# Niemals Schl√ºssel in die Versionskontrolle einf√ºgen
# Verwenden Sie Key Vault (bereits konfiguriert)

# Schl√ºssel regelm√§√üig rotieren
az cognitiveservices account keys regenerate \
  --name $(azd env get-value AZURE_OPENAI_NAME) \
  --resource-group $(azd env get-value AZURE_RESOURCE_GROUP) \
  --key-name key1
```

### 2. Inhaltsfilterung implementieren

```python
# Azure OpenAI enth√§lt integrierte Inhaltsfilterung
# Konfigurieren im Azure-Portal:
# OpenAI-Ressource ‚Üí Inhaltsfilter ‚Üí Benutzerdefinierten Filter erstellen

# Kategorien: Hass, Sexuell, Gewalt, Selbstverletzung
# Stufen: Niedrig, Mittel, Hohe Filterung
```

### 3. Verwenden Sie Managed Identity (Produktion)

```bash
# F√ºr Produktionsbereitstellungen verwenden Sie eine verwaltete Identit√§t
# anstelle von API-Schl√ºsseln (erfordert App-Hosting auf Azure)

# Aktualisieren Sie infra/openai.bicep, um Folgendes einzuschlie√üen:
# identity: { type: 'SystemAssigned' }
```

## Entwicklung

### Lokal ausf√ºhren

```bash
# Abh√§ngigkeiten installieren
pip install -r src/requirements.txt

# Umgebungsvariablen festlegen
export AZURE_OPENAI_ENDPOINT="https://[name].openai.azure.com/"
export AZURE_OPENAI_API_KEY="your-api-key"
export AZURE_OPENAI_MODEL="gpt-4"

# Anwendung ausf√ºhren
python src/chat.py
```

### Tests ausf√ºhren

```bash
# Installiere Testabh√§ngigkeiten
pip install pytest pytest-cov

# Tests ausf√ºhren
pytest tests/ -v

# Mit Abdeckung
pytest tests/ --cov=src --cov-report=html
```

### Modellbereitstellung aktualisieren

```bash
# Verschiedene Modellversionen bereitstellen
az cognitiveservices account deployment create \
  --name $(azd env get-value AZURE_OPENAI_NAME) \
  --resource-group $(azd env get-value AZURE_RESOURCE_GROUP) \
  --deployment-name gpt-35-turbo \
  --model-name gpt-35-turbo \
  --model-version "0613" \
  --model-format OpenAI \
  --sku-capacity 20 \
  --sku-name "Standard"
```

## Bereinigung

```bash
# L√∂schen Sie alle Azure-Ressourcen
azd down --force --purge

# Dies entfernt:
# - OpenAI-Dienst
# - Key Vault (mit 90-t√§giger Soft-L√∂schung)
# - Ressourcengruppe
# - Alle Bereitstellungen und Konfigurationen
```

## N√§chste Schritte

### Dieses Beispiel erweitern

1. **Web-Oberfl√§che hinzuf√ºgen** - Frontend mit React/Vue erstellen
   ```bash
   # F√ºgen Sie den Frontend-Dienst zu azure.yaml hinzu
   # Bereitstellung in Azure Static Web Apps
   ```

2. **RAG implementieren** - Dokumentensuche mit Azure AI Search hinzuf√ºgen
   ```python
   # Azure Cognitive Search integrieren
   # Dokumente hochladen und Vektorindex erstellen
   ```

3. **Funktionsaufrufe hinzuf√ºgen** - Tool-Nutzung aktivieren
   ```python
   # Funktionen in chat.py definieren
   # GPT-4 externe APIs aufrufen lassen
   ```

4. **Multi-Modell-Unterst√ºtzung** - Mehrere Modelle bereitstellen
   ```bash
   # F√ºge gpt-35-turbo, Embedding-Modelle hinzu
   # Implementiere Modell-Routing-Logik
   ```

### Verwandte Beispiele

- **[Retail Multi-Agent](../retail-scenario.md)** - Fortgeschrittene Multi-Agent-Architektur
- **[Datenbank-App](../../../../examples/database-app)** - Persistente Speicherung hinzuf√ºgen
- **[Container-Apps](../../../../examples/container-app)** - Als containerisierten Dienst bereitstellen

### Lernressourcen

- üìö [AZD For Beginners Kurs](../../README.md) - Hauptkurs√ºbersicht
- üìö [Azure OpenAI Dokumentation](https://learn.microsoft.com/azure/ai-services/openai/) - Offizielle Dokumentation
- üìö [OpenAI API-Referenz](https://platform.openai.com/docs/api-reference) - API-Details
- üìö [Verantwortungsvolle KI](https://www.microsoft.com/ai/responsible-ai) - Best Practices

## Zus√§tzliche Ressourcen

### Dokumentation
- **[Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/)** - Vollst√§ndige Anleitung
- **[GPT-4 Modelle](https://learn.microsoft.com/azure/ai-services/openai/concepts/models)** - Modellf√§higkeiten
- **[Inhaltsfilterung](https://learn.microsoft.com/azure/ai-services/openai/concepts/content-filter)** - Sicherheitsfunktionen
- **[Azure Developer CLI](https://learn.microsoft.com/azure/developer/azure-developer-cli/)** - azd-Referenz

### Tutorials
- **[OpenAI Schnellstart](https://learn.microsoft.com/azure/ai-services/openai/quickstart)** - Erste Bereitstellung
- **[Chat-Abschl√ºsse](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt)** - Chat-Anwendungen erstellen
- **[Funktionsaufrufe](https://learn.microsoft.com/azure/ai-services/openai/how-to/function-calling)** - Erweiterte Funktionen

### Tools
- **[Azure OpenAI Studio](https://oai.azure.com/)** - Webbasierter Playground
- **[Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)** - Bessere Prompts schreiben
- **[Token-Rechner](https://platform.openai.com/tokenizer)** - Token-Nutzung sch√§tzen

### Community
- **[Azure AI Discord](https://discord.gg/azure)** - Hilfe von der Community erhalten
- **[GitHub Diskussionen](https://github.com/Azure-Samples/openai/discussions)** - Q&A-Forum
- **[Azure Blog](https://azure.microsoft.com/blog/tag/azure-openai-service/)** - Neueste Updates

---

**üéâ Erfolg!** Sie haben Azure OpenAI bereitgestellt und eine funktionierende Chat-Anwendung erstellt. Erkunden Sie die F√§higkeiten von GPT-4 und experimentieren Sie mit verschiedenen Prompts und Anwendungsf√§llen.

**Fragen?** [Ein Problem √∂ffnen](https://github.com/microsoft/AZD-for-beginners/issues) oder die [FAQ](../../resources/faq.md) √ºberpr√ºfen

**Kostenwarnung:** Denken Sie daran, `azd down` auszuf√ºhren, wenn Sie mit dem Testen fertig sind, um laufende Kosten (~$50-100/Monat bei aktiver Nutzung) zu vermeiden.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-√úbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, beachten Sie bitte, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache sollte als ma√ügebliche Quelle betrachtet werden. F√ºr kritische Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die sich aus der Nutzung dieser √úbersetzung ergeben.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->