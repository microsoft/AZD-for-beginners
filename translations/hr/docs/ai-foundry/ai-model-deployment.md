<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6af361e2339c27aa56a9196e11b32cb7",
  "translation_date": "2025-09-18T12:00:16+00:00",
  "source_file": "docs/ai-foundry/ai-model-deployment.md",
  "language_code": "hr"
}
-->
# Implementacija AI modela s Azure Developer CLI

**Navigacija kroz poglavlja:**
- **游닄 Po캜etna stranica te캜aja**: [AZD za po캜etnike](../../README.md)
- **游닀 Trenutno poglavlje**: Poglavlje 2 - Razvoj s fokusom na AI
- **拘勇 Prethodno**: [Integracija Azure AI Foundry](azure-ai-foundry-integration.md)
- **俱뫮잺 Sljede캖e**: [AI radionica](ai-workshop-lab.md)
- **游 Sljede캖e poglavlje**: [Poglavlje 3: Konfiguracija](../getting-started/configuration.md)

Ovaj vodi캜 pru쬬 detaljne upute za implementaciju AI modela koriste캖i AZD predlo코ke, pokrivaju캖i sve od odabira modela do obrazaca implementacije u produkciji.

## Sadr쬬j

- [Strategija odabira modela](../../../../docs/ai-foundry)
- [AZD konfiguracija za AI modele](../../../../docs/ai-foundry)
- [Obrasci implementacije](../../../../docs/ai-foundry)
- [Upravljanje modelima](../../../../docs/ai-foundry)
- [Razmatranja za produkciju](../../../../docs/ai-foundry)
- [Pra캖enje i preglednost](../../../../docs/ai-foundry)

## Strategija odabira modela

### Azure OpenAI modeli

Odaberite odgovaraju캖i model za svoju primjenu:

```yaml
# azure.yaml - Model configuration
services:
  ai-service:
    project: ./infra
    host: containerapp
    config:
      AZURE_OPENAI_MODELS: |
        [
          {
            "name": "gpt-4o-mini",
            "version": "2024-07-18",
            "deployment": "gpt-4o-mini",
            "capacity": 10,
            "format": "OpenAI"
          },
          {
            "name": "text-embedding-ada-002",
            "version": "2",
            "deployment": "text-embedding-ada-002", 
            "capacity": 30,
            "format": "OpenAI"
          }
        ]
```

### Planiranje kapaciteta modela

| Tip modela | Primjena | Preporu캜eni kapacitet | Tro코kovni aspekti |
|------------|----------|-----------------------|-------------------|
| GPT-4o-mini | Chat, Q&A | 10-50 TPM | Isplativo za ve캖inu radnih optere캖enja |
| GPT-4 | Kompleksno zaklju캜ivanje | 20-100 TPM | Ve캖i tro코ak, koristiti za premium zna캜ajke |
| Text-embedding-ada-002 | Pretra쬴vanje, RAG | 30-120 TPM | Klju캜no za semanti캜ko pretra쬴vanje |
| Whisper | Govor u tekst | 10-50 TPM | Obrada audio sadr쬬ja |

## AZD konfiguracija za AI modele

### Konfiguracija Bicep predlo코ka

Kreirajte implementacije modela koriste캖i Bicep predlo코ke:

```bicep
// infra/main.bicep
@description('OpenAI model deployments')
param openAiModelDeployments array = [
  {
    name: 'gpt-4o-mini'
    model: {
      format: 'OpenAI'
      name: 'gpt-4o-mini'
      version: '2024-07-18'
    }
    sku: {
      name: 'Standard'
      capacity: 10
    }
  }
  {
    name: 'text-embedding-ada-002'
    model: {
      format: 'OpenAI'
      name: 'text-embedding-ada-002'
      version: '2'
    }
    sku: {
      name: 'Standard'
      capacity: 30
    }
  }
]

resource openAi 'Microsoft.CognitiveServices/accounts@2023-05-01' = {
  name: openAiAccountName
  location: location
  kind: 'OpenAI'
  properties: {
    customSubDomainName: openAiAccountName
    networkAcls: {
      defaultAction: 'Allow'
    }
    publicNetworkAccess: 'Enabled'
  }
  sku: {
    name: 'S0'
  }
}

@batchSize(1)
resource deployment 'Microsoft.CognitiveServices/accounts/deployments@2023-05-01' = [for deployment in openAiModelDeployments: {
  parent: openAi
  name: deployment.name
  properties: {
    model: deployment.model
  }
  sku: deployment.sku
}]
```

### Varijable okru쬰nja

Konfigurirajte okru쬰nje svoje aplikacije:

```bash
# .env configuration
AZURE_OPENAI_ENDPOINT=https://your-openai-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-02-15-preview
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o-mini
AZURE_OPENAI_EMBED_DEPLOYMENT=text-embedding-ada-002
```

## Obrasci implementacije

### Obrazac 1: Implementacija u jednoj regiji

```yaml
# azure.yaml - Single region
services:
  ai-app:
    project: ./src
    host: containerapp
    config:
      AZURE_OPENAI_ENDPOINT: ${AZURE_OPENAI_ENDPOINT}
      AZURE_OPENAI_CHAT_DEPLOYMENT: gpt-4o-mini
```

Najbolje za:
- Razvoj i testiranje
- Aplikacije za jedno tr쬴코te
- Optimizaciju tro코kova

### Obrazac 2: Implementacija u vi코e regija

```bicep
// Multi-region deployment
param regions array = ['eastus2', 'westus2', 'francecentral']

resource openAiMultiRegion 'Microsoft.CognitiveServices/accounts@2023-05-01' = [for region in regions: {
  name: '${openAiAccountName}-${region}'
  location: region
  // ... configuration
}]
```

Najbolje za:
- Globalne aplikacije
- Zahtjevi za visoku dostupnost
- Distribuciju optere캖enja

### Obrazac 3: Hibridna implementacija

Kombinirajte Azure OpenAI s drugim AI uslugama:

```bicep
// Hybrid AI services
resource cognitiveServices 'Microsoft.CognitiveServices/accounts@2023-05-01' = {
  name: cognitiveServicesName
  location: location
  kind: 'CognitiveServices'
  properties: {
    customSubDomainName: cognitiveServicesName
  }
  sku: {
    name: 'S0'
  }
}

resource documentIntelligence 'Microsoft.CognitiveServices/accounts@2023-05-01' = {
  name: documentIntelligenceName
  location: location
  kind: 'FormRecognizer'
  properties: {
    customSubDomainName: documentIntelligenceName
  }
  sku: {
    name: 'S0'
  }
}
```

## Upravljanje modelima

### Kontrola verzija

Pratite verzije modela u svojoj AZD konfiguraciji:

```json
{
  "models": {
    "chat": {
      "name": "gpt-4o-mini",
      "version": "2024-07-18",
      "fallback": "gpt-35-turbo"
    },
    "embedding": {
      "name": "text-embedding-ada-002",
      "version": "2"
    }
  }
}
```

### A쬿riranja modela

Koristite AZD hooks za a쬿riranja modela:

```bash
#!/bin/bash
# hooks/predeploy.sh

echo "Checking model availability..."
az cognitiveservices account list-models \
  --name $AZURE_OPENAI_ACCOUNT_NAME \
  --resource-group $AZURE_RESOURCE_GROUP \
  --query "[?name=='gpt-4o-mini']"
```

### A/B testiranje

Implementirajte vi코e verzija modela:

```bicep
param enableABTesting bool = false

resource chatDeployment 'Microsoft.CognitiveServices/accounts/deployments@2023-05-01' = {
  parent: openAi
  name: 'gpt-4o-mini-${enableABTesting ? 'v1' : 'prod'}'
  properties: {
    model: {
      format: 'OpenAI'
      name: 'gpt-4o-mini'
      version: '2024-07-18'
    }
  }
  sku: {
    name: 'Standard'
    capacity: enableABTesting ? 5 : 10
  }
}
```

## Razmatranja za produkciju

### Planiranje kapaciteta

Izra캜unajte potrebni kapacitet na temelju obrazaca kori코tenja:

```python
# Capacity calculation example
def calculate_required_capacity(
    requests_per_minute: int,
    avg_prompt_tokens: int,
    avg_completion_tokens: int,
    safety_margin: float = 0.2
) -> int:
    """Calculate required TPM capacity."""
    total_tokens_per_request = avg_prompt_tokens + avg_completion_tokens
    total_tpm = requests_per_minute * total_tokens_per_request
    return int(total_tpm * (1 + safety_margin))

# Example usage
required_capacity = calculate_required_capacity(
    requests_per_minute=10,
    avg_prompt_tokens=500,
    avg_completion_tokens=200,
    safety_margin=0.3
)
print(f"Required capacity: {required_capacity} TPM")
```

### Konfiguracija automatskog skaliranja

Postavite automatsko skaliranje za Container Apps:

```bicep
resource containerApp 'Microsoft.App/containerApps@2024-03-01' = {
  name: containerAppName
  properties: {
    template: {
      scale: {
        minReplicas: 1
        maxReplicas: 10
        rules: [
          {
            name: 'http-rule'
            http: {
              metadata: {
                concurrentRequests: '10'
              }
            }
          }
          {
            name: 'cpu-rule'
            custom: {
              type: 'cpu'
              metadata: {
                type: 'Utilization'
                value: '70'
              }
            }
          }
        ]
      }
    }
  }
}
```

### Optimizacija tro코kova

Implementirajte kontrolu tro코kova:

```bicep
@description('Enable cost management alerts')
param enableCostAlerts bool = true

resource budgetAlert 'Microsoft.Consumption/budgets@2023-05-01' = if (enableCostAlerts) {
  name: 'ai-budget-alert'
  properties: {
    timePeriod: {
      startDate: '2024-01-01'
      endDate: '2024-12-31'
    }
    timeGrain: 'Monthly'
    amount: 1000
    category: 'Cost'
    notifications: {
      Actual_GreaterThan_80_Percent: {
        enabled: true
        operator: 'GreaterThan'
        threshold: 80
        contactEmails: [
          'admin@yourcompany.com'
        ]
      }
    }
  }
}
```

## Pra캖enje i preglednost

### Integracija s Application Insights

Postavite pra캖enje za AI radna optere캖enja:

```bicep
resource applicationInsights 'Microsoft.Insights/components@2020-02-02' = {
  name: applicationInsightsName
  location: location
  kind: 'web'
  properties: {
    Application_Type: 'web'
    WorkspaceResourceId: logAnalyticsWorkspace.id
  }
}

// Custom metrics for AI models
resource aiMetrics 'Microsoft.Insights/components/analyticsItems@2020-02-02' = {
  parent: applicationInsights
  name: 'ai-model-metrics'
  properties: {
    content: '''
      customEvents
      | where name == "AI_Model_Request"
      | extend model = tostring(customDimensions.model)
      | extend tokens = toint(customDimensions.tokens)
      | extend latency = toint(customDimensions.latency_ms)
      | summarize 
          requests = count(),
          avg_tokens = avg(tokens),
          avg_latency = avg(latency)
        by model, bin(timestamp, 5m)
    '''
    type: 'query'
    scope: 'shared'
  }
}
```

### Prilago캠ene metrike

Pratite metrike specifi캜ne za AI:

```python
# Custom telemetry for AI models
import logging
from applicationinsights import TelemetryClient

class AITelemetry:
    def __init__(self, instrumentation_key: str):
        self.client = TelemetryClient(instrumentation_key)
    
    def track_model_request(self, model: str, tokens: int, latency_ms: int, success: bool):
        """Track AI model request metrics."""
        self.client.track_event(
            'AI_Model_Request',
            {
                'model': model,
                'tokens': str(tokens),
                'latency_ms': str(latency_ms),
                'success': str(success)
            }
        )
        
    def track_model_error(self, model: str, error_type: str, error_message: str):
        """Track AI model errors."""
        self.client.track_exception(
            type=error_type,
            value=error_message,
            properties={
                'model': model,
                'component': 'ai_model'
            }
        )
```

### Provjere zdravlja

Implementirajte pra캖enje zdravlja AI usluga:

```python
# Health check endpoints
from fastapi import FastAPI, HTTPException
import httpx

app = FastAPI()

@app.get("/health/ai-models")
async def check_ai_models():
    """Check AI model availability."""
    try:
        # Test OpenAI connection
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"{AZURE_OPENAI_ENDPOINT}/openai/deployments",
                headers={"api-key": AZURE_OPENAI_API_KEY}
            )
            
        if response.status_code == 200:
            return {"status": "healthy", "models": response.json()}
        else:
            raise HTTPException(status_code=503, detail="AI models unavailable")
            
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"Health check failed: {str(e)}")
```

## Sljede캖i koraci

1. **Pregledajte [Vodi캜 za integraciju Azure AI Foundry](azure-ai-foundry-integration.md)** za obrasce integracije usluga
2. **Dovr코ite [AI radionicu](ai-workshop-lab.md)** za prakti캜no iskustvo
3. **Implementirajte [Prakse za produkcijski AI](production-ai-practices.md)** za implementacije na razini poduze캖a
4. **Istra쬴te [Vodi캜 za rje코avanje problema s AI](../troubleshooting/ai-troubleshooting.md)** za uobi캜ajene probleme

## Resursi

- [Dostupnost modela Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/models)
- [Dokumentacija za Azure Developer CLI](https://learn.microsoft.com/azure/developer/azure-developer-cli/)
- [Skaliranje Container Apps](https://learn.microsoft.com/azure/container-apps/scale-app)
- [Optimizacija tro코kova AI modela](https://learn.microsoft.com/azure/ai-services/openai/how-to/manage-costs)

---

**Navigacija kroz poglavlja:**
- **游닄 Po캜etna stranica te캜aja**: [AZD za po캜etnike](../../README.md)
- **游닀 Trenutno poglavlje**: Poglavlje 2 - Razvoj s fokusom na AI
- **拘勇 Prethodno**: [Integracija Azure AI Foundry](azure-ai-foundry-integration.md)
- **俱뫮잺 Sljede캖e**: [AI radionica](ai-workshop-lab.md)
- **游 Sljede캖e poglavlje**: [Poglavlje 3: Konfiguracija](../getting-started/configuration.md)

---

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden pomo캖u AI usluge za prevo캠enje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati to캜nost, imajte na umu da automatski prijevodi mogu sadr쬬vati pogre코ke ili neto캜nosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za klju캜ne informacije preporu캜uje se profesionalni prijevod od strane 캜ovjeka. Ne preuzimamo odgovornost za nesporazume ili pogre코na tuma캜enja koja mogu proiza캖i iz kori코tenja ovog prijevoda.