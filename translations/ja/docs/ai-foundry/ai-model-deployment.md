<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6af361e2339c27aa56a9196e11b32cb7",
  "translation_date": "2025-09-17T14:13:01+00:00",
  "source_file": "docs/ai-foundry/ai-model-deployment.md",
  "language_code": "ja"
}
-->
# Azure Developer CLI ã‚’ä½¿ç”¨ã—ãŸ AI ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ—ãƒ­ã‚¤

**ç« ã®ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³:**
- **ğŸ“š ã‚³ãƒ¼ã‚¹ãƒ›ãƒ¼ãƒ **: [AZD åˆå¿ƒè€…å‘ã‘](../../README.md)
- **ğŸ“– ç¾åœ¨ã®ç« **: ç¬¬2ç«  - AIãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆé–‹ç™º
- **â¬…ï¸ å‰ç« **: [Azure AI Foundry çµ±åˆ](azure-ai-foundry-integration.md)
- **â¡ï¸ æ¬¡ç« **: [AI ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ãƒ©ãƒœ](ai-workshop-lab.md)
- **ğŸš€ æ¬¡ã®ç« **: [ç¬¬3ç« : è¨­å®š](../getting-started/configuration.md)

ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€AZDãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ã¦AIãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ãŸã‚ã®åŒ…æ‹¬çš„ãªæ‰‹é †ã‚’æä¾›ã—ã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«é¸æŠã‹ã‚‰æœ¬ç•ªç’°å¢ƒã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ‘ã‚¿ãƒ¼ãƒ³ã¾ã§ã‚’ç¶²ç¾…ã—ã¦ã„ã¾ã™ã€‚

## ç›®æ¬¡

- [ãƒ¢ãƒ‡ãƒ«é¸æŠæˆ¦ç•¥](../../../../docs/ai-foundry)
- [AIãƒ¢ãƒ‡ãƒ«å‘ã‘AZDè¨­å®š](../../../../docs/ai-foundry)
- [ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ‘ã‚¿ãƒ¼ãƒ³](../../../../docs/ai-foundry)
- [ãƒ¢ãƒ‡ãƒ«ç®¡ç†](../../../../docs/ai-foundry)
- [æœ¬ç•ªç’°å¢ƒã®è€ƒæ…®äº‹é …](../../../../docs/ai-foundry)
- [ç›£è¦–ã¨å¯è¦³æ¸¬æ€§](../../../../docs/ai-foundry)

## ãƒ¢ãƒ‡ãƒ«é¸æŠæˆ¦ç•¥

### Azure OpenAI ãƒ¢ãƒ‡ãƒ«

ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«é©ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„:

```yaml
# azure.yaml - Model configuration
services:
  ai-service:
    project: ./infra
    host: containerapp
    config:
      AZURE_OPENAI_MODELS: |
        [
          {
            "name": "gpt-4o-mini",
            "version": "2024-07-18",
            "deployment": "gpt-4o-mini",
            "capacity": 10,
            "format": "OpenAI"
          },
          {
            "name": "text-embedding-ada-002",
            "version": "2",
            "deployment": "text-embedding-ada-002", 
            "capacity": 30,
            "format": "OpenAI"
          }
        ]
```

### ãƒ¢ãƒ‡ãƒ«å®¹é‡è¨ˆç”»

| ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ— | ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ | æ¨å¥¨å®¹é‡ | ã‚³ã‚¹ãƒˆã®è€ƒæ…®äº‹é … |
|--------------|--------------|----------|------------------|
| GPT-4o-mini | ãƒãƒ£ãƒƒãƒˆã€Q&A | 10-50 TPM | ã»ã¨ã‚“ã©ã®ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã«ãŠã„ã¦è²»ç”¨å¯¾åŠ¹æœãŒé«˜ã„ |
| GPT-4 | è¤‡é›‘ãªæ¨è«– | 20-100 TPM | é«˜ã‚³ã‚¹ãƒˆã€ãƒ—ãƒ¬ãƒŸã‚¢ãƒ æ©Ÿèƒ½å‘ã‘ |
| Text-embedding-ada-002 | æ¤œç´¢ã€RAG | 30-120 TPM | ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã«å¿…é ˆ |
| Whisper | éŸ³å£°ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¸ã®å¤‰æ› | 10-50 TPM | éŸ³å£°å‡¦ç†ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰å‘ã‘ |

## AIãƒ¢ãƒ‡ãƒ«å‘ã‘AZDè¨­å®š

### Bicepãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè¨­å®š

Bicepãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã™:

```bicep
// infra/main.bicep
@description('OpenAI model deployments')
param openAiModelDeployments array = [
  {
    name: 'gpt-4o-mini'
    model: {
      format: 'OpenAI'
      name: 'gpt-4o-mini'
      version: '2024-07-18'
    }
    sku: {
      name: 'Standard'
      capacity: 10
    }
  }
  {
    name: 'text-embedding-ada-002'
    model: {
      format: 'OpenAI'
      name: 'text-embedding-ada-002'
      version: '2'
    }
    sku: {
      name: 'Standard'
      capacity: 30
    }
  }
]

resource openAi 'Microsoft.CognitiveServices/accounts@2023-05-01' = {
  name: openAiAccountName
  location: location
  kind: 'OpenAI'
  properties: {
    customSubDomainName: openAiAccountName
    networkAcls: {
      defaultAction: 'Allow'
    }
    publicNetworkAccess: 'Enabled'
  }
  sku: {
    name: 'S0'
  }
}

@batchSize(1)
resource deployment 'Microsoft.CognitiveServices/accounts/deployments@2023-05-01' = [for deployment in openAiModelDeployments: {
  parent: openAi
  name: deployment.name
  properties: {
    model: deployment.model
  }
  sku: deployment.sku
}]
```

### ç’°å¢ƒå¤‰æ•°

ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç’°å¢ƒã‚’è¨­å®šã—ã¾ã™:

```bash
# .env configuration
AZURE_OPENAI_ENDPOINT=https://your-openai-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-02-15-preview
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o-mini
AZURE_OPENAI_EMBED_DEPLOYMENT=text-embedding-ada-002
```

## ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ‘ã‚¿ãƒ¼ãƒ³

### ãƒ‘ã‚¿ãƒ¼ãƒ³1: å˜ä¸€ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ãƒ‡ãƒ—ãƒ­ã‚¤

```yaml
# azure.yaml - Single region
services:
  ai-app:
    project: ./src
    host: containerapp
    config:
      AZURE_OPENAI_ENDPOINT: ${AZURE_OPENAI_ENDPOINT}
      AZURE_OPENAI_CHAT_DEPLOYMENT: gpt-4o-mini
```

é©ã—ã¦ã„ã‚‹ã‚±ãƒ¼ã‚¹:
- é–‹ç™ºã¨ãƒ†ã‚¹ãƒˆ
- å˜ä¸€å¸‚å ´å‘ã‘ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
- ã‚³ã‚¹ãƒˆæœ€é©åŒ–

### ãƒ‘ã‚¿ãƒ¼ãƒ³2: è¤‡æ•°ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ãƒ‡ãƒ—ãƒ­ã‚¤

```bicep
// Multi-region deployment
param regions array = ['eastus2', 'westus2', 'francecentral']

resource openAiMultiRegion 'Microsoft.CognitiveServices/accounts@2023-05-01' = [for region in regions: {
  name: '${openAiAccountName}-${region}'
  location: region
  // ... configuration
}]
```

é©ã—ã¦ã„ã‚‹ã‚±ãƒ¼ã‚¹:
- ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
- é«˜å¯ç”¨æ€§è¦ä»¶
- è² è·åˆ†æ•£

### ãƒ‘ã‚¿ãƒ¼ãƒ³3: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ‡ãƒ—ãƒ­ã‚¤

Azure OpenAIã¨ä»–ã®AIã‚µãƒ¼ãƒ“ã‚¹ã‚’çµ„ã¿åˆã‚ã›ã¾ã™:

```bicep
// Hybrid AI services
resource cognitiveServices 'Microsoft.CognitiveServices/accounts@2023-05-01' = {
  name: cognitiveServicesName
  location: location
  kind: 'CognitiveServices'
  properties: {
    customSubDomainName: cognitiveServicesName
  }
  sku: {
    name: 'S0'
  }
}

resource documentIntelligence 'Microsoft.CognitiveServices/accounts@2023-05-01' = {
  name: documentIntelligenceName
  location: location
  kind: 'FormRecognizer'
  properties: {
    customSubDomainName: documentIntelligenceName
  }
  sku: {
    name: 'S0'
  }
}
```

## ãƒ¢ãƒ‡ãƒ«ç®¡ç†

### ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†

AZDè¨­å®šã§ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’è¿½è·¡ã—ã¾ã™:

```json
{
  "models": {
    "chat": {
      "name": "gpt-4o-mini",
      "version": "2024-07-18",
      "fallback": "gpt-35-turbo"
    },
    "embedding": {
      "name": "text-embedding-ada-002",
      "version": "2"
    }
  }
}
```

### ãƒ¢ãƒ‡ãƒ«æ›´æ–°

AZDãƒ•ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°ã—ã¾ã™:

```bash
#!/bin/bash
# hooks/predeploy.sh

echo "Checking model availability..."
az cognitiveservices account list-models \
  --name $AZURE_OPENAI_ACCOUNT_NAME \
  --resource-group $AZURE_RESOURCE_GROUP \
  --query "[?name=='gpt-4o-mini']"
```

### A/Bãƒ†ã‚¹ãƒˆ

è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã™:

```bicep
param enableABTesting bool = false

resource chatDeployment 'Microsoft.CognitiveServices/accounts/deployments@2023-05-01' = {
  parent: openAi
  name: 'gpt-4o-mini-${enableABTesting ? 'v1' : 'prod'}'
  properties: {
    model: {
      format: 'OpenAI'
      name: 'gpt-4o-mini'
      version: '2024-07-18'
    }
  }
  sku: {
    name: 'Standard'
    capacity: enableABTesting ? 5 : 10
  }
}
```

## æœ¬ç•ªç’°å¢ƒã®è€ƒæ…®äº‹é …

### å®¹é‡è¨ˆç”»

ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ã„ã¦å¿…è¦ãªå®¹é‡ã‚’è¨ˆç®—ã—ã¾ã™:

```python
# Capacity calculation example
def calculate_required_capacity(
    requests_per_minute: int,
    avg_prompt_tokens: int,
    avg_completion_tokens: int,
    safety_margin: float = 0.2
) -> int:
    """Calculate required TPM capacity."""
    total_tokens_per_request = avg_prompt_tokens + avg_completion_tokens
    total_tpm = requests_per_minute * total_tokens_per_request
    return int(total_tpm * (1 + safety_margin))

# Example usage
required_capacity = calculate_required_capacity(
    requests_per_minute=10,
    avg_prompt_tokens=500,
    avg_completion_tokens=200,
    safety_margin=0.3
)
print(f"Required capacity: {required_capacity} TPM")
```

### è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°è¨­å®š

Container Appsã®è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’è¨­å®šã—ã¾ã™:

```bicep
resource containerApp 'Microsoft.App/containerApps@2024-03-01' = {
  name: containerAppName
  properties: {
    template: {
      scale: {
        minReplicas: 1
        maxReplicas: 10
        rules: [
          {
            name: 'http-rule'
            http: {
              metadata: {
                concurrentRequests: '10'
              }
            }
          }
          {
            name: 'cpu-rule'
            custom: {
              type: 'cpu'
              metadata: {
                type: 'Utilization'
                value: '70'
              }
            }
          }
        ]
      }
    }
  }
}
```

### ã‚³ã‚¹ãƒˆæœ€é©åŒ–

ã‚³ã‚¹ãƒˆç®¡ç†ã‚’å®Ÿæ–½ã—ã¾ã™:

```bicep
@description('Enable cost management alerts')
param enableCostAlerts bool = true

resource budgetAlert 'Microsoft.Consumption/budgets@2023-05-01' = if (enableCostAlerts) {
  name: 'ai-budget-alert'
  properties: {
    timePeriod: {
      startDate: '2024-01-01'
      endDate: '2024-12-31'
    }
    timeGrain: 'Monthly'
    amount: 1000
    category: 'Cost'
    notifications: {
      Actual_GreaterThan_80_Percent: {
        enabled: true
        operator: 'GreaterThan'
        threshold: 80
        contactEmails: [
          'admin@yourcompany.com'
        ]
      }
    }
  }
}
```

## ç›£è¦–ã¨å¯è¦³æ¸¬æ€§

### Application Insights çµ±åˆ

AIãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã®ç›£è¦–ã‚’è¨­å®šã—ã¾ã™:

```bicep
resource applicationInsights 'Microsoft.Insights/components@2020-02-02' = {
  name: applicationInsightsName
  location: location
  kind: 'web'
  properties: {
    Application_Type: 'web'
    WorkspaceResourceId: logAnalyticsWorkspace.id
  }
}

// Custom metrics for AI models
resource aiMetrics 'Microsoft.Insights/components/analyticsItems@2020-02-02' = {
  parent: applicationInsights
  name: 'ai-model-metrics'
  properties: {
    content: '''
      customEvents
      | where name == "AI_Model_Request"
      | extend model = tostring(customDimensions.model)
      | extend tokens = toint(customDimensions.tokens)
      | extend latency = toint(customDimensions.latency_ms)
      | summarize 
          requests = count(),
          avg_tokens = avg(tokens),
          avg_latency = avg(latency)
        by model, bin(timestamp, 5m)
    '''
    type: 'query'
    scope: 'shared'
  }
}
```

### ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹

AIç‰¹æœ‰ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¿½è·¡ã—ã¾ã™:

```python
# Custom telemetry for AI models
import logging
from applicationinsights import TelemetryClient

class AITelemetry:
    def __init__(self, instrumentation_key: str):
        self.client = TelemetryClient(instrumentation_key)
    
    def track_model_request(self, model: str, tokens: int, latency_ms: int, success: bool):
        """Track AI model request metrics."""
        self.client.track_event(
            'AI_Model_Request',
            {
                'model': model,
                'tokens': str(tokens),
                'latency_ms': str(latency_ms),
                'success': str(success)
            }
        )
        
    def track_model_error(self, model: str, error_type: str, error_message: str):
        """Track AI model errors."""
        self.client.track_exception(
            type=error_type,
            value=error_message,
            properties={
                'model': model,
                'component': 'ai_model'
            }
        )
```

### ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯

AIã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ˜ãƒ«ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿæ–½ã—ã¾ã™:

```python
# Health check endpoints
from fastapi import FastAPI, HTTPException
import httpx

app = FastAPI()

@app.get("/health/ai-models")
async def check_ai_models():
    """Check AI model availability."""
    try:
        # Test OpenAI connection
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"{AZURE_OPENAI_ENDPOINT}/openai/deployments",
                headers={"api-key": AZURE_OPENAI_API_KEY}
            )
            
        if response.status_code == 200:
            return {"status": "healthy", "models": response.json()}
        else:
            raise HTTPException(status_code=503, detail="AI models unavailable")
            
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"Health check failed: {str(e)}")
```

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **[Azure AI Foundry çµ±åˆã‚¬ã‚¤ãƒ‰](azure-ai-foundry-integration.md)** ã‚’ç¢ºèªã—ã¦ã‚µãƒ¼ãƒ“ã‚¹çµ±åˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ã¶
2. **[AI ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ãƒ©ãƒœ](ai-workshop-lab.md)** ã‚’å®Œäº†ã—ã¦å®Ÿè·µçš„ãªçµŒé¨“ã‚’å¾—ã‚‹
3. **[æœ¬ç•ªAIã®å®Ÿè·µ](production-ai-practices.md)** ã‚’å®Ÿè£…ã—ã¦ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒ‡ãƒ—ãƒ­ã‚¤ã‚’è¡Œã†
4. **[AIãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰](../troubleshooting/ai-troubleshooting.md)** ã‚’æ¢ç´¢ã—ã¦ä¸€èˆ¬çš„ãªå•é¡Œã‚’è§£æ±ºã™ã‚‹

## ãƒªã‚½ãƒ¼ã‚¹

- [Azure OpenAI ãƒ¢ãƒ‡ãƒ«ã®åˆ©ç”¨å¯èƒ½æ€§](https://learn.microsoft.com/azure/ai-services/openai/concepts/models)
- [Azure Developer CLI ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://learn.microsoft.com/azure/developer/azure-developer-cli/)
- [Container Apps ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°](https://learn.microsoft.com/azure/container-apps/scale-app)
- [AIãƒ¢ãƒ‡ãƒ«ã®ã‚³ã‚¹ãƒˆæœ€é©åŒ–](https://learn.microsoft.com/azure/ai-services/openai/how-to/manage-costs)

---

**ç« ã®ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³:**
- **ğŸ“š ã‚³ãƒ¼ã‚¹ãƒ›ãƒ¼ãƒ **: [AZD åˆå¿ƒè€…å‘ã‘](../../README.md)
- **ğŸ“– ç¾åœ¨ã®ç« **: ç¬¬2ç«  - AIãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆé–‹ç™º
- **â¬…ï¸ å‰ç« **: [Azure AI Foundry çµ±åˆ](azure-ai-foundry-integration.md)
- **â¡ï¸ æ¬¡ç« **: [AI ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ãƒ©ãƒœ](ai-workshop-lab.md)
- **ğŸš€ æ¬¡ã®ç« **: [ç¬¬3ç« : è¨­å®š](../getting-started/configuration.md)

---

**å…è²¬äº‹é …**:  
ã“ã®æ–‡æ›¸ã¯ã€AIç¿»è¨³ã‚µãƒ¼ãƒ“ã‚¹ [Co-op Translator](https://github.com/Azure/co-op-translator) ã‚’ä½¿ç”¨ã—ã¦ç¿»è¨³ã•ã‚Œã¦ã„ã¾ã™ã€‚æ­£ç¢ºæ€§ã‚’è¿½æ±‚ã—ã¦ãŠã‚Šã¾ã™ãŒã€è‡ªå‹•ç¿»è¨³ã«ã¯èª¤ã‚Šã‚„ä¸æ­£ç¢ºãªéƒ¨åˆ†ãŒå«ã¾ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’ã”æ‰¿çŸ¥ãã ã•ã„ã€‚å…ƒã®è¨€èªã§è¨˜è¼‰ã•ã‚ŒãŸæ–‡æ›¸ãŒæ­£å¼ãªæƒ…å ±æºã¨ã¿ãªã•ã‚Œã‚‹ã¹ãã§ã™ã€‚é‡è¦ãªæƒ…å ±ã«ã¤ã„ã¦ã¯ã€å°‚é–€ã®äººé–“ã«ã‚ˆã‚‹ç¿»è¨³ã‚’æ¨å¥¨ã—ã¾ã™ã€‚ã“ã®ç¿»è¨³ã®ä½¿ç”¨ã«èµ·å› ã™ã‚‹èª¤è§£ã‚„èª¤è§£ã«ã¤ã„ã¦ã€å½“æ–¹ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚