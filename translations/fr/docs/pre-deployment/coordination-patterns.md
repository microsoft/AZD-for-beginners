<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bcefbd5d0107691ef3e6e33ba694d6f4",
  "translation_date": "2025-11-19T16:36:33+00:00",
  "source_file": "docs/pre-deployment/coordination-patterns.md",
  "language_code": "fr"
}
-->
# ModÃ¨les de coordination multi-agents

â±ï¸ **Temps estimÃ©** : 60-75 minutes | ğŸ’° **CoÃ»t estimÃ©** : ~100-300 $/mois | â­ **ComplexitÃ©** : AvancÃ©

**ğŸ“š Parcours d'apprentissage :**
- â† PrÃ©cÃ©dent : [Planification de la capacitÃ©](capacity-planning.md) - StratÃ©gies de dimensionnement et de mise Ã  l'Ã©chelle des ressources
- ğŸ¯ **Vous Ãªtes ici** : ModÃ¨les de coordination multi-agents (Orchestration, communication, gestion des Ã©tats)
- â†’ Suivant : [SÃ©lection de SKU](sku-selection.md) - Choisir les bons services Azure
- ğŸ  [Accueil du cours](../../README.md)

---

## Ce que vous apprendrez

En complÃ©tant cette leÃ§on, vous serez capable de :
- Comprendre les **modÃ¨les d'architecture multi-agents** et savoir quand les utiliser
- ImplÃ©menter des **modÃ¨les d'orchestration** (centralisÃ©, dÃ©centralisÃ©, hiÃ©rarchique)
- Concevoir des stratÃ©gies de **communication entre agents** (synchrone, asynchrone, basÃ©e sur les Ã©vÃ©nements)
- GÃ©rer l'**Ã©tat partagÃ©** entre agents distribuÃ©s
- DÃ©ployer des **systÃ¨mes multi-agents** sur Azure avec AZD
- Appliquer des **modÃ¨les de coordination** Ã  des scÃ©narios d'IA rÃ©els
- Surveiller et dÃ©boguer des systÃ¨mes d'agents distribuÃ©s

## Pourquoi la coordination multi-agents est importante

### L'Ã©volution : d'un agent unique Ã  un systÃ¨me multi-agents

**Agent unique (simple) :**
```
User â†’ Agent â†’ Response
```
- âœ… Facile Ã  comprendre et Ã  implÃ©menter
- âœ… Rapide pour des tÃ¢ches simples
- âŒ LimitÃ© par les capacitÃ©s d'un seul modÃ¨le
- âŒ Impossible de parallÃ©liser des tÃ¢ches complexes
- âŒ Pas de spÃ©cialisation

**SystÃ¨me multi-agents (avancÃ©) :**
```
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Orchestratorâ”‚
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚         â”‚         â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”
    â”‚Agent1â”‚  â”‚Agent2â”‚  â”‚Agent3 â”‚
    â”‚(Plan)â”‚  â”‚(Code)â”‚  â”‚(Review)â”‚
    â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜
```
- âœ… Agents spÃ©cialisÃ©s pour des tÃ¢ches spÃ©cifiques
- âœ… ExÃ©cution parallÃ¨le pour plus de rapiditÃ©
- âœ… Modulaire et facile Ã  maintenir
- âœ… Meilleur pour les flux de travail complexes
- âš ï¸ NÃ©cessite une logique de coordination

**Analogie** : Un agent unique est comme une personne qui fait toutes les tÃ¢ches. Un systÃ¨me multi-agents est comme une Ã©quipe oÃ¹ chaque membre possÃ¨de des compÃ©tences spÃ©cialisÃ©es (chercheur, programmeur, relecteur, rÃ©dacteur) travaillant ensemble.

---

## ModÃ¨les de coordination principaux

### ModÃ¨le 1 : Coordination sÃ©quentielle (ChaÃ®ne de responsabilitÃ©)

**Quand l'utiliser** : Les tÃ¢ches doivent Ãªtre effectuÃ©es dans un ordre spÃ©cifique, chaque agent s'appuie sur la sortie prÃ©cÃ©dente.

```mermaid
sequenceDiagram
    participant Utilisateur
    participant Orchestrateur
    participant Agent1 as Agent de recherche
    participant Agent2 as Agent rÃ©dacteur
    participant Agent3 as Agent Ã©diteur
    
    Utilisateur->>Orchestrateur: "RÃ©digez un article sur l'IA"
    Orchestrateur->>Agent1: Recherche sur le sujet
    Agent1-->>Orchestrateur: RÃ©sultats de la recherche
    Orchestrateur->>Agent2: RÃ©digez un brouillon (en utilisant la recherche)
    Agent2-->>Orchestrateur: Brouillon de l'article
    Orchestrateur->>Agent3: Ã‰ditez et amÃ©liorez
    Agent3-->>Orchestrateur: Article final
    Orchestrateur-->>Utilisateur: Article peaufinÃ©
    
    Note over Utilisateur,Agent3: SÃ©quentiel : Chaque Ã©tape attend la prÃ©cÃ©dente
```
**Avantages :**
- âœ… Flux de donnÃ©es clair
- âœ… Facile Ã  dÃ©boguer
- âœ… Ordre d'exÃ©cution prÃ©visible

**Limitations :**
- âŒ Plus lent (pas de parallÃ©lisme)
- âŒ Une dÃ©faillance bloque toute la chaÃ®ne
- âŒ Ne peut pas gÃ©rer des tÃ¢ches interdÃ©pendantes

**Exemples d'utilisation :**
- Pipeline de crÃ©ation de contenu (recherche â†’ rÃ©daction â†’ Ã©dition â†’ publication)
- GÃ©nÃ©ration de code (planification â†’ implÃ©mentation â†’ test â†’ dÃ©ploiement)
- GÃ©nÃ©ration de rapports (collecte de donnÃ©es â†’ analyse â†’ visualisation â†’ rÃ©sumÃ©)

---

### ModÃ¨le 2 : Coordination parallÃ¨le (Fan-Out/Fan-In)

**Quand l'utiliser** : Les tÃ¢ches indÃ©pendantes peuvent Ãªtre exÃ©cutÃ©es simultanÃ©ment, les rÃ©sultats sont combinÃ©s Ã  la fin.

```mermaid
graph TB
    User[Demande de l'utilisateur]
    Orchestrator[Orchestrateur]
    Agent1[Agent d'analyse]
    Agent2[Agent de recherche]
    Agent3[Agent de donnÃ©es]
    Aggregator[AgrÃ©gateur de rÃ©sultats]
    Response[RÃ©ponse combinÃ©e]
    
    User --> Orchestrator
    Orchestrator --> Agent1
    Orchestrator --> Agent2
    Orchestrator --> Agent3
    Agent1 --> Aggregator
    Agent2 --> Aggregator
    Agent3 --> Aggregator
    Aggregator --> Response
    
    style Orchestrator fill:#2196F3,stroke:#1976D2,stroke-width:3px,color:#fff
    style Aggregator fill:#4CAF50,stroke:#388E3C,stroke-width:3px,color:#fff
```
**Avantages :**
- âœ… Rapide (exÃ©cution parallÃ¨le)
- âœ… TolÃ©rant aux pannes (rÃ©sultats partiels acceptables)
- âœ… Ã‰volutif horizontalement

**Limitations :**
- âš ï¸ Les rÃ©sultats peuvent arriver dans le dÃ©sordre
- âš ï¸ NÃ©cessite une logique d'agrÃ©gation
- âš ï¸ Gestion complexe des Ã©tats

**Exemples d'utilisation :**
- Collecte de donnÃ©es multi-sources (APIs + bases de donnÃ©es + scraping web)
- Analyse concurrentielle (plusieurs modÃ¨les gÃ©nÃ¨rent des solutions, la meilleure est sÃ©lectionnÃ©e)
- Services de traduction (traduire simultanÃ©ment dans plusieurs langues)

---

### ModÃ¨le 3 : Coordination hiÃ©rarchique (Manager-Travailleur)

**Quand l'utiliser** : Flux de travail complexes avec sous-tÃ¢ches, dÃ©lÃ©gation nÃ©cessaire.

```mermaid
graph TB
    Master[MaÃ®tre Orchestrateur]
    Manager1[Responsable de Recherche]
    Manager2[Responsable de Contenu]
    W1[Scraper Web]
    W2[Analyseur de Documents]
    W3[RÃ©dacteur]
    W4[Ã‰diteur]
    
    Master --> Manager1
    Master --> Manager2
    Manager1 --> W1
    Manager1 --> W2
    Manager2 --> W3
    Manager2 --> W4
    
    style Master fill:#FF9800,stroke:#F57C00,stroke-width:3px,color:#fff
    style Manager1 fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff
    style Manager2 fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff
```
**Avantages :**
- âœ… GÃ¨re des flux de travail complexes
- âœ… Modulaire et facile Ã  maintenir
- âœ… Limites de responsabilitÃ© claires

**Limitations :**
- âš ï¸ Architecture plus complexe
- âš ï¸ Latence plus Ã©levÃ©e (plusieurs couches de coordination)
- âš ï¸ NÃ©cessite une orchestration sophistiquÃ©e

**Exemples d'utilisation :**
- Traitement de documents d'entreprise (classer â†’ acheminer â†’ traiter â†’ archiver)
- Pipelines de donnÃ©es multi-Ã©tapes (ingestion â†’ nettoyage â†’ transformation â†’ analyse â†’ rapport)
- Flux de travail d'automatisation complexes (planification â†’ allocation des ressources â†’ exÃ©cution â†’ surveillance)

---

### ModÃ¨le 4 : Coordination basÃ©e sur les Ã©vÃ©nements (Publish-Subscribe)

**Quand l'utiliser** : Les agents doivent rÃ©agir Ã  des Ã©vÃ©nements, couplage lÃ¢che souhaitÃ©.

```mermaid
sequenceDiagram
    participant Agent1 as Collecteur de donnÃ©es
    participant EventBus as Azure Service Bus
    participant Agent2 as Analyseur
    participant Agent3 as Notificateur
    participant Agent4 as Archiviste
    
    Agent1->>EventBus: Publier l'Ã©vÃ©nement "DonnÃ©esReÃ§ues"
    EventBus->>Agent2: S'abonner : Analyser les donnÃ©es
    EventBus->>Agent3: S'abonner : Envoyer une notification
    EventBus->>Agent4: S'abonner : Archiver les donnÃ©es
    
    Note over Agent1,Agent4: Tous les abonnÃ©s traitent indÃ©pendamment
    
    Agent2->>EventBus: Publier l'Ã©vÃ©nement "AnalyseTerminÃ©e"
    EventBus->>Agent3: S'abonner : Envoyer le rapport d'analyse
```
**Avantages :**
- âœ… Couplage lÃ¢che entre agents
- âœ… Facile d'ajouter de nouveaux agents (simplement s'abonner)
- âœ… Traitement asynchrone
- âœ… RÃ©silient (persistance des messages)

**Limitations :**
- âš ï¸ CohÃ©rence Ã©ventuelle
- âš ï¸ DÃ©bogage complexe
- âš ï¸ ProblÃ¨mes d'ordre des messages

**Exemples d'utilisation :**
- SystÃ¨mes de surveillance en temps rÃ©el (alertes, tableaux de bord, journaux)
- Notifications multi-canaux (email, SMS, push, Slack)
- Pipelines de traitement de donnÃ©es (plusieurs consommateurs des mÃªmes donnÃ©es)

---

### ModÃ¨le 5 : Coordination basÃ©e sur le consensus (Vote/Quorum)

**Quand l'utiliser** : Accord nÃ©cessaire entre plusieurs agents avant de continuer.

```mermaid
graph TB
    Input[TÃ¢che d'entrÃ©e]
    Agent1[Agent 1 : GPT-4]
    Agent2[Agent 2 : Claude]
    Agent3[Agent 3 : Gemini]
    Voter[Votant par consensus]
    Output[RÃ©sultat convenu]
    
    Input --> Agent1
    Input --> Agent2
    Input --> Agent3
    Agent1 --> Voter
    Agent2 --> Voter
    Agent3 --> Voter
    Voter --> Output
    
    style Voter fill:#9C27B0,stroke:#7B1FA2,stroke-width:3px,color:#fff
```
**Avantages :**
- âœ… Plus grande prÃ©cision (opinions multiples)
- âœ… TolÃ©rant aux pannes (Ã©checs minoritaires acceptables)
- âœ… Assurance qualitÃ© intÃ©grÃ©e

**Limitations :**
- âŒ CoÃ»teux (appels multiples aux modÃ¨les)
- âŒ Plus lent (attente de tous les agents)
- âš ï¸ RÃ©solution des conflits nÃ©cessaire

**Exemples d'utilisation :**
- ModÃ©ration de contenu (plusieurs modÃ¨les examinent le contenu)
- Revue de code (plusieurs analyseurs/linter)
- Diagnostic mÃ©dical (plusieurs modÃ¨les d'IA, validation par des experts)

---

## AperÃ§u de l'architecture

### SystÃ¨me multi-agents complet sur Azure

```mermaid
graph TB
    User[Utilisateur/Client API]
    APIM[Gestion des API Azure]
    Orchestrator[Service Orchestrateur<br/>Application de conteneur]
    ServiceBus[Azure Service Bus<br/>Event Hub]
    
    Agent1[Agent de recherche<br/>Application de conteneur]
    Agent2[Agent rÃ©dacteur<br/>Application de conteneur]
    Agent3[Agent analyste<br/>Application de conteneur]
    Agent4[Agent rÃ©viseur<br/>Application de conteneur]
    
    CosmosDB[(Cosmos DB<br/>Ã‰tat partagÃ©)]
    Storage[Azure Storage<br/>Artefacts]
    AppInsights[Application Insights<br/>Surveillance]
    
    User --> APIM
    APIM --> Orchestrator
    
    Orchestrator --> ServiceBus
    ServiceBus --> Agent1
    ServiceBus --> Agent2
    ServiceBus --> Agent3
    ServiceBus --> Agent4
    
    Agent1 --> CosmosDB
    Agent2 --> CosmosDB
    Agent3 --> CosmosDB
    Agent4 --> CosmosDB
    
    Agent1 --> Storage
    Agent2 --> Storage
    Agent3 --> Storage
    Agent4 --> Storage
    
    Orchestrator -.-> AppInsights
    Agent1 -.-> AppInsights
    Agent2 -.-> AppInsights
    Agent3 -.-> AppInsights
    Agent4 -.-> AppInsights
    
    style Orchestrator fill:#FF9800,stroke:#F57C00,stroke-width:3px,color:#fff
    style ServiceBus fill:#9C27B0,stroke:#7B1FA2,stroke-width:3px,color:#fff
    style CosmosDB fill:#4CAF50,stroke:#388E3C,stroke-width:3px,color:#fff
```
**Composants clÃ©s :**

| Composant | Objectif | Service Azure |
|-----------|----------|---------------|
| **API Gateway** | Point d'entrÃ©e, limitation de dÃ©bit, authentification | API Management |
| **Orchestrateur** | Coordonne les flux de travail des agents | Container Apps |
| **File de messages** | Communication asynchrone | Service Bus / Event Hubs |
| **Agents** | Travailleurs IA spÃ©cialisÃ©s | Container Apps / Functions |
| **Stockage d'Ã©tat** | Ã‰tat partagÃ©, suivi des tÃ¢ches | Cosmos DB |
| **Stockage d'artefacts** | Documents, rÃ©sultats, journaux | Blob Storage |
| **Surveillance** | Traces distribuÃ©es, journaux | Application Insights |

---

## PrÃ©requis

### Outils requis

```bash
# VÃ©rifier Azure Developer CLI
azd version
# âœ… Attendu : version azd 1.0.0 ou supÃ©rieure

# VÃ©rifier Azure CLI
az --version
# âœ… Attendu : azure-cli 2.50.0 ou supÃ©rieure

# VÃ©rifier Docker (pour les tests locaux)
docker --version
# âœ… Attendu : version Docker 20.10 ou supÃ©rieure
```

### Exigences Azure

- Abonnement Azure actif
- Permissions pour crÃ©er :
  - Container Apps
  - Espaces de noms Service Bus
  - Comptes Cosmos DB
  - Comptes de stockage
  - Application Insights

### Connaissances prÃ©alables

Vous devriez avoir complÃ©tÃ© :
- [Gestion de la configuration](../getting-started/configuration.md)
- [Authentification et sÃ©curitÃ©](../getting-started/authsecurity.md)
- [Exemple de microservices](../../../../examples/microservices)

---

## Guide d'implÃ©mentation

### Structure du projet

```
multi-agent-system/
â”œâ”€â”€ azure.yaml                    # AZD configuration
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ main.bicep               # Main infrastructure
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ servicebus.bicep     # Message queue
â”‚   â”‚   â”œâ”€â”€ cosmos.bicep         # State store
â”‚   â”‚   â”œâ”€â”€ storage.bicep        # Artifact storage
â”‚   â”‚   â””â”€â”€ monitoring.bicep     # Application Insights
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ orchestrator.bicep   # Orchestrator service
â”‚       â””â”€â”€ agent.bicep          # Agent template
â””â”€â”€ src/
    â”œâ”€â”€ orchestrator/            # Orchestration logic
    â”‚   â”œâ”€â”€ app.py
    â”‚   â”œâ”€â”€ workflows.py
    â”‚   â””â”€â”€ Dockerfile
    â”œâ”€â”€ agents/
    â”‚   â”œâ”€â”€ research/            # Research agent
    â”‚   â”œâ”€â”€ writer/              # Writer agent
    â”‚   â”œâ”€â”€ analyst/             # Analyst agent
    â”‚   â””â”€â”€ reviewer/            # Reviewer agent
    â””â”€â”€ shared/
        â”œâ”€â”€ state_manager.py     # Shared state logic
        â””â”€â”€ message_handler.py   # Message handling
```

---

## LeÃ§on 1 : ModÃ¨le de coordination sÃ©quentielle

### ImplÃ©mentation : Pipeline de crÃ©ation de contenu

Construisons un pipeline sÃ©quentiel : Recherche â†’ RÃ©daction â†’ Ã‰dition â†’ Publication

### 1. Configuration AZD

**Fichier : `azure.yaml`**

```yaml
name: content-pipeline
metadata:
  template: multi-agent-sequential@1.0.0

services:
  orchestrator:
    project: ./src/orchestrator
    language: python
    host: containerapp
  
  research-agent:
    project: ./src/agents/research
    language: python
    host: containerapp
  
  writer-agent:
    project: ./src/agents/writer
    language: python
    host: containerapp
  
  editor-agent:
    project: ./src/agents/editor
    language: python
    host: containerapp
```

### 2. Infrastructure : Service Bus pour la coordination

**Fichier : `infra/core/servicebus.bicep`**

```bicep
param name string
param location string
param tags object = {}

resource serviceBusNamespace 'Microsoft.ServiceBus/namespaces@2022-10-01-preview' = {
  name: name
  location: location
  tags: tags
  sku: {
    name: 'Standard'
    tier: 'Standard'
  }
  properties: {
    minimumTlsVersion: '1.2'
  }
}

// Queue for orchestrator â†’ research agent
resource researchQueue 'Microsoft.ServiceBus/namespaces/queues@2022-10-01-preview' = {
  parent: serviceBusNamespace
  name: 'research-tasks'
  properties: {
    maxDeliveryCount: 3
    lockDuration: 'PT5M'
    deadLetteringOnMessageExpiration: true
  }
}

// Queue for research agent â†’ writer agent
resource writerQueue 'Microsoft.ServiceBus/namespaces/queues@2022-10-01-preview' = {
  parent: serviceBusNamespace
  name: 'writer-tasks'
  properties: {
    maxDeliveryCount: 3
    lockDuration: 'PT5M'
  }
}

// Queue for writer agent â†’ editor agent
resource editorQueue 'Microsoft.ServiceBus/namespaces/queues@2022-10-01-preview' = {
  parent: serviceBusNamespace
  name: 'editor-tasks'
  properties: {
    maxDeliveryCount: 3
    lockDuration: 'PT5M'
  }
}

output namespace string = serviceBusNamespace.name
output connectionString string = listKeys('${serviceBusNamespace.id}/AuthorizationRules/RootManageSharedAccessKey', serviceBusNamespace.apiVersion).primaryConnectionString
```

### 3. Gestionnaire d'Ã©tat partagÃ©

**Fichier : `src/shared/state_manager.py`**

```python
from azure.cosmos import CosmosClient, PartitionKey
from datetime import datetime
import os

class StateManager:
    """Manages shared state across agents using Cosmos DB"""
    
    def __init__(self):
        endpoint = os.environ['COSMOS_ENDPOINT']
        key = os.environ['COSMOS_KEY']
        
        self.client = CosmosClient(endpoint, key)
        self.database = self.client.get_database_client('agent-state')
        self.container = self.database.get_container_client('tasks')
    
    def create_task(self, task_id: str, task_type: str, input_data: dict):
        """Create a new task"""
        task = {
            'id': task_id,
            'type': task_type,
            'status': 'pending',
            'input': input_data,
            'created_at': datetime.utcnow().isoformat(),
            'steps': []
        }
        self.container.create_item(task)
        return task
    
    def update_task_step(self, task_id: str, step_name: str, result: dict):
        """Update task with completed step"""
        task = self.container.read_item(task_id, partition_key=task_id)
        
        task['steps'].append({
            'name': step_name,
            'completed_at': datetime.utcnow().isoformat(),
            'result': result
        })
        
        self.container.replace_item(task_id, task)
        return task
    
    def complete_task(self, task_id: str, final_result: dict):
        """Mark task as complete"""
        task = self.container.read_item(task_id, partition_key=task_id)
        task['status'] = 'completed'
        task['result'] = final_result
        task['completed_at'] = datetime.utcnow().isoformat()
        self.container.replace_item(task_id, task)
        return task
    
    def get_task(self, task_id: str):
        """Retrieve task state"""
        return self.container.read_item(task_id, partition_key=task_id)
```

### 4. Service orchestrateur

**Fichier : `src/orchestrator/app.py`**

```python
from flask import Flask, request, jsonify
from azure.servicebus import ServiceBusClient, ServiceBusMessage
import json
import uuid
import os
from shared.state_manager import StateManager

app = Flask(__name__)
state_manager = StateManager()

# Connexion au Service Bus
servicebus_connection_str = os.environ['SERVICEBUS_CONNECTION_STRING']
servicebus_client = ServiceBusClient.from_connection_string(servicebus_connection_str)

@app.route('/health', methods=['GET'])
def health():
    return jsonify({'status': 'healthy', 'service': 'orchestrator'})

@app.route('/create-content', methods=['POST'])
def create_content():
    """
    Sequential workflow: Research â†’ Write â†’ Edit â†’ Publish
    """
    data = request.json
    topic = data.get('topic')
    
    if not topic:
        return jsonify({'error': 'Topic required'}), 400
    
    # CrÃ©er une tÃ¢che dans le magasin d'Ã©tat
    task_id = str(uuid.uuid4())
    task = state_manager.create_task(
        task_id=task_id,
        task_type='content_creation',
        input_data={'topic': topic}
    )
    
    # Envoyer un message Ã  l'agent de recherche (premiÃ¨re Ã©tape)
    sender = servicebus_client.get_queue_sender('research-tasks')
    message = ServiceBusMessage(
        body=json.dumps({
            'task_id': task_id,
            'topic': topic,
            'next_queue': 'writer-tasks'  # OÃ¹ envoyer les rÃ©sultats
        }),
        content_type='application/json'
    )
    
    with sender:
        sender.send_messages(message)
    
    return jsonify({
        'task_id': task_id,
        'status': 'started',
        'workflow': 'sequential',
        'steps': ['research', 'write', 'edit', 'publish'],
        'message': 'Content creation pipeline initiated'
    }), 202

@app.route('/task/<task_id>', methods=['GET'])
def get_task_status(task_id):
    """Check task status"""
    try:
        task = state_manager.get_task(task_id)
        return jsonify(task)
    except Exception as e:
        return jsonify({'error': str(e)}), 404

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
```

### 5. Agent de recherche

**Fichier : `src/agents/research/app.py`**

```python
from azure.servicebus import ServiceBusClient, ServiceBusMessage
from openai import AzureOpenAI
import json
import os
import time
from shared.state_manager import StateManager

# Initialiser les clients
state_manager = StateManager()
servicebus_client = ServiceBusClient.from_connection_string(
    os.environ['SERVICEBUS_CONNECTION_STRING']
)

openai_client = AzureOpenAI(
    api_key=os.environ['AZURE_OPENAI_API_KEY'],
    api_version="2024-02-01",
    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT']
)

def process_research_task(message_data):
    """Process research request and pass to writer"""
    task_id = message_data['task_id']
    topic = message_data['topic']
    next_queue = message_data['next_queue']
    
    print(f"ğŸ”¬ Researching: {topic}")
    
    # Appeler Azure OpenAI pour la recherche
    response = openai_client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are a research assistant. Provide comprehensive research on the given topic."},
            {"role": "user", "content": f"Research this topic thoroughly: {topic}"}
        ],
        max_tokens=1500
    )
    
    research_results = response.choices[0].message.content
    
    # Mettre Ã  jour l'Ã©tat
    state_manager.update_task_step(
        task_id=task_id,
        step_name='research',
        result={'research': research_results}
    )
    
    # Envoyer au prochain agent (rÃ©dacteur)
    sender = servicebus_client.get_queue_sender(next_queue)
    message = ServiceBusMessage(
        body=json.dumps({
            'task_id': task_id,
            'topic': topic,
            'research': research_results,
            'next_queue': 'editor-tasks'
        }),
        content_type='application/json'
    )
    
    with sender:
        sender.send_messages(message)
    
    print(f"âœ… Research complete for task {task_id}")

def main():
    """Listen to research queue"""
    receiver = servicebus_client.get_queue_receiver('research-tasks')
    
    print("ğŸ”¬ Research Agent started, listening for tasks...")
    
    with receiver:
        while True:
            messages = receiver.receive_messages(max_wait_time=5)
            for message in messages:
                try:
                    message_data = json.loads(str(message))
                    process_research_task(message_data)
                    receiver.complete_message(message)
                except Exception as e:
                    print(f"âŒ Error processing message: {e}")
                    receiver.abandon_message(message)

if __name__ == '__main__':
    main()
```

### 6. Agent rÃ©dacteur

**Fichier : `src/agents/writer/app.py`**

```python
from azure.servicebus import ServiceBusClient, ServiceBusMessage
from openai import AzureOpenAI
import json
import os
from shared.state_manager import StateManager

state_manager = StateManager()
servicebus_client = ServiceBusClient.from_connection_string(
    os.environ['SERVICEBUS_CONNECTION_STRING']
)

openai_client = AzureOpenAI(
    api_key=os.environ['AZURE_OPENAI_API_KEY'],
    api_version="2024-02-01",
    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT']
)

def process_writing_task(message_data):
    """Write article based on research"""
    task_id = message_data['task_id']
    topic = message_data['topic']
    research = message_data['research']
    next_queue = message_data['next_queue']
    
    print(f"âœï¸ Writing article: {topic}")
    
    # Appeler Azure OpenAI pour rÃ©diger un article
    response = openai_client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are a professional writer. Write engaging, well-structured articles."},
            {"role": "user", "content": f"Based on this research:\n\n{research}\n\nWrite a comprehensive article about: {topic}"}
        ],
        max_tokens=2000
    )
    
    article_draft = response.choices[0].message.content
    
    # Mettre Ã  jour l'Ã©tat
    state_manager.update_task_step(
        task_id=task_id,
        step_name='writing',
        result={'draft': article_draft}
    )
    
    # Envoyer Ã  l'Ã©diteur
    sender = servicebus_client.get_queue_sender(next_queue)
    message = ServiceBusMessage(
        body=json.dumps({
            'task_id': task_id,
            'topic': topic,
            'draft': article_draft
        }),
        content_type='application/json'
    )
    
    with sender:
        sender.send_messages(message)
    
    print(f"âœ… Article draft complete for task {task_id}")

def main():
    """Listen to writer queue"""
    receiver = servicebus_client.get_queue_receiver('writer-tasks')
    
    print("âœï¸ Writer Agent started, listening for tasks...")
    
    with receiver:
        while True:
            messages = receiver.receive_messages(max_wait_time=5)
            for message in messages:
                try:
                    message_data = json.loads(str(message))
                    process_writing_task(message_data)
                    receiver.complete_message(message)
                except Exception as e:
                    print(f"âŒ Error: {e}")
                    receiver.abandon_message(message)

if __name__ == '__main__':
    main()
```

### 7. Agent Ã©diteur

**Fichier : `src/agents/editor/app.py`**

```python
from azure.servicebus import ServiceBusClient
from openai import AzureOpenAI
import json
import os
from shared.state_manager import StateManager

state_manager = StateManager()
servicebus_client = ServiceBusClient.from_connection_string(
    os.environ['SERVICEBUS_CONNECTION_STRING']
)

openai_client = AzureOpenAI(
    api_key=os.environ['AZURE_OPENAI_API_KEY'],
    api_version="2024-02-01",
    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT']
)

def process_editing_task(message_data):
    """Edit and finalize article"""
    task_id = message_data['task_id']
    topic = message_data['topic']
    draft = message_data['draft']
    
    print(f"ğŸ“ Editing article: {topic}")
    
    # Appeler Azure OpenAI pour modifier
    response = openai_client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are an expert editor. Improve grammar, clarity, and structure."},
            {"role": "user", "content": f"Edit and improve this article:\n\n{draft}"}
        ],
        max_tokens=2000
    )
    
    final_article = response.choices[0].message.content
    
    # Marquer la tÃ¢che comme terminÃ©e
    state_manager.complete_task(
        task_id=task_id,
        final_result={
            'topic': topic,
            'final_article': final_article,
            'word_count': len(final_article.split())
        }
    )
    
    print(f"âœ… Article finalized for task {task_id}")

def main():
    """Listen to editor queue"""
    receiver = servicebus_client.get_queue_receiver('editor-tasks')
    
    print("ğŸ“ Editor Agent started, listening for tasks...")
    
    with receiver:
        while True:
            messages = receiver.receive_messages(max_wait_time=5)
            for message in messages:
                try:
                    message_data = json.loads(str(message))
                    process_editing_task(message_data)
                    receiver.complete_message(message)
                except Exception as e:
                    print(f"âŒ Error: {e}")
                    receiver.abandon_message(message)

if __name__ == '__main__':
    main()
```

### 8. DÃ©ployer et tester

```bash
# Initialiser et dÃ©ployer
azd init
azd up

# Obtenir l'URL de l'orchestrateur
ORCHESTRATOR_URL=$(azd env get-values | grep ORCHESTRATOR_URL | cut -d '=' -f2 | tr -d '"')

# CrÃ©er du contenu
curl -X POST $ORCHESTRATOR_URL/create-content \
  -H "Content-Type: application/json" \
  -d '{"topic": "The Future of AI in Healthcare"}'
```

**âœ… RÃ©sultat attendu :**
```json
{
  "task_id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "status": "started",
  "workflow": "sequential",
  "steps": ["research", "write", "edit", "publish"],
  "message": "Content creation pipeline initiated"
}
```

**VÃ©rifiez la progression des tÃ¢ches :**
```bash
TASK_ID="a1b2c3d4-e5f6-7890-abcd-ef1234567890"
curl $ORCHESTRATOR_URL/task/$TASK_ID
```

**âœ… RÃ©sultat attendu (terminÃ©) :**
```json
{
  "id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "type": "content_creation",
  "status": "completed",
  "steps": [
    {
      "name": "research",
      "completed_at": "2025-11-19T10:30:00Z",
      "result": {"research": "..."}
    },
    {
      "name": "writing",
      "completed_at": "2025-11-19T10:32:00Z",
      "result": {"draft": "..."}
    }
  ],
  "result": {
    "topic": "The Future of AI in Healthcare",
    "final_article": "...",
    "word_count": 1500
  }
}
```

---

## LeÃ§on 2 : ModÃ¨le de coordination parallÃ¨le

### ImplÃ©mentation : AgrÃ©gateur de recherche multi-sources

Construisons un systÃ¨me parallÃ¨le qui collecte des informations de plusieurs sources simultanÃ©ment.

### Orchestrateur parallÃ¨le

**Fichier : `src/orchestrator/parallel_workflow.py`**

```python
from flask import Flask, request, jsonify
from azure.servicebus import ServiceBusClient, ServiceBusMessage
import json
import uuid
import os
from shared.state_manager import StateManager

app = Flask(__name__)
state_manager = StateManager()

servicebus_client = ServiceBusClient.from_connection_string(
    os.environ['SERVICEBUS_CONNECTION_STRING']
)

@app.route('/research-parallel', methods=['POST'])
def research_parallel():
    """
    Parallel workflow: Multiple agents work simultaneously
    """
    data = request.json
    query = data.get('query')
    
    task_id = str(uuid.uuid4())
    task = state_manager.create_task(
        task_id=task_id,
        task_type='parallel_research',
        input_data={
            'query': query,
            'agents': ['web', 'academic', 'news', 'social']
        }
    )
    
    # Diffusion : Envoyer Ã  tous les agents simultanÃ©ment
    agents = [
        ('web-research-queue', 'web'),
        ('academic-research-queue', 'academic'),
        ('news-research-queue', 'news'),
        ('social-research-queue', 'social')
    ]
    
    for queue_name, agent_type in agents:
        sender = servicebus_client.get_queue_sender(queue_name)
        message = ServiceBusMessage(
            body=json.dumps({
                'task_id': task_id,
                'query': query,
                'agent_type': agent_type,
                'result_queue': 'aggregation-queue'
            }),
            content_type='application/json'
        )
        
        with sender:
            sender.send_messages(message)
    
    return jsonify({
        'task_id': task_id,
        'status': 'started',
        'workflow': 'parallel',
        'agents_dispatched': 4,
        'message': 'Parallel research initiated'
    }), 202

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
```

### Logique d'agrÃ©gation

**Fichier : `src/agents/aggregator/app.py`**

```python
from azure.servicebus import ServiceBusClient
import json
import os
from collections import defaultdict
from shared.state_manager import StateManager

state_manager = StateManager()
servicebus_client = ServiceBusClient.from_connection_string(
    os.environ['SERVICEBUS_CONNECTION_STRING']
)

# Suivre les rÃ©sultats par tÃ¢che
task_results = defaultdict(list)
expected_agents = 4  # web, acadÃ©mique, actualitÃ©s, social

def process_result(message_data):
    """Aggregate results from parallel agents"""
    task_id = message_data['task_id']
    agent_type = message_data['agent_type']
    result = message_data['result']
    
    # Stocker le rÃ©sultat
    task_results[task_id].append({
        'agent': agent_type,
        'data': result
    })
    
    print(f"ğŸ“Š Received result from {agent_type} agent ({len(task_results[task_id])}/{expected_agents})")
    
    # VÃ©rifier si tous les agents ont terminÃ© (fan-in)
    if len(task_results[task_id]) == expected_agents:
        print(f"âœ… All agents completed for task {task_id}. Aggregating...")
        
        # Combiner les rÃ©sultats
        aggregated = {
            'query': message_data['query'],
            'sources': task_results[task_id],
            'summary': generate_summary(task_results[task_id])
        }
        
        # Marquer comme terminÃ©
        state_manager.complete_task(task_id, aggregated)
        
        # Nettoyer
        del task_results[task_id]
        
        print(f"âœ… Aggregation complete for task {task_id}")

def generate_summary(results):
    """Generate summary from all sources"""
    summaries = [r['data'].get('summary', '') for r in results]
    return '\n\n'.join(summaries)

def main():
    """Listen to aggregation queue"""
    receiver = servicebus_client.get_queue_receiver('aggregation-queue')
    
    print("ğŸ“Š Aggregator started, listening for results...")
    
    with receiver:
        while True:
            messages = receiver.receive_messages(max_wait_time=5)
            for message in messages:
                try:
                    message_data = json.loads(str(message))
                    process_result(message_data)
                    receiver.complete_message(message)
                except Exception as e:
                    print(f"âŒ Error: {e}")
                    receiver.abandon_message(message)

if __name__ == '__main__':
    main()
```

**Avantages du modÃ¨le parallÃ¨le :**
- âš¡ **4x plus rapide** (les agents fonctionnent simultanÃ©ment)
- ğŸ”„ **TolÃ©rant aux pannes** (rÃ©sultats partiels acceptables)
- ğŸ“ˆ **Ã‰volutif** (ajouter facilement plus d'agents)

---

## Exercices pratiques

### Exercice 1 : Ajouter une gestion des dÃ©lais â­â­ (Moyen)

**Objectif** : ImplÃ©menter une logique de dÃ©lai pour que l'agrÃ©gateur ne reste pas bloquÃ© indÃ©finiment Ã  cause d'agents lents.

**Ã‰tapes** :

1. **Ajoutez le suivi des dÃ©lais Ã  l'agrÃ©gateur :**

```python
from datetime import datetime, timedelta

task_timeouts = {}  # task_id -> temps d'expiration

def process_result(message_data):
    task_id = message_data['task_id']
    
    # DÃ©finir un dÃ©lai d'attente sur le premier rÃ©sultat
    if task_id not in task_timeouts:
        task_timeouts[task_id] = datetime.utcnow() + timedelta(seconds=30)
    
    task_results[task_id].append({
        'agent': message_data['agent_type'],
        'data': message_data['result']
    })
    
    # VÃ©rifier si terminÃ© OU expirÃ©
    if len(task_results[task_id]) == expected_agents or \
       datetime.utcnow() > task_timeouts[task_id]:
        
        print(f"ğŸ“Š Aggregating with {len(task_results[task_id])}/{expected_agents} results")
        
        aggregated = {
            'query': message_data['query'],
            'sources': task_results[task_id],
            'completed_agents': len(task_results[task_id]),
            'timed_out': len(task_results[task_id]) < expected_agents
        }
        
        state_manager.complete_task(task_id, aggregated)
        
        # Nettoyage
        del task_results[task_id]
        del task_timeouts[task_id]
```

2. **Testez avec des retards artificiels :**

```python
# Dans un agent, ajoutez un dÃ©lai pour simuler un traitement lent
import time
time.sleep(35)  # DÃ©passe le dÃ©lai d'attente de 30 secondes
```

3. **DÃ©ployez et vÃ©rifiez :**

```bash
azd deploy aggregator

# Soumettre la tÃ¢che
curl -X POST $ORCHESTRATOR_URL/research-parallel \
  -H "Content-Type: application/json" \
  -d '{"query": "AI safety research"}'

# VÃ©rifier les rÃ©sultats aprÃ¨s 30 secondes
curl $ORCHESTRATOR_URL/task/$TASK_ID
```

**âœ… CritÃ¨res de rÃ©ussite :**
- âœ… La tÃ¢che se termine aprÃ¨s 30 secondes mÃªme si certains agents ne sont pas terminÃ©s
- âœ… La rÃ©ponse indique des rÃ©sultats partiels (`"timed_out": true`)
- âœ… Les rÃ©sultats disponibles sont retournÃ©s (3 sur 4 agents)

**Temps** : 20-25 minutes

---

### Exercice 2 : ImplÃ©menter une logique de reprise â­â­â­ (AvancÃ©)

**Objectif** : RÃ©essayer automatiquement les tÃ¢ches des agents Ã©chouÃ©es avant d'abandonner.

**Ã‰tapes** :

1. **Ajoutez le suivi des reprises Ã  l'orchestrateur :**

```python
from dataclasses import dataclass
from typing import Dict

@dataclass
class RetryConfig:
    max_retries: int = 3
    backoff_seconds: int = 5

retry_counts: Dict[str, int] = {}  # message_id -> nombre_de_tentatives

def send_with_retry(queue_name: str, message_data: dict, retry_config: RetryConfig):
    """Send message with retry metadata"""
    message_id = message_data.get('message_id', str(uuid.uuid4()))
    message_data['message_id'] = message_id
    message_data['retry_count'] = retry_counts.get(message_id, 0)
    message_data['max_retries'] = retry_config.max_retries
    
    sender = servicebus_client.get_queue_sender(queue_name)
    message = ServiceBusMessage(
        body=json.dumps(message_data),
        content_type='application/json',
        message_id=message_id
    )
    
    with sender:
        sender.send_messages(message)
```

2. **Ajoutez un gestionnaire de reprise aux agents :**

```python
def process_with_retry(message, receiver, process_func):
    """Process message with automatic retry on failure"""
    try:
        message_data = json.loads(str(message))
        
        # Traiter le message
        process_func(message_data)
        
        # SuccÃ¨s - terminÃ©
        receiver.complete_message(message)
        
    except Exception as e:
        message_id = message.message_id
        retry_count = message_data.get('retry_count', 0)
        max_retries = message_data.get('max_retries', 3)
        
        if retry_count < max_retries:
            # RÃ©essayer : abandonner et remettre en file d'attente avec un compte incrÃ©mentÃ©
            print(f"âš ï¸ Retry {retry_count + 1}/{max_retries} for message {message_id}")
            
            message_data['retry_count'] = retry_count + 1
            
            # Renvoyer dans la mÃªme file avec un dÃ©lai
            time.sleep(5 * (retry_count + 1))  # Recul exponentiel
            send_with_retry(queue_name, message_data, RetryConfig())
            
            receiver.complete_message(message)  # Supprimer l'original
        else:
            # Nombre maximal de tentatives dÃ©passÃ© - dÃ©placer vers la file des lettres mortes
            print(f"âŒ Max retries exceeded for message {message_id}")
            receiver.dead_letter_message(
                message,
                reason="MaxRetriesExceeded",
                error_description=str(e)
            )
```

3. **Surveillez la file d'attente des messages morts :**

```python
def monitor_dead_letters():
    """Check dead letter queue for failed messages"""
    receiver = servicebus_client.get_queue_receiver(
        'research-queue',
        sub_queue='deadletter'
    )
    
    with receiver:
        messages = receiver.receive_messages(max_wait_time=5)
        for message in messages:
            print(f"â˜ ï¸ Dead letter: {message.message_id}")
            print(f"Reason: {message.dead_letter_reason}")
            print(f"Description: {message.dead_letter_error_description}")
```

**âœ… CritÃ¨res de rÃ©ussite :**
- âœ… Les tÃ¢ches Ã©chouÃ©es sont automatiquement rÃ©essayÃ©es (jusqu'Ã  3 fois)
- âœ… Retard exponentiel entre les reprises (5s, 10s, 15s)
- âœ… AprÃ¨s le nombre maximal de reprises, les messages vont dans la file d'attente des messages morts
- âœ… La file d'attente des messages morts peut Ãªtre surveillÃ©e et rejouÃ©e

**Temps** : 30-40 minutes

---

### Exercice 3 : ImplÃ©menter un disjoncteur â­â­â­ (AvancÃ©)

**Objectif** : EmpÃªcher les dÃ©faillances en cascade en arrÃªtant les requÃªtes vers les agents dÃ©faillants.

**Ã‰tapes** :

1. **CrÃ©ez une classe de disjoncteur :**

```python
from enum import Enum
from datetime import datetime, timedelta

class CircuitState(Enum):
    CLOSED = "closed"      # Fonctionnement normal
    OPEN = "open"          # Ã‰chec, rejeter les demandes
    HALF_OPEN = "half_open"  # Test si rÃ©cupÃ©rÃ©

class CircuitBreaker:
    def __init__(self, failure_threshold=5, timeout_seconds=60):
        self.failure_threshold = failure_threshold
        self.timeout_seconds = timeout_seconds
        self.failure_count = 0
        self.last_failure_time = None
        self.state = CircuitState.CLOSED
    
    def call(self, func):
        """Execute function with circuit breaker protection"""
        if self.state == CircuitState.OPEN:
            # VÃ©rifier si le dÃ©lai est expirÃ©
            if datetime.utcnow() - self.last_failure_time > timedelta(seconds=self.timeout_seconds):
                self.state = CircuitState.HALF_OPEN
                print("ğŸ”„ Circuit breaker: HALF_OPEN (testing)")
            else:
                raise Exception(f"Circuit breaker OPEN for agent. Try again in {self.timeout_seconds}s")
        
        try:
            result = func()
            
            # SuccÃ¨s
            if self.state == CircuitState.HALF_OPEN:
                self.state = CircuitState.CLOSED
                self.failure_count = 0
                print("âœ… Circuit breaker: CLOSED (recovered)")
            
            return result
            
        except Exception as e:
            self.failure_count += 1
            self.last_failure_time = datetime.utcnow()
            
            if self.failure_count >= self.failure_threshold:
                self.state = CircuitState.OPEN
                print(f"ğŸ”´ Circuit breaker: OPEN (too many failures)")
            
            raise e
```

2. **Appliquez-la aux appels des agents :**

```python
# Dans l'orchestrateur
agent_circuits = {
    'web': CircuitBreaker(failure_threshold=5, timeout_seconds=60),
    'academic': CircuitBreaker(failure_threshold=5, timeout_seconds=60),
    'news': CircuitBreaker(failure_threshold=5, timeout_seconds=60),
    'social': CircuitBreaker(failure_threshold=5, timeout_seconds=60)
}

def send_to_agent(agent_type, message_data):
    """Send with circuit breaker protection"""
    circuit = agent_circuits[agent_type]
    
    try:
        circuit.call(lambda: send_message(agent_type, message_data))
    except Exception as e:
        print(f"âš ï¸ Skipping {agent_type} agent: {e}")
        # Continuer avec d'autres agents
```

3. **Testez le disjoncteur :**

```bash
# Simuler des Ã©checs rÃ©pÃ©tÃ©s (arrÃªter un agent)
az containerapp stop --name web-research-agent --resource-group rg-agents

# Envoyer plusieurs requÃªtes
for i in {1..10}; do
  curl -X POST $ORCHESTRATOR_URL/research-parallel \
    -H "Content-Type: application/json" \
    -d '{"query": "test query '$i'"}'
  sleep 2
done

# VÃ©rifier les journaux - devrait voir le circuit ouvert aprÃ¨s 5 Ã©checs
azd logs orchestrator --tail 50
```

**âœ… CritÃ¨res de rÃ©ussite :**
- âœ… AprÃ¨s 5 Ã©checs, le disjoncteur s'ouvre (rejette les requÃªtes)
- âœ… AprÃ¨s 60 secondes, le disjoncteur passe en semi-ouvert (teste la rÃ©cupÃ©ration)
- âœ… Les autres agents continuent de fonctionner normalement
- âœ… Le disjoncteur se ferme automatiquement lorsque l'agent se rÃ©tablit

**Temps** : 40-50 minutes

---

## Surveillance et dÃ©bogage

### Traces distribuÃ©es avec Application Insights

**Fichier : `src/shared/tracing.py`**

```python
from opencensus.ext.azure.log_exporter import AzureLogHandler
from opencensus.ext.azure.trace_exporter import AzureExporter
from opencensus.trace import config_integration
from opencensus.trace.tracer import Tracer
from opencensus.trace.samplers import AlwaysOnSampler
import logging
import os

# Configurer la traÃ§abilitÃ©
config_integration.trace_integrations(['requests', 'logging'])

connection_string = os.environ.get('APPLICATIONINSIGHTS_CONNECTION_STRING')

# CrÃ©er un traceur
tracer = Tracer(
    exporter=AzureExporter(connection_string=connection_string),
    sampler=AlwaysOnSampler()
)

# Configurer la journalisation
logger = logging.getLogger(__name__)
logger.addHandler(AzureLogHandler(connection_string=connection_string))
logger.setLevel(logging.INFO)

def trace_agent_call(agent_name, task_id, operation):
    """Trace agent operations"""
    with tracer.span(name=f'{agent_name}.{operation}') as span:
        span.add_attribute('agent', agent_name)
        span.add_attribute('task_id', task_id)
        span.add_attribute('operation', operation)
        
        try:
            result = operation()
            span.add_attribute('status', 'success')
            return result
        except Exception as e:
            span.add_attribute('status', 'error')
            span.add_attribute('error', str(e))
            raise
```

### RequÃªtes Application Insights

**Suivre les flux de travail multi-agents :**

```kusto
// Trace complete workflow for a task
traces
| where customDimensions.task_id == "a1b2c3d4-..."
| project timestamp, message, customDimensions.agent, customDimensions.operation
| order by timestamp asc
```

**Comparaison des performances des agents :**

```kusto
// Compare agent execution times
dependencies
| where name contains "agent"
| summarize 
    avg_duration = avg(duration),
    p95_duration = percentile(duration, 95),
    count = count()
  by agent = tostring(customDimensions.agent)
| order by avg_duration desc
```

**Analyse des Ã©checs :**

```kusto
// Find which agents fail most
exceptions
| where customDimensions.agent != ""
| summarize 
    failure_count = count(),
    unique_errors = dcount(outerMessage)
  by agent = tostring(customDimensions.agent)
| order by failure_count desc
```

---

## Analyse des coÃ»ts

### CoÃ»ts des systÃ¨mes multi-agents (estimations mensuelles)

| Composant | Configuration | CoÃ»t |
|-----------|---------------|------|
| **Orchestrateur** | 1 Container App (1 vCPU, 2GB) | 30-50 $ |
| **4 Agents** | 4 Container Apps (0.5 vCPU, 1GB chacun) | 60-120 $ |
| **Service Bus** | Niveau standard, 10M messages | 10-20 $ |
| **Cosmos DB** | Serverless, 5GB de stockage, 1M RUs | 25-50 $ |
| **Blob Storage** | 10GB de stockage, 100K opÃ©rations | 5-10 $ |
| **Application Insights** | 5GB d'ingestion | 10-15 $ |
| **Azure OpenAI** | GPT-4, 10M tokens | 100-300 $ |
| **Total** | | **240-565 $/mois** |

### StratÃ©gies d'optimisation des coÃ»ts

1. **Utilisez le serverless autant que possible :**
   ```bicep
   // Cosmos DB serverless (no minimum cost)
   properties: {
     databaseAccountOfferType: 'Standard'
     capabilities: [{ name: 'EnableServerless' }]
   }
   ```

2. **RÃ©duisez les agents Ã  zÃ©ro lorsqu'ils sont inactifs :**
   ```bicep
   scale: {
     minReplicas: 0  // Scale to zero when no messages
     maxReplicas: 10
   }
   ```

3. **Utilisez le regroupement pour Service Bus :**
   ```python
   # Envoyer des messages par lots (moins cher)
   sender.send_messages([message1, message2, message3])
   ```

4. **Mettez en cache les rÃ©sultats frÃ©quemment utilisÃ©s :**
   ```python
   # Utiliser Azure Cache pour Redis
   if cache.exists(query_hash):
       return cache.get(query_hash)
   ```

---

## Bonnes pratiques

### âœ… Ã€ FAIRE :

1. **Utilisez des opÃ©rations idempotentes**
   ```python
   # L'agent peut traiter en toute sÃ©curitÃ© le mÃªme message plusieurs fois
   def process_task(task_id):
       if state_manager.task_exists(task_id):
           print(f"Task {task_id} already processed, skipping")
           return
       # Traiter la tÃ¢che...
   ```

2. **ImplÃ©mentez une journalisation complÃ¨te**
   ```python
   logger.info(f"Agent: {agent_name}, Task: {task_id}, Action: {action}")
   ```

3. **Utilisez des IDs de corrÃ©lation**
   ```python
   # Transmettre task_id Ã  travers tout le flux de travail
   message_data = {
       'task_id': task_id,  # ID de corrÃ©lation
       'timestamp': datetime.utcnow().isoformat()
   }
   ```

4. **DÃ©finissez une durÃ©e de vie des messages (TTL)**
   ```bicep
   properties: {
     defaultMessageTimeToLive: 'PT1H'  // 1 hour max
   }
   ```

5. **Surveillez les files d'attente des messages morts**
   ```python
   # Surveillance rÃ©guliÃ¨re des messages Ã©chouÃ©s
   monitor_dead_letters()
   ```

### âŒ Ã€ NE PAS FAIRE :

1. **Ne crÃ©ez pas de dÃ©pendances circulaires**
   ```python
   # âŒ MAUVAIS : Agent A â†’ Agent B â†’ Agent A (boucle infinie)
   # âœ… BON : DÃ©finir un graphe orientÃ© acyclique clair (DAG)
   ```

2. **Ne bloquez pas les threads des agents**
   ```python
   # âŒ MAUVAIS : Attente synchrone
   while not task_complete:
       time.sleep(1)
   
   # âœ… BON : Utiliser les rappels de la file de messages
   ```

3. **Ne nÃ©gligez pas les Ã©checs partiels**
   ```python
   # âŒ MAUVAIS : Ã‰chouer tout le processus si un agent Ã©choue
   # âœ… BON : Retourner des rÃ©sultats partiels avec des indicateurs d'erreur
   ```

4. **N'utilisez pas de reprises infinies**
   ```python
   # âŒ MAUVAIS : rÃ©essayer indÃ©finiment
   # âœ… BON : max_retries = 3, puis lettre morte
   ```

---
## Guide de dÃ©pannage

### ProblÃ¨me : Messages bloquÃ©s dans la file d'attente

**SymptÃ´mes :**
- Les messages s'accumulent dans la file d'attente
- Les agents ne traitent pas
- Le statut de la tÃ¢che reste Ã  "en attente"

**Diagnostic :**
```bash
# VÃ©rifier la profondeur de la file d'attente
az servicebus queue show \
  --namespace-name mybus \
  --name research-tasks \
  --query "countDetails"

# VÃ©rifier la santÃ© de l'agent
azd logs research-agent --tail 50
```

**Solutions :**

1. **Augmenter le nombre de rÃ©plicas d'agents :**
   ```bash
   az containerapp update \
     --name research-agent \
     --min-replicas 3 \
     --max-replicas 10
   ```

2. **VÃ©rifier la file d'attente des lettres mortes :**
   ```bash
   az servicebus queue show \
     --namespace-name mybus \
     --name research-tasks \
     --query "countDetails.deadLetterMessageCount"
   ```

---

### ProblÃ¨me : Expiration de la tÃ¢che / ne se termine jamais

**SymptÃ´mes :**
- Le statut de la tÃ¢che reste "en cours"
- Certains agents terminent, d'autres non
- Aucun message d'erreur

**Diagnostic :**
```bash
# VÃ©rifier l'Ã©tat de la tÃ¢che
curl $ORCHESTRATOR_URL/task/$TASK_ID

# VÃ©rifier Application Insights
# ExÃ©cuter la requÃªte : traces | where customDimensions.task_id == "..."
```

**Solutions :**

1. **ImplÃ©menter un dÃ©lai d'expiration dans l'agrÃ©gateur (Exercice 1)**

2. **VÃ©rifier les Ã©checs des agents :**
   ```bash
   azd logs --follow | grep "ERROR\|FAIL"
   ```

3. **S'assurer que tous les agents fonctionnent :**
   ```bash
   az containerapp list \
     --resource-group rg-agents \
     --query "[].{name:name, status:properties.runningStatus}"
   ```

---

## En savoir plus

### Documentation officielle
- [Azure Service Bus](https://learn.microsoft.com/azure/service-bus-messaging/service-bus-messaging-overview)
- [Cosmos DB](https://learn.microsoft.com/azure/cosmos-db/introduction)
- [Container Apps DAPR](https://learn.microsoft.com/azure/container-apps/dapr-overview)
- [ModÃ¨les de conception multi-agents](https://learn.microsoft.com/azure/architecture/guide/ai/multi-agent-systems)

### Prochaines Ã©tapes dans ce cours
- â† PrÃ©cÃ©dent : [Planification de capacitÃ©](capacity-planning.md)
- â†’ Suivant : [SÃ©lection de SKU](sku-selection.md)
- ğŸ  [Accueil du cours](../../README.md)

### Exemples associÃ©s
- [Exemple de microservices](../../../../examples/microservices) - ModÃ¨les de communication entre services
- [Exemple Azure OpenAI](../../../../examples/azure-openai-chat) - IntÃ©gration de l'IA

---

## RÃ©sumÃ©

**Vous avez appris :**
- âœ… Cinq modÃ¨les de coordination (sÃ©quentiel, parallÃ¨le, hiÃ©rarchique, Ã©vÃ©nementiel, consensus)
- âœ… Architecture multi-agents sur Azure (Service Bus, Cosmos DB, Container Apps)
- âœ… Gestion des Ã©tats entre agents distribuÃ©s
- âœ… Gestion des dÃ©lais d'expiration, des reprises et des disjoncteurs
- âœ… Surveillance et dÃ©bogage des systÃ¨mes distribuÃ©s
- âœ… StratÃ©gies d'optimisation des coÃ»ts

**Points clÃ©s :**
1. **Choisir le bon modÃ¨le** - SÃ©quentiel pour les workflows ordonnÃ©s, parallÃ¨le pour la rapiditÃ©, Ã©vÃ©nementiel pour la flexibilitÃ©
2. **GÃ©rer l'Ã©tat avec soin** - Utiliser Cosmos DB ou Ã©quivalent pour un Ã©tat partagÃ©
3. **GÃ©rer les Ã©checs avec prÃ©caution** - DÃ©lais d'expiration, reprises, disjoncteurs, files d'attente des lettres mortes
4. **Surveiller tout** - La traÃ§abilitÃ© distribuÃ©e est essentielle pour le dÃ©bogage
5. **Optimiser les coÃ»ts** - Ã‰chelle Ã  zÃ©ro, utilisation du serverless, mise en cache

**Prochaines Ã©tapes :**
1. Terminer les exercices pratiques
2. Construire un systÃ¨me multi-agents adaptÃ© Ã  votre cas d'utilisation
3. Ã‰tudier [SÃ©lection de SKU](sku-selection.md) pour optimiser les performances et les coÃ»ts

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Avertissement** :  
Ce document a Ã©tÃ© traduit Ã  l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatisÃ©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit Ãªtre considÃ©rÃ© comme la source faisant autoritÃ©. Pour des informations critiques, il est recommandÃ© de recourir Ã  une traduction humaine professionnelle. Nous ne sommes pas responsables des malentendus ou des interprÃ©tations erronÃ©es rÃ©sultant de l'utilisation de cette traduction.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->