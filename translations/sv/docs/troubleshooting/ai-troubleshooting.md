<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c8ab8fd8ed338b3ec17484b453dcda68",
  "translation_date": "2025-09-17T23:16:40+00:00",
  "source_file": "docs/troubleshooting/ai-troubleshooting.md",
  "language_code": "sv"
}
-->
# AI-specifik fels칬kningsguide

**Kapitelnavigation:**
- **游닄 Kursens startsida**: [AZD F칬r Nyb칬rjare](../../README.md)
- **游닀 Nuvarande kapitel**: Kapitel 7 - Fels칬kning & Debugging
- **拘勇 F칬reg친ende**: [Debugging Guide](debugging.md)
- **俱뫮잺 N칛sta kapitel**: [Kapitel 8: Produktions- & F칬retagsm칬nster](../ai-foundry/production-ai-practices.md)
- **游뱄 Relaterat**: [Kapitel 2: AI-First Utveckling](../ai-foundry/azure-ai-foundry-integration.md)

**F칬reg친ende:** [Produktions-AI-praktiker](../ai-foundry/production-ai-practices.md) | **N칛sta:** [Kom ig친ng med AZD](../getting-started/README.md)

Denna omfattande fels칬kningsguide tar upp vanliga problem vid implementering av AI-l칬sningar med AZD och erbjuder l칬sningar och debuggingtekniker specifika f칬r Azure AI-tj칛nster.

## Inneh친llsf칬rteckning

- [Problem med Azure OpenAI-tj칛nsten](../../../../docs/troubleshooting)
- [Problem med Azure AI Search](../../../../docs/troubleshooting)
- [Problem med Container Apps-implementering](../../../../docs/troubleshooting)
- [Autentisering och beh칬righetsfel](../../../../docs/troubleshooting)
- [Fel vid modellimplementering](../../../../docs/troubleshooting)
- [Prestanda- och skalningsproblem](../../../../docs/troubleshooting)
- [Kostnads- och kvothantering](../../../../docs/troubleshooting)
- [Debuggingverktyg och tekniker](../../../../docs/troubleshooting)

## Problem med Azure OpenAI-tj칛nsten

### Problem: OpenAI-tj칛nsten 칛r inte tillg칛nglig i regionen

**Symptom:**
```
Error: The requested resource type is not available in the location 'westus'
```

**Orsaker:**
- Azure OpenAI 칛r inte tillg칛nglig i vald region
- Kvoten 칛r f칬rbrukad i f칬redragna regioner
- Begr칛nsningar i regional kapacitet

**L칬sningar:**

1. **Kontrollera regionens tillg칛nglighet:**
```bash
# List available regions for OpenAI
az cognitiveservices account list-skus \
  --kind OpenAI \
  --query "[].locations[]" \
  --output table
```

2. **Uppdatera AZD-konfigurationen:**
```yaml
# azure.yaml - Force specific region
infra:
  provider: bicep
  path: infra
  module: main
parameters:
  location: "eastus2"  # Known working region
```

3. **Anv칛nd alternativa regioner:**
```bicep
// infra/main.bicep - Multi-region fallback
@allowed([
  'eastus2'
  'francecentral'
  'canadaeast'
  'swedencentral'
])
param openAiLocation string = 'eastus2'
```

### Problem: Kvoten f칬r modellimplementering 칬verskriden

**Symptom:**
```
Error: Deployment failed due to insufficient quota
```

**L칬sningar:**

1. **Kontrollera aktuell kvot:**
```bash
# Check quota usage
az cognitiveservices usage list \
  --name YOUR_OPENAI_RESOURCE \
  --resource-group YOUR_RG
```

2. **Beg칛r kvot칬kning:**
```bash
# Submit quota increase request
az support tickets create \
  --ticket-name "OpenAI Quota Increase" \
  --description "Need increased quota for production deployment" \
  --severity "minimal" \
  --problem-classification "/providers/Microsoft.Support/services/quota_service_guid/problemClassifications/quota_service_problemClassification_guid"
```

3. **Optimera modellkapacitet:**
```bicep
// Reduce initial capacity
resource deployment 'Microsoft.CognitiveServices/accounts/deployments@2023-05-01' = {
  properties: {
    model: {
      format: 'OpenAI'
      name: 'gpt-4o-mini'
      version: '2024-07-18'
    }
  }
  sku: {
    name: 'Standard'
    capacity: 1  // Start with minimal capacity
  }
}
```

### Problem: Ogiltig API-version

**Symptom:**
```
Error: The API version '2023-05-15' is not available for OpenAI
```

**L칬sningar:**

1. **Anv칛nd en st칬dd API-version:**
```python
# Use latest supported version
AZURE_OPENAI_API_VERSION = "2024-02-15-preview"
```

2. **Kontrollera API-versionens kompatibilitet:**
```bash
# List supported API versions
az rest --method get \
  --url "https://management.azure.com/providers/Microsoft.CognitiveServices/operations?api-version=2023-05-01" \
  --query "value[?name.value=='Microsoft.CognitiveServices/accounts/read'].properties.serviceSpecification.metricSpecifications[].supportedApiVersions[]"
```

## Problem med Azure AI Search

### Problem: Otillr칛cklig priss칛ttningstier f칬r s칬ktj칛nsten

**Symptom:**
```
Error: Semantic search requires Basic tier or higher
```

**L칬sningar:**

1. **Uppgradera priss칛ttningstier:**
```bicep
// infra/main.bicep - Use Basic tier
resource searchService 'Microsoft.Search/searchServices@2023-11-01' = {
  name: searchServiceName
  location: location
  sku: {
    name: 'basic'  // Minimum for semantic search
  }
  properties: {
    replicaCount: 1
    partitionCount: 1
    hostingMode: 'default'
    semanticSearch: 'standard'
  }
}
```

2. **Inaktivera semantisk s칬kning (utveckling):**
```bicep
// For development environments
resource searchService 'Microsoft.Search/searchServices@2023-11-01' = {
  name: searchServiceName
  sku: {
    name: 'free'
  }
  properties: {
    semanticSearch: 'disabled'
  }
}
```

### Problem: Fel vid skapande av index

**Symptom:**
```
Error: Cannot create index, insufficient permissions
```

**L칬sningar:**

1. **Verifiera nycklar f칬r s칬ktj칛nsten:**
```bash
# Get search service admin key
az search admin-key show \
  --service-name YOUR_SEARCH_SERVICE \
  --resource-group YOUR_RG
```

2. **Kontrollera indexschema:**
```python
# Validate index schema
from azure.search.documents.indexes import SearchIndexClient
from azure.search.documents.indexes.models import SearchIndex

def validate_index_schema(index_definition):
    """Validate index schema before creation."""
    required_fields = ['id', 'content']
    field_names = [field.name for field in index_definition.fields]
    
    for required in required_fields:
        if required not in field_names:
            raise ValueError(f"Missing required field: {required}")
```

3. **Anv칛nd hanterad identitet:**
```bicep
// Grant search permissions to managed identity
resource searchContributor 'Microsoft.Authorization/roleAssignments@2022-04-01' = {
  scope: searchService
  name: guid(searchService.id, containerApp.id, searchIndexDataContributorRole)
  properties: {
    principalId: containerApp.identity.principalId
    roleDefinitionId: subscriptionResourceId('Microsoft.Authorization/roleDefinitions', '8ebe5a00-799e-43f5-93ac-243d3dce84a7')
    principalType: 'ServicePrincipal'
  }
}
```

## Problem med Container Apps-implementering

### Problem: Fel vid containerbyggnad

**Symptom:**
```
Error: Failed to build container image
```

**L칬sningar:**

1. **Kontrollera Dockerfile-syntax:**
```dockerfile
# Dockerfile - Python AI app example
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first for better caching
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8000
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

2. **Validera beroenden:**
```txt
# requirements.txt - Pin versions for stability
fastapi==0.104.1
uvicorn==0.24.0
openai==1.3.7
azure-identity==1.14.1
azure-keyvault-secrets==4.7.0
azure-search-documents==11.4.0
azure-cosmos==4.5.1
```

3. **L칛gg till h칛lsokontroll:**
```python
# main.py - Add health check endpoint
from fastapi import FastAPI

app = FastAPI()

@app.get("/health")
async def health_check():
    return {"status": "healthy"}
```

### Problem: Fel vid uppstart av containerapp

**Symptom:**
```
Error: Container failed to start within timeout period
```

**L칬sningar:**

1. **칐ka uppstartstidens timeout:**
```bicep
resource containerApp 'Microsoft.App/containerApps@2024-03-01' = {
  properties: {
    template: {
      containers: [
        {
          name: 'main'
          image: containerImage
          resources: {
            cpu: json('0.5')
            memory: '1Gi'
          }
          probes: [
            {
              type: 'startup'
              httpGet: {
                path: '/health'
                port: 8000
              }
              initialDelaySeconds: 30
              periodSeconds: 10
              timeoutSeconds: 5
              failureThreshold: 10  // Allow more time for AI models to load
            }
          ]
        }
      ]
    }
  }
}
```

2. **Optimera modellens laddning:**
```python
# Lazy load models to reduce startup time
import asyncio
from contextlib import asynccontextmanager

class ModelManager:
    def __init__(self):
        self._client = None
        
    async def get_client(self):
        if self._client is None:
            self._client = await self._initialize_client()
        return self._client
        
    async def _initialize_client(self):
        # Initialize AI client here
        pass

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    app.state.model_manager = ModelManager()
    yield
    # Shutdown
    pass

app = FastAPI(lifespan=lifespan)
```

## Autentisering och beh칬righetsfel

### Problem: Nekad beh칬righet f칬r hanterad identitet

**Symptom:**
```
Error: Authentication failed for Azure OpenAI Service
```

**L칬sningar:**

1. **Verifiera rolltilldelningar:**
```bash
# Check current role assignments
az role assignment list \
  --assignee YOUR_MANAGED_IDENTITY_ID \
  --scope /subscriptions/YOUR_SUBSCRIPTION/resourceGroups/YOUR_RG
```

2. **Tilldela n칬dv칛ndiga roller:**
```bicep
// Required role assignments for AI services
var cognitiveServicesOpenAIUserRole = subscriptionResourceId('Microsoft.Authorization/roleDefinitions', '5e0bd9bd-7b93-4f28-af87-19fc36ad61bd')
var searchIndexDataContributorRole = subscriptionResourceId('Microsoft.Authorization/roleDefinitions', '8ebe5a00-799e-43f5-93ac-243d3dce84a7')

resource openAiRoleAssignment 'Microsoft.Authorization/roleAssignments@2022-04-01' = {
  scope: openAi
  name: guid(openAi.id, containerApp.id, cognitiveServicesOpenAIUserRole)
  properties: {
    principalId: containerApp.identity.principalId
    roleDefinitionId: cognitiveServicesOpenAIUserRole
    principalType: 'ServicePrincipal'
  }
}
```

3. **Testa autentisering:**
```python
# Test managed identity authentication
from azure.identity import DefaultAzureCredential
from azure.core.exceptions import ClientAuthenticationError

async def test_authentication():
    try:
        credential = DefaultAzureCredential()
        token = await credential.get_token("https://cognitiveservices.azure.com/.default")
        print(f"Authentication successful: {token.token[:10]}...")
    except ClientAuthenticationError as e:
        print(f"Authentication failed: {e}")
```

### Problem: Nekad 친tkomst till Key Vault

**Symptom:**
```
Error: The user, group or application does not have secrets get permission
```

**L칬sningar:**

1. **Ge beh칬righeter till Key Vault:**
```bicep
resource keyVaultAccessPolicy 'Microsoft.KeyVault/vaults/accessPolicies@2023-07-01' = {
  parent: keyVault
  name: 'add'
  properties: {
    accessPolicies: [
      {
        tenantId: subscription().tenantId
        objectId: containerApp.identity.principalId
        permissions: {
          secrets: ['get', 'list']
        }
      }
    ]
  }
}
```

2. **Anv칛nd RBAC ist칛llet f칬r 친tkomstpolicyer:**
```bicep
resource keyVaultSecretsUserRole 'Microsoft.Authorization/roleAssignments@2022-04-01' = {
  scope: keyVault
  name: guid(keyVault.id, containerApp.id, 'Key Vault Secrets User')
  properties: {
    principalId: containerApp.identity.principalId
    roleDefinitionId: subscriptionResourceId('Microsoft.Authorization/roleDefinitions', '4633458b-17de-408a-b874-0445c86b69e6')
    principalType: 'ServicePrincipal'
  }
}
```

## Fel vid modellimplementering

### Problem: Modellversionen 칛r inte tillg칛nglig

**Symptom:**
```
Error: Model version 'gpt-4-32k' is not available
```

**L칬sningar:**

1. **Kontrollera tillg칛ngliga modeller:**
```bash
# List available models
az cognitiveservices account list-models \
  --name YOUR_OPENAI_RESOURCE \
  --resource-group YOUR_RG \
  --query "[].{name:model.name, version:model.version}" \
  --output table
```

2. **Anv칛nd modellfallbacks:**
```bicep
// Model deployment with fallback
@description('Primary model configuration')
param primaryModel object = {
  name: 'gpt-4o-mini'
  version: '2024-07-18'
}

@description('Fallback model configuration')
param fallbackModel object = {
  name: 'gpt-35-turbo'
  version: '0125'
}

// Try primary model first, fallback if unavailable
resource primaryDeployment 'Microsoft.CognitiveServices/accounts/deployments@2023-05-01' = {
  parent: openAi
  name: 'chat-model'
  properties: {
    model: primaryModel
  }
  sku: {
    name: 'Standard'
    capacity: 10
  }
}
```

3. **Validera modellen innan implementering:**
```python
# Pre-deployment model validation
import httpx

async def validate_model_availability(model_name: str, version: str) -> bool:
    """Check if model is available before deployment."""
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"{AZURE_OPENAI_ENDPOINT}/openai/models",
                headers={"api-key": AZURE_OPENAI_API_KEY}
            )
            models = response.json()
            return any(
                model["id"] == f"{model_name}-{version}"
                for model in models.get("data", [])
            )
    except Exception:
        return False
```

## Prestanda- och skalningsproblem

### Problem: H칬g svarslatens

**Symptom:**
- Svarstider > 30 sekunder
- Timeout-fel
- D친lig anv칛ndarupplevelse

**L칬sningar:**

1. **Implementera timeout f칬r f칬rfr친gningar:**
```python
# Configure proper timeouts
import httpx

client = httpx.AsyncClient(
    timeout=httpx.Timeout(
        connect=5.0,
        read=30.0,
        write=10.0,
        pool=10.0
    )
)
```

2. **L칛gg till svarscaching:**
```python
# Redis cache for responses
import redis.asyncio as redis
import json

class ResponseCache:
    def __init__(self, redis_url: str):
        self.redis = redis.from_url(redis_url)
        
    async def get_cached_response(self, query_hash: str) -> str | None:
        """Get cached response if available."""
        cached = await self.redis.get(f"ai_response:{query_hash}")
        return cached.decode() if cached else None
        
    async def cache_response(self, query_hash: str, response: str, ttl: int = 3600):
        """Cache AI response with TTL."""
        await self.redis.setex(f"ai_response:{query_hash}", ttl, response)
```

3. **Konfigurera autoskalning:**
```bicep
resource containerApp 'Microsoft.App/containerApps@2024-03-01' = {
  properties: {
    template: {
      scale: {
        minReplicas: 2
        maxReplicas: 20
        rules: [
          {
            name: 'http-requests'
            http: {
              metadata: {
                concurrentRequests: '5'  // Scale aggressively for AI workloads
              }
            }
          }
          {
            name: 'cpu-utilization'
            custom: {
              type: 'cpu'
              metadata: {
                type: 'Utilization'
                value: '60'  // Lower threshold for AI apps
              }
            }
          }
        ]
      }
    }
  }
}
```

### Problem: Minnesfel

**Symptom:**
```
Error: Container killed due to memory limit exceeded
```

**L칬sningar:**

1. **칐ka minnesallokering:**
```bicep
resource containerApp 'Microsoft.App/containerApps@2024-03-01' = {
  properties: {
    template: {
      containers: [
        {
          name: 'main'
          resources: {
            cpu: json('1.0')
            memory: '2Gi'  // Increase for AI workloads
          }
        }
      ]
    }
  }
}
```

2. **Optimera minnesanv칛ndning:**
```python
# Memory-efficient model handling
import gc
import psutil

class MemoryOptimizedAI:
    def __init__(self):
        self.max_memory_percent = 80
        
    async def process_request(self, request):
        """Process request with memory monitoring."""
        # Check memory usage before processing
        memory_percent = psutil.virtual_memory().percent
        if memory_percent > self.max_memory_percent:
            gc.collect()  # Force garbage collection
            
        result = await self._process_ai_request(request)
        
        # Clean up after processing
        gc.collect()
        return result
```

## Kostnads- och kvothantering

### Problem: Ov칛ntat h칬ga kostnader

**Symptom:**
- Azure-faktura h칬gre 칛n f칬rv칛ntat
- Tokenanv칛ndning 칬verstiger uppskattningar
- Budgetvarningar utl칬sta

**L칬sningar:**

1. **Implementera kostnadskontroller:**
```python
# Token usage tracking
class TokenTracker:
    def __init__(self, monthly_limit: int = 100000):
        self.monthly_limit = monthly_limit
        self.current_usage = 0
        
    async def track_usage(self, prompt_tokens: int, completion_tokens: int):
        """Track token usage with limits."""
        total_tokens = prompt_tokens + completion_tokens
        self.current_usage += total_tokens
        
        if self.current_usage > self.monthly_limit:
            raise Exception("Monthly token limit exceeded")
            
        return total_tokens
```

2. **St칛ll in kostnadsvarningar:**
```bicep
resource budgetAlert 'Microsoft.Consumption/budgets@2023-05-01' = {
  name: 'ai-workload-budget'
  properties: {
    timePeriod: {
      startDate: '2024-01-01'
      endDate: '2024-12-31'
    }
    timeGrain: 'Monthly'
    amount: 500  // $500 monthly limit
    category: 'Cost'
    notifications: {
      Actual_GreaterThan_80_Percent: {
        enabled: true
        operator: 'GreaterThan'
        threshold: 80
        contactEmails: ['admin@company.com']
        contactRoles: ['Owner']
      }
    }
  }
}
```

3. **Optimera modellval:**
```python
# Cost-aware model selection
MODEL_COSTS = {
    'gpt-4o-mini': 0.00015,  # per 1K tokens
    'gpt-4': 0.03,          # per 1K tokens
    'gpt-35-turbo': 0.0015  # per 1K tokens
}

def select_model_by_cost(complexity: str, budget_remaining: float) -> str:
    """Select model based on complexity and budget."""
    if complexity == 'simple' or budget_remaining < 10:
        return 'gpt-4o-mini'
    elif complexity == 'medium':
        return 'gpt-35-turbo'
    else:
        return 'gpt-4'
```

## Debuggingverktyg och tekniker

### AZD Debugging-kommandon

```bash
# Enable verbose logging
azd up --debug

# Check deployment status
azd show

# View deployment logs
azd logs --follow

# Check environment variables
azd env get-values
```

### Applikationsdebugging

1. **Strukturerad loggning:**
```python
import logging
import json

# Configure structured logging for AI applications
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

def log_ai_request(model: str, tokens: int, latency: float, success: bool):
    """Log AI request details."""
    logger.info(json.dumps({
        'event': 'ai_request',
        'model': model,
        'tokens': tokens,
        'latency_ms': latency,
        'success': success
    }))
```

2. **H칛lsokontrollendpoints:**
```python
@app.get("/debug/health")
async def detailed_health_check():
    """Comprehensive health check for debugging."""
    checks = {}
    
    # Check OpenAI connectivity
    try:
        client = AsyncOpenAI(azure_endpoint=AZURE_OPENAI_ENDPOINT)
        await client.models.list()
        checks['openai'] = {'status': 'healthy'}
    except Exception as e:
        checks['openai'] = {'status': 'unhealthy', 'error': str(e)}
    
    # Check Search service
    try:
        search_client = SearchIndexClient(
            endpoint=AZURE_SEARCH_ENDPOINT,
            credential=DefaultAzureCredential()
        )
        indexes = await search_client.list_index_names()
        checks['search'] = {'status': 'healthy', 'indexes': list(indexes)}
    except Exception as e:
        checks['search'] = {'status': 'unhealthy', 'error': str(e)}
    
    return checks
```

3. **Prestanda칬vervakning:**
```python
import time
from functools import wraps

def monitor_performance(func):
    """Decorator to monitor function performance."""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            success = True
        except Exception as e:
            result = None
            success = False
            raise
        finally:
            end_time = time.time()
            latency = (end_time - start_time) * 1000
            
            logger.info(json.dumps({
                'function': func.__name__,
                'latency_ms': latency,
                'success': success
            }))
        
        return result
    return wrapper
```

## Vanliga felkoder och l칬sningar

| Felkod | Beskrivning | L칬sning |
|--------|-------------|---------|
| 401 | Obeh칬rig | Kontrollera API-nycklar och konfiguration f칬r hanterad identitet |
| 403 | F칬rbjuden | Verifiera RBAC-rolltilldelningar |
| 429 | Begr칛nsad hastighet | Implementera retry-logik med exponentiell backoff |
| 500 | Internt serverfel | Kontrollera modellimplementeringsstatus och loggar |
| 503 | Tj칛nsten otillg칛nglig | Verifiera tj칛nstens h칛lsa och regional tillg칛nglighet |

## N칛sta steg

1. **Granska [AI Model Deployment Guide](ai-model-deployment.md)** f칬r b칛sta praxis vid implementering
2. **Slutf칬r [Produktions-AI-praktiker](production-ai-practices.md)** f칬r f칬retagsklara l칬sningar
3. **G친 med i [Azure AI Foundry Discord](https://aka.ms/foundry/discord)** f칬r communitysupport
4. **Rapportera problem** till [AZD GitHub-repository](https://github.com/Azure/azure-dev) f칬r AZD-specifika problem

## Resurser

- [Fels칬kning av Azure OpenAI-tj칛nsten](https://learn.microsoft.com/azure/ai-services/openai/troubleshooting)
- [Fels칬kning av Container Apps](https://learn.microsoft.com/azure/container-apps/troubleshooting)
- [Fels칬kning av Azure AI Search](https://learn.microsoft.com/azure/search/search-monitor-logs)

---

**Kapitelnavigation:**
- **游닄 Kursens startsida**: [AZD F칬r Nyb칬rjare](../../README.md)
- **游닀 Nuvarande kapitel**: Kapitel 7 - Fels칬kning & Debugging
- **拘勇 F칬reg친ende**: [Debugging Guide](debugging.md)
- **俱뫮잺 N칛sta kapitel**: [Kapitel 8: Produktions- & F칬retagsm칬nster](../ai-foundry/production-ai-practices.md)
- **游뱄 Relaterat**: [Kapitel 2: AI-First Utveckling](../ai-foundry/azure-ai-foundry-integration.md)
- [Fels칬kning av Azure Developer CLI](https://learn.microsoft.com/azure/developer/azure-developer-cli/troubleshoot)

---

**Ansvarsfriskrivning**:  
Detta dokument har 칬versatts med hj칛lp av AI-칬vers칛ttningstj칛nsten [Co-op Translator](https://github.com/Azure/co-op-translator). 츿ven om vi str칛var efter noggrannhet, b칬r det noteras att automatiska 칬vers칛ttningar kan inneh친lla fel eller felaktigheter. Det ursprungliga dokumentet p친 dess originalspr친k b칬r betraktas som den auktoritativa k칛llan. F칬r kritisk information rekommenderas professionell m칛nsklig 칬vers칛ttning. Vi ansvarar inte f칬r eventuella missf칬rst친nd eller feltolkningar som uppst친r vid anv칛ndning av denna 칬vers칛ttning.