# Vzory koordinÃ¡cie viacerÃ½ch agentov

â±ï¸ **OdhadovanÃ½ Äas**: 60-75 minÃºt | ğŸ’° **OdhadovanÃ© nÃ¡klady**: ~$100-300/mesiac | â­ **ZloÅ¾itosÅ¥**: PokroÄilÃ¡

**ğŸ“š UÄebnÃ¡ cesta:**
- â† PredchÃ¡dzajÃºce: [PlÃ¡novanie kapacÃ­t](capacity-planning.md) - StratÃ©gie dimenzovania a Å¡kÃ¡lovania zdrojov
- ğŸ¯ **Tu sa nachÃ¡dzate**: Vzory koordinÃ¡cie viacerÃ½ch agentov (OrchestrÃ¡cia, komunikÃ¡cia, sprÃ¡va stavu)
- â†’ Äalej: [VÃ½ber SKU](sku-selection.md) - VÃ½ber sprÃ¡vnych sluÅ¾ieb Azure
- ğŸ  [Domov kurzu](../../README.md)

---

## ÄŒo sa nauÄÃ­te

Po absolvovanÃ­ tejto lekcie budete:
- RozumieÅ¥ vzorom **architektÃºry viacerÃ½ch agentov** a vedieÅ¥, kedy ich pouÅ¾iÅ¥
- ImplementovaÅ¥ **orchestraÄnÃ© vzory** (centralizovanÃ©, decentralizovanÃ©, hierarchickÃ©)
- NavrhovaÅ¥ stratÃ©gie **komunikÃ¡cie agentov** (synchronnÃ©, asynchronnÃ©, zaloÅ¾enÃ© na udalostiach)
- SpravovaÅ¥ **zdieÄ¾anÃ½ stav** medzi distribuovanÃ½mi agentmi
- NasadzovaÅ¥ **systÃ©my viacerÃ½ch agentov** na Azure pomocou AZD
- AplikovaÅ¥ **koordinaÄnÃ© vzory** na reÃ¡lne scenÃ¡re AI
- MonitorovaÅ¥ a odstraÅˆovaÅ¥ chyby v systÃ©moch distribuovanÃ½ch agentov

## PreÄo je koordinÃ¡cia viacerÃ½ch agentov dÃ´leÅ¾itÃ¡

### VÃ½voj: Od jednÃ©ho agenta k viacerÃ½m agentom

**Jeden agent (jednoduchÃ½):**
```
User â†’ Agent â†’ Response
```
- âœ… JednoduchÃ© na pochopenie a implementÃ¡ciu
- âœ… RÃ½chle pre jednoduchÃ© Ãºlohy
- âŒ ObmedzenÃ© schopnosÅ¥ami jednÃ©ho modelu
- âŒ NemoÅ¾nosÅ¥ paralelizÃ¡cie zloÅ¾itÃ½ch Ãºloh
- âŒ Å½iadna Å¡pecializÃ¡cia

**SystÃ©m viacerÃ½ch agentov (pokroÄilÃ½):**
```
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Orchestratorâ”‚
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚         â”‚         â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”
    â”‚Agent1â”‚  â”‚Agent2â”‚  â”‚Agent3 â”‚
    â”‚(Plan)â”‚  â”‚(Code)â”‚  â”‚(Review)â”‚
    â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜
```
- âœ… Å pecializovanÃ­ agenti na konkrÃ©tne Ãºlohy
- âœ… ParalelnÃ© vykonÃ¡vanie pre rÃ½chlosÅ¥
- âœ… ModulÃ¡rne a udrÅ¾iavateÄ¾nÃ©
- âœ… LepÅ¡ie pri zloÅ¾itÃ½ch pracovnÃ½ch postupoch
- âš ï¸ VyÅ¾aduje logiku koordinÃ¡cie

**AnalÃ³gia**: Jeden agent je ako jedna osoba, ktorÃ¡ vykonÃ¡va vÅ¡etky Ãºlohy. SystÃ©m viacerÃ½ch agentov je ako tÃ­m, kde kaÅ¾dÃ½ Älen mÃ¡ Å¡pecializovanÃ© zruÄnosti (vÃ½skumnÃ­k, programÃ¡tor, recenzent, autor) a pracuje spoloÄne.

---

## ZÃ¡kladnÃ© vzory koordinÃ¡cie

### Vzor 1: SekvenÄnÃ¡ koordinÃ¡cia (ReÅ¥az zodpovednosti)

**Kedy pouÅ¾iÅ¥**: Ãšlohy musia byÅ¥ dokonÄenÃ© v konkrÃ©tnom poradÃ­, kaÅ¾dÃ½ agent stavia na vÃ½stupe predchÃ¡dzajÃºceho.

```mermaid
sequenceDiagram
    participant User
    participant Orchestrator
    participant Agent1 as VÃ½skumnÃ½ agent
    participant Agent2 as PÃ­sacÃ­ agent
    participant Agent3 as RedakÄnÃ½ agent
    
    User->>Orchestrator: "NapÃ­Å¡ ÄlÃ¡nok o AI"
    Orchestrator->>Agent1: PreskÃºmaj tÃ©mu
    Agent1-->>Orchestrator: VÃ½sledky vÃ½skumu
    Orchestrator->>Agent2: NapÃ­Å¡ nÃ¡vrh (pouÅ¾Ã­vajÃºc vÃ½skum)
    Agent2-->>Orchestrator: NÃ¡vrh ÄlÃ¡nku
    Orchestrator->>Agent3: Uprav a vylepÅ¡i
    Agent3-->>Orchestrator: FinÃ¡lny ÄlÃ¡nok
    Orchestrator-->>User: UpravenÃ½ ÄlÃ¡nok
    
    Note over User,Agent3: SekvenÄnÃ©: KaÅ¾dÃ½ krok ÄakÃ¡ na predchÃ¡dzajÃºci
```
**VÃ½hody:**
- âœ… JasnÃ½ tok dÃ¡t
- âœ… JednoduchÃ© na ladenie
- âœ… PredvÃ­dateÄ¾nÃ© poradie vykonÃ¡vania

**Obmedzenia:**
- âŒ PomalÅ¡ie (Å¾iadna paralelizÃ¡cia)
- âŒ Jedno zlyhanie blokuje celÃ½ reÅ¥azec
- âŒ NemoÅ¾nosÅ¥ spracovaÅ¥ vzÃ¡jomne zÃ¡vislÃ© Ãºlohy

**PrÃ­klady pouÅ¾itia:**
- Pipeline na tvorbu obsahu (vÃ½skum â†’ pÃ­sanie â†’ Ãºprava â†’ publikovanie)
- Generovanie kÃ³du (plÃ¡n â†’ implementÃ¡cia â†’ testovanie â†’ nasadenie)
- Generovanie sprÃ¡v (zber dÃ¡t â†’ analÃ½za â†’ vizualizÃ¡cia â†’ zhrnutie)

---

### Vzor 2: ParalelnÃ¡ koordinÃ¡cia (Fan-Out/Fan-In)

**Kedy pouÅ¾iÅ¥**: NezÃ¡vislÃ© Ãºlohy mÃ´Å¾u beÅ¾aÅ¥ sÃºÄasne, vÃ½sledky sa kombinujÃº na konci.

```mermaid
graph TB
    User[PoÅ¾iadavka pouÅ¾Ã­vateÄ¾a]
    Orchestrator[OrchestrÃ¡tor]
    Agent1[AnalytickÃ½ agent]
    Agent2[VÃ½skumnÃ½ agent]
    Agent3[DÃ¡tovÃ½ agent]
    Aggregator[AgregÃ¡tor vÃ½sledkov]
    Response[KombinovanÃ¡ odpoveÄ]
    
    User --> Orchestrator
    Orchestrator --> Agent1
    Orchestrator --> Agent2
    Orchestrator --> Agent3
    Agent1 --> Aggregator
    Agent2 --> Aggregator
    Agent3 --> Aggregator
    Aggregator --> Response
    
    style Orchestrator fill:#2196F3,stroke:#1976D2,stroke-width:3px,color:#fff
    style Aggregator fill:#4CAF50,stroke:#388E3C,stroke-width:3px,color:#fff
```
**VÃ½hody:**
- âœ… RÃ½chle (paralelnÃ© vykonÃ¡vanie)
- âœ… OdolnÃ© voÄi chybÃ¡m (ÄiastoÄnÃ© vÃ½sledky sÃº prijateÄ¾nÃ©)
- âœ… HorizontÃ¡lne Å¡kÃ¡lovateÄ¾nÃ©

**Obmedzenia:**
- âš ï¸ VÃ½sledky mÃ´Å¾u prichÃ¡dzaÅ¥ mimo poradia
- âš ï¸ PotrebnÃ¡ logika agregÃ¡cie
- âš ï¸ KomplexnÃ¡ sprÃ¡va stavu

**PrÃ­klady pouÅ¾itia:**
- Zber dÃ¡t z viacerÃ½ch zdrojov (API + databÃ¡zy + web scraping)
- KonkurenÄnÃ¡ analÃ½za (viac modelov generuje rieÅ¡enia, vyberÃ¡ sa najlepÅ¡ie)
- PrekladateÄ¾skÃ© sluÅ¾by (preklad do viacerÃ½ch jazykov sÃºÄasne)

---

### Vzor 3: HierarchickÃ¡ koordinÃ¡cia (ManaÅ¾Ã©r-pracovnÃ­k)

**Kedy pouÅ¾iÅ¥**: ZloÅ¾itÃ© pracovnÃ© postupy s podÃºlohami, potrebnÃ¡ delegÃ¡cia.

```mermaid
graph TB
    Master[HlavnÃ½ orchestrÃ¡tor]
    Manager1[ManaÅ¾Ã©r vÃ½skumu]
    Manager2[ManaÅ¾Ã©r obsahu]
    W1[WebovÃ½ scraper]
    W2[AnalyzÃ¡tor ÄlÃ¡nkov]
    W3[SpisovateÄ¾]
    W4[Editor]
    
    Master --> Manager1
    Master --> Manager2
    Manager1 --> W1
    Manager1 --> W2
    Manager2 --> W3
    Manager2 --> W4
    
    style Master fill:#FF9800,stroke:#F57C00,stroke-width:3px,color:#fff
    style Manager1 fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff
    style Manager2 fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff
```
**VÃ½hody:**
- âœ… RieÅ¡i zloÅ¾itÃ© pracovnÃ© postupy
- âœ… ModulÃ¡rne a udrÅ¾iavateÄ¾nÃ©
- âœ… JasnÃ© hranice zodpovednosti

**Obmedzenia:**
- âš ï¸ ZloÅ¾itejÅ¡ia architektÃºra
- âš ï¸ VyÅ¡Å¡ia latencia (viac vrstiev koordinÃ¡cie)
- âš ï¸ VyÅ¾aduje sofistikovanÃº orchestrÃ¡ciu

**PrÃ­klady pouÅ¾itia:**
- Spracovanie dokumentov v podniku (klasifikÃ¡cia â†’ smerovanie â†’ spracovanie â†’ archivÃ¡cia)
- ViacstupÅˆovÃ© dÃ¡tovÃ© pipeline (zber â†’ Äistenie â†’ transformÃ¡cia â†’ analÃ½za â†’ sprÃ¡va)
- ZloÅ¾itÃ© automatizaÄnÃ© pracovnÃ© postupy (plÃ¡novanie â†’ alokÃ¡cia zdrojov â†’ vykonÃ¡vanie â†’ monitorovanie)

---

### Vzor 4: KoordinÃ¡cia zaloÅ¾enÃ¡ na udalostiach (Publish-Subscribe)

**Kedy pouÅ¾iÅ¥**: Agenti potrebujÃº reagovaÅ¥ na udalosti, poÅ¾adovanÃ¡ voÄ¾nÃ¡ vÃ¤zba.

```mermaid
sequenceDiagram
    participant Agent1 as ZberaÄ Ãºdajov
    participant EventBus as Azure Service Bus
    participant Agent2 as AnalyzÃ¡tor
    participant Agent3 as NotifikÃ¡tor
    participant Agent4 as ArchivÃ¡tor
    
    Agent1->>EventBus: PublikovaÅ¥ udalosÅ¥ "ÃšdajePrijatÃ©"
    EventBus->>Agent2: Odber: AnalyzovaÅ¥ Ãºdaje
    EventBus->>Agent3: Odber: PoslaÅ¥ notifikÃ¡ciu
    EventBus->>Agent4: Odber: ArchivovaÅ¥ Ãºdaje
    
    Note over Agent1,Agent4: VÅ¡etci odberatelia spracovÃ¡vajÃº nezÃ¡visle
    
    Agent2->>EventBus: PublikovaÅ¥ udalosÅ¥ "AnalÃ½zaDokonÄenÃ¡"
    EventBus->>Agent3: Odber: PoslaÅ¥ sprÃ¡vu o analÃ½ze
```
**VÃ½hody:**
- âœ… VoÄ¾nÃ¡ vÃ¤zba medzi agentmi
- âœ… JednoduchÃ© pridanie novÃ½ch agentov (len sa prihlÃ¡sia)
- âœ… AsynchronnÃ© spracovanie
- âœ… OdolnÃ© (perzistencia sprÃ¡v)

**Obmedzenia:**
- âš ï¸ EventuÃ¡lna konzistencia
- âš ï¸ KomplexnÃ© ladenie
- âš ï¸ ProblÃ©my s poradÃ­m sprÃ¡v

**PrÃ­klady pouÅ¾itia:**
- SystÃ©my monitorovania v reÃ¡lnom Äase (upozornenia, dashboardy, logy)
- ViackanÃ¡lovÃ© notifikÃ¡cie (email, SMS, push, Slack)
- Pipeline na spracovanie dÃ¡t (viac spotrebiteÄ¾ov rovnakÃ½ch dÃ¡t)

---

### Vzor 5: KoordinÃ¡cia zaloÅ¾enÃ¡ na konsenze (Hlasovanie/KvÃ³rum)

**Kedy pouÅ¾iÅ¥**: PotrebnÃ¡ dohoda viacerÃ½ch agentov pred pokraÄovanÃ­m.

```mermaid
graph TB
    Input[VstupnÃ¡ Ãºloha]
    Agent1[Agent 1: GPT-4]
    Agent2[Agent 2: Claude]
    Agent3[Agent 3: Gemini]
    Voter[KonzensuÃ¡lny hlasovaÄ]
    Output[DohodnutÃ½ vÃ½stup]
    
    Input --> Agent1
    Input --> Agent2
    Input --> Agent3
    Agent1 --> Voter
    Agent2 --> Voter
    Agent3 --> Voter
    Voter --> Output
    
    style Voter fill:#9C27B0,stroke:#7B1FA2,stroke-width:3px,color:#fff
```
**VÃ½hody:**
- âœ… VyÅ¡Å¡ia presnosÅ¥ (viac nÃ¡zorov)
- âœ… OdolnÃ© voÄi chybÃ¡m (zlyhanie menÅ¡iny je prijateÄ¾nÃ©)
- âœ… ZabudovanÃ¡ kontrola kvality

**Obmedzenia:**
- âŒ NÃ¡kladnÃ© (viac volanÃ­ modelov)
- âŒ PomalÅ¡ie (Äakanie na vÅ¡etkÃ½ch agentov)
- âš ï¸ PotrebnÃ© rieÅ¡enie konfliktov

**PrÃ­klady pouÅ¾itia:**
- Moderovanie obsahu (viac modelov kontroluje obsah)
- Kontrola kÃ³du (viac linters/analyzÃ¡torov)
- Diagnostika v medicÃ­ne (viac AI modelov, validÃ¡cia expertov)

---

## PrehÄ¾ad architektÃºry

### KompletnÃ½ systÃ©m viacerÃ½ch agentov na Azure

```mermaid
graph TB
    User[PouÅ¾Ã­vateÄ¾/Klient API]
    APIM[Azure API Management]
    Orchestrator[SluÅ¾ba OrchestrÃ¡tor<br/>AplikÃ¡cia v kontajneri]
    ServiceBus[Azure Service Bus<br/>Event Hub]
    
    Agent1[Agent vÃ½skumu<br/>AplikÃ¡cia v kontajneri]
    Agent2[Agent pÃ­sania<br/>AplikÃ¡cia v kontajneri]
    Agent3[Agent analÃ½zy<br/>AplikÃ¡cia v kontajneri]
    Agent4[Agent recenzie<br/>AplikÃ¡cia v kontajneri]
    
    CosmosDB[(Cosmos DB<br/>ZdieÄ¾anÃ½ stav)]
    Storage[Azure Storage<br/>Artefakty]
    AppInsights[Application Insights<br/>Monitorovanie]
    
    User --> APIM
    APIM --> Orchestrator
    
    Orchestrator --> ServiceBus
    ServiceBus --> Agent1
    ServiceBus --> Agent2
    ServiceBus --> Agent3
    ServiceBus --> Agent4
    
    Agent1 --> CosmosDB
    Agent2 --> CosmosDB
    Agent3 --> CosmosDB
    Agent4 --> CosmosDB
    
    Agent1 --> Storage
    Agent2 --> Storage
    Agent3 --> Storage
    Agent4 --> Storage
    
    Orchestrator -.-> AppInsights
    Agent1 -.-> AppInsights
    Agent2 -.-> AppInsights
    Agent3 -.-> AppInsights
    Agent4 -.-> AppInsights
    
    style Orchestrator fill:#FF9800,stroke:#F57C00,stroke-width:3px,color:#fff
    style ServiceBus fill:#9C27B0,stroke:#7B1FA2,stroke-width:3px,color:#fff
    style CosmosDB fill:#4CAF50,stroke:#388E3C,stroke-width:3px,color:#fff
```
**KÄ¾ÃºÄovÃ© komponenty:**

| Komponent | ÃšÄel | SluÅ¾ba Azure |
|-----------|------|--------------|
| **API Gateway** | VstupnÃ½ bod, obmedzenie rÃ½chlosti, autentifikÃ¡cia | API Management |
| **OrchestrÃ¡tor** | Koordinuje pracovnÃ© postupy agentov | Container Apps |
| **Message Queue** | AsynchronnÃ¡ komunikÃ¡cia | Service Bus / Event Hubs |
| **Agenti** | Å pecializovanÃ­ AI pracovnÃ­ci | Container Apps / Functions |
| **State Store** | ZdieÄ¾anÃ½ stav, sledovanie Ãºloh | Cosmos DB |
| **Artifact Storage** | Dokumenty, vÃ½sledky, logy | Blob Storage |
| **Monitoring** | DistribuovanÃ© sledovanie, logy | Application Insights |

---

## Predpoklady

### PotrebnÃ© nÃ¡stroje

```bash
# OveriÅ¥ Azure Developer CLI
azd version
# âœ… OÄakÃ¡vanÃ©: azd verzia 1.0.0 alebo vyÅ¡Å¡ia

# OveriÅ¥ Azure CLI
az --version
# âœ… OÄakÃ¡vanÃ©: azure-cli 2.50.0 alebo vyÅ¡Å¡ia

# OveriÅ¥ Docker (pre lokÃ¡lne testovanie)
docker --version
# âœ… OÄakÃ¡vanÃ©: Docker verzia 20.10 alebo vyÅ¡Å¡ia
```

### PoÅ¾iadavky na Azure

- AktÃ­vne predplatnÃ© Azure
- OprÃ¡vnenia na vytvorenie:
  - Container Apps
  - Namespace Service Bus
  - ÃšÄty Cosmos DB
  - ÃšÄty Storage
  - Application Insights

### PoÅ¾adovanÃ© znalosti

Mali by ste maÅ¥ dokonÄenÃ©:
- [SprÃ¡va konfigurÃ¡cie](../getting-started/configuration.md)
- [AutentifikÃ¡cia a bezpeÄnosÅ¥](../getting-started/authsecurity.md)
- [PrÃ­klad mikroservisov](../../../../examples/microservices)

---

## NÃ¡vod na implementÃ¡ciu

### Å truktÃºra projektu

```
multi-agent-system/
â”œâ”€â”€ azure.yaml                    # AZD configuration
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ main.bicep               # Main infrastructure
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ servicebus.bicep     # Message queue
â”‚   â”‚   â”œâ”€â”€ cosmos.bicep         # State store
â”‚   â”‚   â”œâ”€â”€ storage.bicep        # Artifact storage
â”‚   â”‚   â””â”€â”€ monitoring.bicep     # Application Insights
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ orchestrator.bicep   # Orchestrator service
â”‚       â””â”€â”€ agent.bicep          # Agent template
â””â”€â”€ src/
    â”œâ”€â”€ orchestrator/            # Orchestration logic
    â”‚   â”œâ”€â”€ app.py
    â”‚   â”œâ”€â”€ workflows.py
    â”‚   â””â”€â”€ Dockerfile
    â”œâ”€â”€ agents/
    â”‚   â”œâ”€â”€ research/            # Research agent
    â”‚   â”œâ”€â”€ writer/              # Writer agent
    â”‚   â”œâ”€â”€ analyst/             # Analyst agent
    â”‚   â””â”€â”€ reviewer/            # Reviewer agent
    â””â”€â”€ shared/
        â”œâ”€â”€ state_manager.py     # Shared state logic
        â””â”€â”€ message_handler.py   # Message handling
```

---

## Lekcia 1: Vzor sekvenÄnej koordinÃ¡cie

### ImplementÃ¡cia: Pipeline na tvorbu obsahu

Postavme sekvenÄnÃ½ pipeline: VÃ½skum â†’ PÃ­sanie â†’ Ãšprava â†’ Publikovanie

### 1. KonfigurÃ¡cia AZD

**SÃºbor: `azure.yaml`**

```yaml
name: content-pipeline
metadata:
  template: multi-agent-sequential@1.0.0

services:
  orchestrator:
    project: ./src/orchestrator
    language: python
    host: containerapp
  
  research-agent:
    project: ./src/agents/research
    language: python
    host: containerapp
  
  writer-agent:
    project: ./src/agents/writer
    language: python
    host: containerapp
  
  editor-agent:
    project: ./src/agents/editor
    language: python
    host: containerapp
```

### 2. InfraÅ¡truktÃºra: Service Bus na koordinÃ¡ciu

**SÃºbor: `infra/core/servicebus.bicep`**

```bicep
param name string
param location string
param tags object = {}

resource serviceBusNamespace 'Microsoft.ServiceBus/namespaces@2022-10-01-preview' = {
  name: name
  location: location
  tags: tags
  sku: {
    name: 'Standard'
    tier: 'Standard'
  }
  properties: {
    minimumTlsVersion: '1.2'
  }
}

// Queue for orchestrator â†’ research agent
resource researchQueue 'Microsoft.ServiceBus/namespaces/queues@2022-10-01-preview' = {
  parent: serviceBusNamespace
  name: 'research-tasks'
  properties: {
    maxDeliveryCount: 3
    lockDuration: 'PT5M'
    deadLetteringOnMessageExpiration: true
  }
}

// Queue for research agent â†’ writer agent
resource writerQueue 'Microsoft.ServiceBus/namespaces/queues@2022-10-01-preview' = {
  parent: serviceBusNamespace
  name: 'writer-tasks'
  properties: {
    maxDeliveryCount: 3
    lockDuration: 'PT5M'
  }
}

// Queue for writer agent â†’ editor agent
resource editorQueue 'Microsoft.ServiceBus/namespaces/queues@2022-10-01-preview' = {
  parent: serviceBusNamespace
  name: 'editor-tasks'
  properties: {
    maxDeliveryCount: 3
    lockDuration: 'PT5M'
  }
}

output namespace string = serviceBusNamespace.name
output connectionString string = listKeys('${serviceBusNamespace.id}/AuthorizationRules/RootManageSharedAccessKey', serviceBusNamespace.apiVersion).primaryConnectionString
```

### 3. SprÃ¡vca zdieÄ¾anÃ©ho stavu

**SÃºbor: `src/shared/state_manager.py`**

```python
from azure.cosmos import CosmosClient, PartitionKey
from datetime import datetime
import os

class StateManager:
    """Manages shared state across agents using Cosmos DB"""
    
    def __init__(self):
        endpoint = os.environ['COSMOS_ENDPOINT']
        key = os.environ['COSMOS_KEY']
        
        self.client = CosmosClient(endpoint, key)
        self.database = self.client.get_database_client('agent-state')
        self.container = self.database.get_container_client('tasks')
    
    def create_task(self, task_id: str, task_type: str, input_data: dict):
        """Create a new task"""
        task = {
            'id': task_id,
            'type': task_type,
            'status': 'pending',
            'input': input_data,
            'created_at': datetime.utcnow().isoformat(),
            'steps': []
        }
        self.container.create_item(task)
        return task
    
    def update_task_step(self, task_id: str, step_name: str, result: dict):
        """Update task with completed step"""
        task = self.container.read_item(task_id, partition_key=task_id)
        
        task['steps'].append({
            'name': step_name,
            'completed_at': datetime.utcnow().isoformat(),
            'result': result
        })
        
        self.container.replace_item(task_id, task)
        return task
    
    def complete_task(self, task_id: str, final_result: dict):
        """Mark task as complete"""
        task = self.container.read_item(task_id, partition_key=task_id)
        task['status'] = 'completed'
        task['result'] = final_result
        task['completed_at'] = datetime.utcnow().isoformat()
        self.container.replace_item(task_id, task)
        return task
    
    def get_task(self, task_id: str):
        """Retrieve task state"""
        return self.container.read_item(task_id, partition_key=task_id)
```

### 4. SluÅ¾ba orchestrÃ¡tora

**SÃºbor: `src/orchestrator/app.py`**

```python
from flask import Flask, request, jsonify
from azure.servicebus import ServiceBusClient, ServiceBusMessage
import json
import uuid
import os
from shared.state_manager import StateManager

app = Flask(__name__)
state_manager = StateManager()

# Pripojenie k Service Bus
servicebus_connection_str = os.environ['SERVICEBUS_CONNECTION_STRING']
servicebus_client = ServiceBusClient.from_connection_string(servicebus_connection_str)

@app.route('/health', methods=['GET'])
def health():
    return jsonify({'status': 'healthy', 'service': 'orchestrator'})

@app.route('/create-content', methods=['POST'])
def create_content():
    """
    Sequential workflow: Research â†’ Write â†’ Edit â†’ Publish
    """
    data = request.json
    topic = data.get('topic')
    
    if not topic:
        return jsonify({'error': 'Topic required'}), 400
    
    # VytvoriÅ¥ Ãºlohu v ÃºloÅ¾isku stavu
    task_id = str(uuid.uuid4())
    task = state_manager.create_task(
        task_id=task_id,
        task_type='content_creation',
        input_data={'topic': topic}
    )
    
    # PoslaÅ¥ sprÃ¡vu vÃ½skumnÃ©mu agentovi (prvÃ½ krok)
    sender = servicebus_client.get_queue_sender('research-tasks')
    message = ServiceBusMessage(
        body=json.dumps({
            'task_id': task_id,
            'topic': topic,
            'next_queue': 'writer-tasks'  # Kam poslaÅ¥ vÃ½sledky
        }),
        content_type='application/json'
    )
    
    with sender:
        sender.send_messages(message)
    
    return jsonify({
        'task_id': task_id,
        'status': 'started',
        'workflow': 'sequential',
        'steps': ['research', 'write', 'edit', 'publish'],
        'message': 'Content creation pipeline initiated'
    }), 202

@app.route('/task/<task_id>', methods=['GET'])
def get_task_status(task_id):
    """Check task status"""
    try:
        task = state_manager.get_task(task_id)
        return jsonify(task)
    except Exception as e:
        return jsonify({'error': str(e)}), 404

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
```

### 5. Agent vÃ½skumu

**SÃºbor: `src/agents/research/app.py`**

```python
from azure.servicebus import ServiceBusClient, ServiceBusMessage
from openai import AzureOpenAI
import json
import os
import time
from shared.state_manager import StateManager

# InicializovaÅ¥ klientov
state_manager = StateManager()
servicebus_client = ServiceBusClient.from_connection_string(
    os.environ['SERVICEBUS_CONNECTION_STRING']
)

openai_client = AzureOpenAI(
    api_key=os.environ['AZURE_OPENAI_API_KEY'],
    api_version="2024-02-01",
    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT']
)

def process_research_task(message_data):
    """Process research request and pass to writer"""
    task_id = message_data['task_id']
    topic = message_data['topic']
    next_queue = message_data['next_queue']
    
    print(f"ğŸ”¬ Researching: {topic}")
    
    # ZavolaÅ¥ Azure OpenAI na vÃ½skum
    response = openai_client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are a research assistant. Provide comprehensive research on the given topic."},
            {"role": "user", "content": f"Research this topic thoroughly: {topic}"}
        ],
        max_tokens=1500
    )
    
    research_results = response.choices[0].message.content
    
    # AktualizovaÅ¥ stav
    state_manager.update_task_step(
        task_id=task_id,
        step_name='research',
        result={'research': research_results}
    )
    
    # PoslaÅ¥ ÄalÅ¡iemu agentovi (autorovi)
    sender = servicebus_client.get_queue_sender(next_queue)
    message = ServiceBusMessage(
        body=json.dumps({
            'task_id': task_id,
            'topic': topic,
            'research': research_results,
            'next_queue': 'editor-tasks'
        }),
        content_type='application/json'
    )
    
    with sender:
        sender.send_messages(message)
    
    print(f"âœ… Research complete for task {task_id}")

def main():
    """Listen to research queue"""
    receiver = servicebus_client.get_queue_receiver('research-tasks')
    
    print("ğŸ”¬ Research Agent started, listening for tasks...")
    
    with receiver:
        while True:
            messages = receiver.receive_messages(max_wait_time=5)
            for message in messages:
                try:
                    message_data = json.loads(str(message))
                    process_research_task(message_data)
                    receiver.complete_message(message)
                except Exception as e:
                    print(f"âŒ Error processing message: {e}")
                    receiver.abandon_message(message)

if __name__ == '__main__':
    main()
```

### 6. Agent pÃ­sania

**SÃºbor: `src/agents/writer/app.py`**

```python
from azure.servicebus import ServiceBusClient, ServiceBusMessage
from openai import AzureOpenAI
import json
import os
from shared.state_manager import StateManager

state_manager = StateManager()
servicebus_client = ServiceBusClient.from_connection_string(
    os.environ['SERVICEBUS_CONNECTION_STRING']
)

openai_client = AzureOpenAI(
    api_key=os.environ['AZURE_OPENAI_API_KEY'],
    api_version="2024-02-01",
    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT']
)

def process_writing_task(message_data):
    """Write article based on research"""
    task_id = message_data['task_id']
    topic = message_data['topic']
    research = message_data['research']
    next_queue = message_data['next_queue']
    
    print(f"âœï¸ Writing article: {topic}")
    
    # Zavolajte Azure OpenAI na napÃ­sanie ÄlÃ¡nku
    response = openai_client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are a professional writer. Write engaging, well-structured articles."},
            {"role": "user", "content": f"Based on this research:\n\n{research}\n\nWrite a comprehensive article about: {topic}"}
        ],
        max_tokens=2000
    )
    
    article_draft = response.choices[0].message.content
    
    # AktualizovaÅ¥ stav
    state_manager.update_task_step(
        task_id=task_id,
        step_name='writing',
        result={'draft': article_draft}
    )
    
    # PoslaÅ¥ editorovi
    sender = servicebus_client.get_queue_sender(next_queue)
    message = ServiceBusMessage(
        body=json.dumps({
            'task_id': task_id,
            'topic': topic,
            'draft': article_draft
        }),
        content_type='application/json'
    )
    
    with sender:
        sender.send_messages(message)
    
    print(f"âœ… Article draft complete for task {task_id}")

def main():
    """Listen to writer queue"""
    receiver = servicebus_client.get_queue_receiver('writer-tasks')
    
    print("âœï¸ Writer Agent started, listening for tasks...")
    
    with receiver:
        while True:
            messages = receiver.receive_messages(max_wait_time=5)
            for message in messages:
                try:
                    message_data = json.loads(str(message))
                    process_writing_task(message_data)
                    receiver.complete_message(message)
                except Exception as e:
                    print(f"âŒ Error: {e}")
                    receiver.abandon_message(message)

if __name__ == '__main__':
    main()
```

### 7. Agent Ãºpravy

**SÃºbor: `src/agents/editor/app.py`**

```python
from azure.servicebus import ServiceBusClient
from openai import AzureOpenAI
import json
import os
from shared.state_manager import StateManager

state_manager = StateManager()
servicebus_client = ServiceBusClient.from_connection_string(
    os.environ['SERVICEBUS_CONNECTION_STRING']
)

openai_client = AzureOpenAI(
    api_key=os.environ['AZURE_OPENAI_API_KEY'],
    api_version="2024-02-01",
    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT']
)

def process_editing_task(message_data):
    """Edit and finalize article"""
    task_id = message_data['task_id']
    topic = message_data['topic']
    draft = message_data['draft']
    
    print(f"ğŸ“ Editing article: {topic}")
    
    # ZavolaÅ¥ Azure OpenAI na Ãºpravu
    response = openai_client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are an expert editor. Improve grammar, clarity, and structure."},
            {"role": "user", "content": f"Edit and improve this article:\n\n{draft}"}
        ],
        max_tokens=2000
    )
    
    final_article = response.choices[0].message.content
    
    # OznaÄiÅ¥ Ãºlohu ako dokonÄenÃº
    state_manager.complete_task(
        task_id=task_id,
        final_result={
            'topic': topic,
            'final_article': final_article,
            'word_count': len(final_article.split())
        }
    )
    
    print(f"âœ… Article finalized for task {task_id}")

def main():
    """Listen to editor queue"""
    receiver = servicebus_client.get_queue_receiver('editor-tasks')
    
    print("ğŸ“ Editor Agent started, listening for tasks...")
    
    with receiver:
        while True:
            messages = receiver.receive_messages(max_wait_time=5)
            for message in messages:
                try:
                    message_data = json.loads(str(message))
                    process_editing_task(message_data)
                    receiver.complete_message(message)
                except Exception as e:
                    print(f"âŒ Error: {e}")
                    receiver.abandon_message(message)

if __name__ == '__main__':
    main()
```

### 8. Nasadenie a testovanie

```bash
# InicializovaÅ¥ a nasadiÅ¥
azd init
azd up

# ZÃ­skaÅ¥ URL orchestrÃ¡tora
ORCHESTRATOR_URL=$(azd env get-values | grep ORCHESTRATOR_URL | cut -d '=' -f2 | tr -d '"')

# VytvoriÅ¥ obsah
curl -X POST $ORCHESTRATOR_URL/create-content \
  -H "Content-Type: application/json" \
  -d '{"topic": "The Future of AI in Healthcare"}'
```

**âœ… OÄakÃ¡vanÃ½ vÃ½stup:**
```json
{
  "task_id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "status": "started",
  "workflow": "sequential",
  "steps": ["research", "write", "edit", "publish"],
  "message": "Content creation pipeline initiated"
}
```

**Skontrolujte postup Ãºlohy:**
```bash
TASK_ID="a1b2c3d4-e5f6-7890-abcd-ef1234567890"
curl $ORCHESTRATOR_URL/task/$TASK_ID
```

**âœ… OÄakÃ¡vanÃ½ vÃ½stup (dokonÄenÃ©):**
```json
{
  "id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "type": "content_creation",
  "status": "completed",
  "steps": [
    {
      "name": "research",
      "completed_at": "2025-11-19T10:30:00Z",
      "result": {"research": "..."}
    },
    {
      "name": "writing",
      "completed_at": "2025-11-19T10:32:00Z",
      "result": {"draft": "..."}
    }
  ],
  "result": {
    "topic": "The Future of AI in Healthcare",
    "final_article": "...",
    "word_count": 1500
  }
}
```

---

## Lekcia 2: Vzor paralelnej koordinÃ¡cie

### ImplementÃ¡cia: AgregÃ¡tor vÃ½skumu z viacerÃ½ch zdrojov

Postavme paralelnÃ½ systÃ©m, ktorÃ½ sÃºÄasne zhromaÅ¾Äuje informÃ¡cie z viacerÃ½ch zdrojov.

### ParalelnÃ½ orchestrÃ¡tor

**SÃºbor: `src/orchestrator/parallel_workflow.py`**

```python
from flask import Flask, request, jsonify
from azure.servicebus import ServiceBusClient, ServiceBusMessage
import json
import uuid
import os
from shared.state_manager import StateManager

app = Flask(__name__)
state_manager = StateManager()

servicebus_client = ServiceBusClient.from_connection_string(
    os.environ['SERVICEBUS_CONNECTION_STRING']
)

@app.route('/research-parallel', methods=['POST'])
def research_parallel():
    """
    Parallel workflow: Multiple agents work simultaneously
    """
    data = request.json
    query = data.get('query')
    
    task_id = str(uuid.uuid4())
    task = state_manager.create_task(
        task_id=task_id,
        task_type='parallel_research',
        input_data={
            'query': query,
            'agents': ['web', 'academic', 'news', 'social']
        }
    )
    
    # Rozoslanie: PoslaÅ¥ vÅ¡etkÃ½m agentom sÃºÄasne
    agents = [
        ('web-research-queue', 'web'),
        ('academic-research-queue', 'academic'),
        ('news-research-queue', 'news'),
        ('social-research-queue', 'social')
    ]
    
    for queue_name, agent_type in agents:
        sender = servicebus_client.get_queue_sender(queue_name)
        message = ServiceBusMessage(
            body=json.dumps({
                'task_id': task_id,
                'query': query,
                'agent_type': agent_type,
                'result_queue': 'aggregation-queue'
            }),
            content_type='application/json'
        )
        
        with sender:
            sender.send_messages(message)
    
    return jsonify({
        'task_id': task_id,
        'status': 'started',
        'workflow': 'parallel',
        'agents_dispatched': 4,
        'message': 'Parallel research initiated'
    }), 202

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
```

### Logika agregÃ¡cie

**SÃºbor: `src/agents/aggregator/app.py`**

```python
from azure.servicebus import ServiceBusClient
import json
import os
from collections import defaultdict
from shared.state_manager import StateManager

state_manager = StateManager()
servicebus_client = ServiceBusClient.from_connection_string(
    os.environ['SERVICEBUS_CONNECTION_STRING']
)

# SledovaÅ¥ vÃ½sledky podÄ¾a Ãºlohy
task_results = defaultdict(list)
expected_agents = 4  # web, akademickÃ©, sprÃ¡vy, sociÃ¡lne

def process_result(message_data):
    """Aggregate results from parallel agents"""
    task_id = message_data['task_id']
    agent_type = message_data['agent_type']
    result = message_data['result']
    
    # UloÅ¾iÅ¥ vÃ½sledok
    task_results[task_id].append({
        'agent': agent_type,
        'data': result
    })
    
    print(f"ğŸ“Š Received result from {agent_type} agent ({len(task_results[task_id])}/{expected_agents})")
    
    # SkontrolovaÅ¥, Äi vÅ¡etci agenti dokonÄili (fan-in)
    if len(task_results[task_id]) == expected_agents:
        print(f"âœ… All agents completed for task {task_id}. Aggregating...")
        
        # KombinovaÅ¥ vÃ½sledky
        aggregated = {
            'query': message_data['query'],
            'sources': task_results[task_id],
            'summary': generate_summary(task_results[task_id])
        }
        
        # OznaÄiÅ¥ ako dokonÄenÃ©
        state_manager.complete_task(task_id, aggregated)
        
        # VyÄistiÅ¥
        del task_results[task_id]
        
        print(f"âœ… Aggregation complete for task {task_id}")

def generate_summary(results):
    """Generate summary from all sources"""
    summaries = [r['data'].get('summary', '') for r in results]
    return '\n\n'.join(summaries)

def main():
    """Listen to aggregation queue"""
    receiver = servicebus_client.get_queue_receiver('aggregation-queue')
    
    print("ğŸ“Š Aggregator started, listening for results...")
    
    with receiver:
        while True:
            messages = receiver.receive_messages(max_wait_time=5)
            for message in messages:
                try:
                    message_data = json.loads(str(message))
                    process_result(message_data)
                    receiver.complete_message(message)
                except Exception as e:
                    print(f"âŒ Error: {e}")
                    receiver.abandon_message(message)

if __name__ == '__main__':
    main()
```

**VÃ½hody paralelnÃ©ho vzoru:**
- âš¡ **4x rÃ½chlejÅ¡ie** (agenti beÅ¾ia sÃºÄasne)
- ğŸ”„ **OdolnÃ© voÄi chybÃ¡m** (ÄiastoÄnÃ© vÃ½sledky sÃº prijateÄ¾nÃ©)
- ğŸ“ˆ **Å kÃ¡lovateÄ¾nÃ©** (Ä¾ahko pridÃ¡te viac agentov)

---

## PraktickÃ© cviÄenia

### CviÄenie 1: Pridanie logiky ÄasovÃ©ho limitu â­â­ (Stredne nÃ¡roÄnÃ©)

**CieÄ¾**: ImplementovaÅ¥ logiku ÄasovÃ©ho limitu, aby agregÃ¡tor neÄakal prÃ­liÅ¡ dlho na pomalÃ½ch agentov.

**Kroky**:

1. **Pridajte sledovanie ÄasovÃ©ho limitu do agregÃ¡tora:**

```python
from datetime import datetime, timedelta

task_timeouts = {}  # task_id -> Äas vyprÅ¡ania

def process_result(message_data):
    task_id = message_data['task_id']
    
    # NastaviÅ¥ ÄasovÃ½ limit na prvÃ½ vÃ½sledok
    if task_id not in task_timeouts:
        task_timeouts[task_id] = datetime.utcnow() + timedelta(seconds=30)
    
    task_results[task_id].append({
        'agent': message_data['agent_type'],
        'data': message_data['result']
    })
    
    # SkontrolovaÅ¥, Äi je dokonÄenÃ© ALEBO vyprÅ¡al Äas
    if len(task_results[task_id]) == expected_agents or \
       datetime.utcnow() > task_timeouts[task_id]:
        
        print(f"ğŸ“Š Aggregating with {len(task_results[task_id])}/{expected_agents} results")
        
        aggregated = {
            'query': message_data['query'],
            'sources': task_results[task_id],
            'completed_agents': len(task_results[task_id]),
            'timed_out': len(task_results[task_id]) < expected_agents
        }
        
        state_manager.complete_task(task_id, aggregated)
        
        # VyÄistiÅ¥
        del task_results[task_id]
        del task_timeouts[task_id]
```

2. **Otestujte s umelÃ½mi oneskoreniami:**

```python
# V jednom agentovi pridajte oneskorenie na simulÃ¡ciu pomalÃ©ho spracovania
import time
time.sleep(35)  # Presahuje 30-sekundovÃ½ ÄasovÃ½ limit
```

3. **Nasadenie a overenie:**

```bash
azd deploy aggregator

# OdoslaÅ¥ Ãºlohu
curl -X POST $ORCHESTRATOR_URL/research-parallel \
  -H "Content-Type: application/json" \
  -d '{"query": "AI safety research"}'

# SkontrolovaÅ¥ vÃ½sledky po 30 sekundÃ¡ch
curl $ORCHESTRATOR_URL/task/$TASK_ID
```

**âœ… KritÃ©riÃ¡ Ãºspechu:**
- âœ… Ãšloha sa dokonÄÃ­ po 30 sekundÃ¡ch, aj keÄ agenti nie sÃº hotovÃ­
- âœ… OdpoveÄ indikuje ÄiastoÄnÃ© vÃ½sledky (`"timed_out": true`)
- âœ… DostupnÃ© vÃ½sledky sÃº vrÃ¡tenÃ© (3 z 4 agentov)

**ÄŒas**: 20-25 minÃºt

---

### CviÄenie 2: ImplementÃ¡cia logiky opakovania â­â­â­ (PokroÄilÃ©)

**CieÄ¾**: Automaticky opakovaÅ¥ zlyhanÃ© Ãºlohy agentov pred vzdanÃ­m sa.

**Kroky**:

1. **Pridajte sledovanie opakovania do orchestrÃ¡tora:**

```python
from dataclasses import dataclass
from typing import Dict

@dataclass
class RetryConfig:
    max_retries: int = 3
    backoff_seconds: int = 5

retry_counts: Dict[str, int] = {}  # message_id -> poÄet_pokÃºsenÃ­

def send_with_retry(queue_name: str, message_data: dict, retry_config: RetryConfig):
    """Send message with retry metadata"""
    message_id = message_data.get('message_id', str(uuid.uuid4()))
    message_data['message_id'] = message_id
    message_data['retry_count'] = retry_counts.get(message_id, 0)
    message_data['max_retries'] = retry_config.max_retries
    
    sender = servicebus_client.get_queue_sender(queue_name)
    message = ServiceBusMessage(
        body=json.dumps(message_data),
        content_type='application/json',
        message_id=message_id
    )
    
    with sender:
        sender.send_messages(message)
```

2. **Pridajte handler opakovania do agentov:**

```python
def process_with_retry(message, receiver, process_func):
    """Process message with automatic retry on failure"""
    try:
        message_data = json.loads(str(message))
        
        # SpracovaÅ¥ sprÃ¡vu
        process_func(message_data)
        
        # Ãšspech - dokonÄenÃ©
        receiver.complete_message(message)
        
    except Exception as e:
        message_id = message.message_id
        retry_count = message_data.get('retry_count', 0)
        max_retries = message_data.get('max_retries', 3)
        
        if retry_count < max_retries:
            # OpakovaÅ¥: zruÅ¡iÅ¥ a znovu zaradiÅ¥ do fronty so zvÃ½Å¡enÃ½m poÄtom
            print(f"âš ï¸ Retry {retry_count + 1}/{max_retries} for message {message_id}")
            
            message_data['retry_count'] = retry_count + 1
            
            # PoslaÅ¥ spÃ¤Å¥ do rovnakej fronty s oneskorenÃ­m
            time.sleep(5 * (retry_count + 1))  # ExponenciÃ¡lne oneskorenie
            send_with_retry(queue_name, message_data, RetryConfig())
            
            receiver.complete_message(message)  # OdstrÃ¡niÅ¥ originÃ¡l
        else:
            # MaximÃ¡lny poÄet opakovanÃ­ prekroÄenÃ½ - presunÃºÅ¥ do fronty nevybavenÃ½ch sprÃ¡v
            print(f"âŒ Max retries exceeded for message {message_id}")
            receiver.dead_letter_message(
                message,
                reason="MaxRetriesExceeded",
                error_description=str(e)
            )
```

3. **Monitorujte frontu neÃºspeÅ¡nÃ½ch sprÃ¡v:**

```python
def monitor_dead_letters():
    """Check dead letter queue for failed messages"""
    receiver = servicebus_client.get_queue_receiver(
        'research-queue',
        sub_queue='deadletter'
    )
    
    with receiver:
        messages = receiver.receive_messages(max_wait_time=5)
        for message in messages:
            print(f"â˜ ï¸ Dead letter: {message.message_id}")
            print(f"Reason: {message.dead_letter_reason}")
            print(f"Description: {message.dead_letter_error_description}")
```

**âœ… KritÃ©riÃ¡ Ãºspechu:**
- âœ… ZlyhanÃ© Ãºlohy sa automaticky opakujÃº (aÅ¾ 3-krÃ¡t)
- âœ… ExponenciÃ¡lne oneskorenie medzi opakovaniami (5s, 10s, 15s)
- âœ… Po maximÃ¡lnom poÄte opakovanÃ­ sa sprÃ¡vy presunÃº do fronty neÃºspeÅ¡nÃ½ch sprÃ¡v
- âœ… Frontu neÃºspeÅ¡nÃ½ch sprÃ¡v je moÅ¾nÃ© monitorovaÅ¥ a opÃ¤tovne spracovaÅ¥

**ÄŒas**: 30-40 minÃºt

---

### CviÄenie 3: ImplementÃ¡cia obvodu preruÅ¡enia â­â­â­ (PokroÄilÃ©)

**CieÄ¾**: ZabrÃ¡niÅ¥ kaskÃ¡dovÃ½m zlyhaniam zastavenÃ­m poÅ¾iadaviek na zlyhÃ¡vajÃºcich agentov.

**Kroky**:

1. **Vytvorte triedu obvodu preruÅ¡enia:**

```python
from enum import Enum
from datetime import datetime, timedelta

class CircuitState(Enum):
    CLOSED = "closed"      # NormÃ¡lna prevÃ¡dzka
    OPEN = "open"          # Zlyhanie, odmietnutie poÅ¾iadaviek
    HALF_OPEN = "half_open"  # Testovanie, Äi sa obnovilo

class CircuitBreaker:
    def __init__(self, failure_threshold=5, timeout_seconds=60):
        self.failure_threshold = failure_threshold
        self.timeout_seconds = timeout_seconds
        self.failure_count = 0
        self.last_failure_time = None
        self.state = CircuitState.CLOSED
    
    def call(self, func):
        """Execute function with circuit breaker protection"""
        if self.state == CircuitState.OPEN:
            # Skontrolujte, Äi vyprÅ¡al ÄasovÃ½ limit
            if datetime.utcnow() - self.last_failure_time > timedelta(seconds=self.timeout_seconds):
                self.state = CircuitState.HALF_OPEN
                print("ğŸ”„ Circuit breaker: HALF_OPEN (testing)")
            else:
                raise Exception(f"Circuit breaker OPEN for agent. Try again in {self.timeout_seconds}s")
        
        try:
            result = func()
            
            # Ãšspech
            if self.state == CircuitState.HALF_OPEN:
                self.state = CircuitState.CLOSED
                self.failure_count = 0
                print("âœ… Circuit breaker: CLOSED (recovered)")
            
            return result
            
        except Exception as e:
            self.failure_count += 1
            self.last_failure_time = datetime.utcnow()
            
            if self.failure_count >= self.failure_threshold:
                self.state = CircuitState.OPEN
                print(f"ğŸ”´ Circuit breaker: OPEN (too many failures)")
            
            raise e
```

2. **Aplikujte na volania agentov:**

```python
# V orchestrÃ¡tore
agent_circuits = {
    'web': CircuitBreaker(failure_threshold=5, timeout_seconds=60),
    'academic': CircuitBreaker(failure_threshold=5, timeout_seconds=60),
    'news': CircuitBreaker(failure_threshold=5, timeout_seconds=60),
    'social': CircuitBreaker(failure_threshold=5, timeout_seconds=60)
}

def send_to_agent(agent_type, message_data):
    """Send with circuit breaker protection"""
    circuit = agent_circuits[agent_type]
    
    try:
        circuit.call(lambda: send_message(agent_type, message_data))
    except Exception as e:
        print(f"âš ï¸ Skipping {agent_type} agent: {e}")
        # PokraÄujte s ostatnÃ½mi agentmi
```

3. **Otestujte obvod preruÅ¡enia:**

```bash
# SimulovaÅ¥ opakovanÃ© zlyhania (zastaviÅ¥ jednÃ©ho agenta)
az containerapp stop --name web-research-agent --resource-group rg-agents

# PoslaÅ¥ viacero poÅ¾iadaviek
for i in {1..10}; do
  curl -X POST $ORCHESTRATOR_URL/research-parallel \
    -H "Content-Type: application/json" \
    -d '{"query": "test query '$i'"}'
  sleep 2
done

# SkontrolovaÅ¥ logy - po 5 zlyhaniach by mal byÅ¥ obvod otvorenÃ½
azd logs orchestrator --tail 50
```

**âœ… KritÃ©riÃ¡ Ãºspechu:**
- âœ… Po 5 zlyhaniach sa obvod otvorÃ­ (odmieta poÅ¾iadavky)
- âœ… Po 60 sekundÃ¡ch sa obvod polootvorÃ­ (testuje obnovu)
- âœ… OstatnÃ­ agenti pokraÄujÃº v prÃ¡ci normÃ¡lne
- âœ… Obvod sa automaticky zatvorÃ­, keÄ sa agent obnovÃ­

**ÄŒas**: 40-50 minÃºt

---

## Monitorovanie a ladenie

### DistribuovanÃ© sledovanie pomocou Application Insights

**SÃºbor: `src/shared/tracing.py`**

```python
from opencensus.ext.azure.log_exporter import AzureLogHandler
from opencensus.ext.azure.trace_exporter import AzureExporter
from opencensus.trace import config_integration
from opencensus.trace.tracer import Tracer
from opencensus.trace.samplers import AlwaysOnSampler
import logging
import os

# Nakonfigurujte sledovanie
config_integration.trace_integrations(['requests', 'logging'])

connection_string = os.environ.get('APPLICATIONINSIGHTS_CONNECTION_STRING')

# Vytvorte sledovaÄ
tracer = Tracer(
    exporter=AzureExporter(connection_string=connection_string),
    sampler=AlwaysOnSampler()
)

# Nakonfigurujte protokolovanie
logger = logging.getLogger(__name__)
logger.addHandler(AzureLogHandler(connection_string=connection_string))
logger.setLevel(logging.INFO)

def trace_agent_call(agent_name, task_id, operation):
    """Trace agent operations"""
    with tracer.span(name=f'{agent_name}.{operation}') as span:
        span.add_attribute('agent', agent_name)
        span.add_attribute('task_id', task_id)
        span.add_attribute('operation', operation)
        
        try:
            result = operation()
            span.add_attribute('status', 'success')
            return result
        except Exception as e:
            span.add_attribute('status', 'error')
            span.add_attribute('error', str(e))
            raise
```

### Dotazy v Application Insights

**Sledovanie pracovnÃ½ch postupov viacerÃ½ch agentov:**

```kusto
// Trace complete workflow for a task
traces
| where customDimensions.task_id == "a1b2c3d4-..."
| project timestamp, message, customDimensions.agent, customDimensions.operation
| order by timestamp asc
```

**Porovnanie vÃ½konu agentov:**

```kusto
// Compare agent execution times
dependencies
| where name contains "agent"
| summarize 
    avg_duration = avg(duration),
    p95_duration = percentile(duration, 95),
    count = count()
  by agent = tostring(customDimensions.agent)
| order by avg_duration desc
```

**AnalÃ½za zlyhanÃ­:**

```kusto
// Find which agents fail most
exceptions
| where customDimensions.agent != ""
| summarize 
    failure_count = count(),
    unique_errors = dcount(outerMessage)
  by agent = tostring(customDimensions.agent)
| order by failure_count desc
```

---

## AnalÃ½za nÃ¡kladov

### NÃ¡klady na systÃ©m viacerÃ½ch agentov (mesaÄnÃ© odhady)

| Komponent | KonfigurÃ¡cia | NÃ¡klady |
|-----------|--------------|---------|
| **OrchestrÃ¡tor** | 1 Container App (1 vCPU, 2GB) | $30-50 |
| **4 Agenti** | 4 Container Apps (0.5 vCPU, 1GB kaÅ¾dÃ½) | $60-120 |
| **Service Bus** | Å tandardnÃ¡ ÃºroveÅˆ, 10M sprÃ¡v | $10-20 |
| **Cosmos DB** | Serverless, 5GB ÃºloÅ¾isko, 1M RUs | $25-50 |
| **Blob Storage** | 10GB ÃºloÅ¾isko, 100K operÃ¡ciÃ­ | $5-10 |
| **Application Insights** | 5GB ingestie | $10-15 |
| **Azure OpenAI** | GPT-4, 10M tokenov | $100-300 |
| **Celkom** | | **$240-565/mesiac** |

### StratÃ©gie optimalizÃ¡cie nÃ¡kladov

1. **PouÅ¾Ã­vajte serverless, kde je to moÅ¾nÃ©:**
   ```bicep
   // Cosmos DB serverless (no minimum cost)
   properties: {
     databaseAccountOfferType: 'Standard'
     capabilities: [{ name: 'EnableServerless' }]
   }
   ```

2. **Å kÃ¡lujte agentov na nulu, keÄ sÃº neÄinnÃ­:**
   ```bicep
   scale: {
     minReplicas: 0  // Scale to zero when no messages
     maxReplicas: 10
   }
   ```

3. **PouÅ¾Ã­vajte batching pre Service Bus:**
   ```python
   # Posielajte sprÃ¡vy v dÃ¡vkach (lacnejÅ¡ie)
   sender.send_messages([message1, message2, message3])
   ```

4. **Cache Äasto pouÅ¾Ã­vanÃ© vÃ½sledky:**
   ```python
   # PouÅ¾ite Azure Cache pre Redis
   if cache.exists(query_hash):
       return cache.get(query_hash)
   ```

---

## NajlepÅ¡ie postupy

### âœ… ROBTE:

1. **PouÅ¾Ã­vajte idempotentnÃ© operÃ¡cie**
   ```python
   # Agent mÃ´Å¾e bezpeÄne spracovaÅ¥ rovnakÃº sprÃ¡vu viackrÃ¡t
   def process_task(task_id):
       if state_manager.task_exists(task_id):
           print(f"Task {task_id} already processed, skipping")
           return
       # Spracovanie Ãºlohy...
   ```

2. **Implementujte komplexnÃ© logovanie**
   ```python
   logger.info(f"Agent: {agent_name}, Task: {task_id}, Action: {action}")
   ```

3. **PouÅ¾Ã­vajte korelaÄnÃ© ID**
   ```python
   # PreniesÅ¥ task_id cez celÃ½ pracovnÃ½ postup
   message_data = {
       'task_id': task_id,  # KorelaÄnÃ© ID
       'timestamp': datetime.utcnow().isoformat()
   }
   ```

4. **Nastavte TTL (Äas Å¾ivota) sprÃ¡v**
   ```bicep
   properties: {
     defaultMessageTimeToLive: 'PT1H'  // 1 hour max
   }
   ```

5. **Monitorujte fronty neÃºspeÅ¡nÃ½ch sprÃ¡v**
   ```python
   # PravidelnÃ© monitorovanie neÃºspeÅ¡nÃ½ch sprÃ¡v
   monitor_dead_letters()
   ```

### âŒ NEROBTE:

1. **NevytvÃ¡rajte kruhovÃ© zÃ¡vislosti**
   ```python
   # âŒ ZLÃ‰: Agent A â†’ Agent B â†’ Agent A (nekoneÄnÃ¡ sluÄka)
   # âœ… DOBRÃ‰: DefinovaÅ¥ jasnÃ½ orientovanÃ½ acyklickÃ½ graf (DAG)
   ```

2. **Neblokujte vlÃ¡kna agentov**
   ```python
   # âŒ ZLÃ‰: SynchronnÃ© Äakanie
   while not task_complete:
       time.sleep(1)
   
   # âœ… DOBRÃ‰: PouÅ¾ite spÃ¤tnÃ© volania frontu sprÃ¡v
   ```

3. **Neignorujte ÄiastoÄnÃ© zlyhania**
   ```python
   # âŒ ZLÃ‰: Zlyhanie celÃ©ho pracovnÃ©ho procesu, ak zlyhÃ¡ jeden agent
   # âœ… DOBRÃ‰: VrÃ¡tiÅ¥ ÄiastoÄnÃ© vÃ½sledky s indikÃ¡tormi chÃ½b
   ```

4. **NepouÅ¾Ã­vajte nekoneÄnÃ© opakovania**
   ```python
   # âŒ ZLÃ‰: opakovaÅ¥ navÅ¾dy
   # âœ… DOBRÃ‰: max_retries = 3, potom dead letter
   ```

---
## PrÃ­ruÄka na rieÅ¡enie problÃ©mov

### ProblÃ©m: SprÃ¡vy uviaznutÃ© v rade

**PrÃ­znaky:**
- SprÃ¡vy sa hromadia v rade
- Agenti nespracovÃ¡vajÃº
- Stav Ãºlohy uviaznutÃ½ na "ÄakÃ¡ sa"

**DiagnÃ³za:**
```bash
# Skontrolujte hÄºbku fronty
az servicebus queue show \
  --namespace-name mybus \
  --name research-tasks \
  --query "countDetails"

# Skontrolujte stav agenta
azd logs research-agent --tail 50
```

**RieÅ¡enia:**

1. **ZvÃ½Å¡te poÄet replÃ­k agentov:**
   ```bash
   az containerapp update \
     --name research-agent \
     --min-replicas 3 \
     --max-replicas 10
   ```

2. **Skontrolujte frontu neÃºspeÅ¡nÃ½ch sprÃ¡v:**
   ```bash
   az servicebus queue show \
     --namespace-name mybus \
     --name research-tasks \
     --query "countDetails.deadLetterMessageCount"
   ```

---

### ProblÃ©m: ÄŒasovÃ½ limit Ãºlohy/nikdy sa nedokonÄÃ­

**PrÃ­znaky:**
- Stav Ãºlohy zostÃ¡va "v procese"
- NiektorÃ­ agenti dokonÄia, inÃ­ nie
- Å½iadne chybovÃ© hlÃ¡senia

**DiagnÃ³za:**
```bash
# SkontrolovaÅ¥ stav Ãºlohy
curl $ORCHESTRATOR_URL/task/$TASK_ID

# SkontrolovaÅ¥ Application Insights
# SpustiÅ¥ dotaz: traces | where customDimensions.task_id == "..."
```

**RieÅ¡enia:**

1. **Implementujte ÄasovÃ½ limit v agregÃ¡tore (CviÄenie 1)**

2. **Skontrolujte zlyhania agentov:**
   ```bash
   azd logs --follow | grep "ERROR\|FAIL"
   ```

3. **Overte, Äi vÅ¡etci agenti beÅ¾ia:**
   ```bash
   az containerapp list \
     --resource-group rg-agents \
     --query "[].{name:name, status:properties.runningStatus}"
   ```

---

## Zistite viac

### OficiÃ¡lna dokumentÃ¡cia
- [Azure Service Bus](https://learn.microsoft.com/azure/service-bus-messaging/service-bus-messaging-overview)
- [Cosmos DB](https://learn.microsoft.com/azure/cosmos-db/introduction)
- [Container Apps DAPR](https://learn.microsoft.com/azure/container-apps/dapr-overview)
- [Multi-Agent Design Patterns](https://learn.microsoft.com/azure/architecture/guide/ai/multi-agent-systems)

### ÄalÅ¡ie kroky v tomto kurze
- â† PredchÃ¡dzajÃºce: [PlÃ¡novanie kapacity](capacity-planning.md)
- â†’ ÄalÅ¡ie: [VÃ½ber SKU](sku-selection.md)
- ğŸ  [Domov kurzu](../../README.md)

### SÃºvisiace prÃ­klady
- [PrÃ­klad mikrosluÅ¾ieb](../../../../examples/microservices) - Vzory komunikÃ¡cie sluÅ¾ieb
- [PrÃ­klad Azure OpenAI](../../../../examples/azure-openai-chat) - IntegrÃ¡cia AI

---

## Zhrnutie

**NauÄili ste sa:**
- âœ… PÃ¤Å¥ koordinaÄnÃ½ch vzorov (sekvenÄnÃ½, paralelnÃ½, hierarchickÃ½, udalosÅ¥ami riadenÃ½, konsenzus)
- âœ… ArchitektÃºru multi-agentov na Azure (Service Bus, Cosmos DB, Container Apps)
- âœ… SprÃ¡vu stavu medzi distribuovanÃ½mi agentmi
- âœ… RieÅ¡enie ÄasovÃ½ch limitov, opakovanÃ­ a obvodovÃ½ch prepÃ­naÄov
- âœ… Monitorovanie a ladenie distribuovanÃ½ch systÃ©mov
- âœ… StratÃ©gie optimalizÃ¡cie nÃ¡kladov

**HlavnÃ© poznatky:**
1. **Vyberte sprÃ¡vny vzor** - SekvenÄnÃ½ pre usporiadanÃ© pracovnÃ© postupy, paralelnÃ½ pre rÃ½chlosÅ¥, udalosÅ¥ami riadenÃ½ pre flexibilitu
2. **Spravujte stav opatrne** - PouÅ¾Ã­vajte Cosmos DB alebo podobnÃ© rieÅ¡enia pre zdieÄ¾anÃ½ stav
3. **RieÅ¡te zlyhania s rozvahou** - ÄŒasovÃ© limity, opakovania, obvodovÃ© prepÃ­naÄe, fronty neÃºspeÅ¡nÃ½ch sprÃ¡v
4. **Monitorujte vÅ¡etko** - DistribuovanÃ© sledovanie je nevyhnutnÃ© pre ladenie
5. **Optimalizujte nÃ¡klady** - Å kÃ¡lovanie na nulu, vyuÅ¾Ã­vanie serverless, implementÃ¡cia cache

**ÄalÅ¡ie kroky:**
1. DokonÄite praktickÃ© cviÄenia
2. Vytvorte multi-agentovÃ½ systÃ©m pre vÃ¡Å¡ prÃ­pad pouÅ¾itia
3. Å tudujte [VÃ½ber SKU](sku-selection.md) na optimalizÃ¡ciu vÃ½konu a nÃ¡kladov

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Zrieknutie sa zodpovednosti**:  
Tento dokument bol preloÅ¾enÃ½ pomocou sluÅ¾by AI prekladu [Co-op Translator](https://github.com/Azure/co-op-translator). Hoci sa snaÅ¾Ã­me o presnosÅ¥, prosÃ­m, uvedomte si, Å¾e automatizovanÃ© preklady mÃ´Å¾u obsahovaÅ¥ chyby alebo nepresnosti. PÃ´vodnÃ½ dokument v jeho rodnom jazyku by mal byÅ¥ povaÅ¾ovanÃ½ za autoritatÃ­vny zdroj. Pre kritickÃ© informÃ¡cie sa odporÃºÄa profesionÃ¡lny Ä¾udskÃ½ preklad. Nenesieme zodpovednosÅ¥ za akÃ©koÄ¾vek nedorozumenia alebo nesprÃ¡vne interpretÃ¡cie vyplÃ½vajÃºce z pouÅ¾itia tohto prekladu.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->