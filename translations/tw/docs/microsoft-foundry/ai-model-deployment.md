<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2432e08775264e481d86a2e0e512a347",
  "translation_date": "2025-11-19T11:30:28+00:00",
  "source_file": "docs/microsoft-foundry/ai-model-deployment.md",
  "language_code": "tw"
}
-->
# ä½¿ç”¨ Azure Developer CLI éƒ¨ç½² AI æ¨¡å‹

**ç« ç¯€å°è¦½ï¼š**
- **ğŸ“š èª²ç¨‹é¦–é **ï¼š[AZD åˆå­¸è€…æŒ‡å—](../../README.md)
- **ğŸ“– æœ¬ç« å…§å®¹**ï¼šç¬¬ 2 ç«  - AI å„ªå…ˆé–‹ç™¼
- **â¬…ï¸ ä¸Šä¸€ç« **ï¼š[Microsoft Foundry æ•´åˆ](microsoft-foundry-integration.md)
- **â¡ï¸ ä¸‹ä¸€ç« **ï¼š[AI å·¥ä½œåŠå¯¦é©—](ai-workshop-lab.md)
- **ğŸš€ ä¸‹ä¸€ç« ç¯€**ï¼š[ç¬¬ 3 ç« ï¼šè¨­å®š](../getting-started/configuration.md)

æœ¬æŒ‡å—æä¾›ä½¿ç”¨ AZD ç¯„æœ¬éƒ¨ç½² AI æ¨¡å‹çš„å®Œæ•´èªªæ˜ï¼Œæ¶µè“‹å¾æ¨¡å‹é¸æ“‡åˆ°ç”Ÿç”¢éƒ¨ç½²æ¨¡å¼çš„æ‰€æœ‰å…§å®¹ã€‚

## ç›®éŒ„

- [æ¨¡å‹é¸æ“‡ç­–ç•¥](../../../../docs/microsoft-foundry)
- [AI æ¨¡å‹çš„ AZD è¨­å®š](../../../../docs/microsoft-foundry)
- [éƒ¨ç½²æ¨¡å¼](../../../../docs/microsoft-foundry)
- [æ¨¡å‹ç®¡ç†](../../../../docs/microsoft-foundry)
- [ç”Ÿç”¢ç’°å¢ƒè€ƒé‡](../../../../docs/microsoft-foundry)
- [ç›£æ§èˆ‡å¯è§€å¯Ÿæ€§](../../../../docs/microsoft-foundry)

## æ¨¡å‹é¸æ“‡ç­–ç•¥

### Azure OpenAI æ¨¡å‹

æ ¹æ“šæ‚¨çš„ä½¿ç”¨æ¡ˆä¾‹é¸æ“‡åˆé©çš„æ¨¡å‹ï¼š

```yaml
# azure.yaml - Model configuration
services:
  ai-service:
    project: ./infra
    host: containerapp
    config:
      AZURE_OPENAI_MODELS: |
        [
          {
            "name": "gpt-4o-mini",
            "version": "2024-07-18",
            "deployment": "gpt-4o-mini",
            "capacity": 10,
            "format": "OpenAI"
          },
          {
            "name": "text-embedding-ada-002",
            "version": "2",
            "deployment": "text-embedding-ada-002", 
            "capacity": 30,
            "format": "OpenAI"
          }
        ]
```

### æ¨¡å‹å®¹é‡è¦åŠƒ

| æ¨¡å‹é¡å‹ | ä½¿ç”¨æ¡ˆä¾‹ | å»ºè­°å®¹é‡ | æˆæœ¬è€ƒé‡ |
|----------|----------|----------|----------|
| GPT-4o-mini | èŠå¤©ã€å•ç­” | 10-50 TPM | å¤§å¤šæ•¸å·¥ä½œè² è¼‰çš„æˆæœ¬æ•ˆç›Šé¸æ“‡ |
| GPT-4 | è¤‡é›œæ¨ç† | 20-100 TPM | æˆæœ¬è¼ƒé«˜ï¼Œé©ç”¨æ–¼é«˜ç´šåŠŸèƒ½ |
| Text-embedding-ada-002 | æœç´¢ã€RAG | 30-120 TPM | èªç¾©æœç´¢çš„å¿…è¦é¸æ“‡ |
| Whisper | èªéŸ³è½‰æ–‡å­— | 10-50 TPM | éŸ³é »è™•ç†å·¥ä½œè² è¼‰ |

## AI æ¨¡å‹çš„ AZD è¨­å®š

### Bicep ç¯„æœ¬è¨­å®š

é€é Bicep ç¯„æœ¬å»ºç«‹æ¨¡å‹éƒ¨ç½²ï¼š

```bicep
// infra/main.bicep
@description('OpenAI model deployments')
param openAiModelDeployments array = [
  {
    name: 'gpt-4o-mini'
    model: {
      format: 'OpenAI'
      name: 'gpt-4o-mini'
      version: '2024-07-18'
    }
    sku: {
      name: 'Standard'
      capacity: 10
    }
  }
  {
    name: 'text-embedding-ada-002'
    model: {
      format: 'OpenAI'
      name: 'text-embedding-ada-002'
      version: '2'
    }
    sku: {
      name: 'Standard'
      capacity: 30
    }
  }
]

resource openAi 'Microsoft.CognitiveServices/accounts@2023-05-01' = {
  name: openAiAccountName
  location: location
  kind: 'OpenAI'
  properties: {
    customSubDomainName: openAiAccountName
    networkAcls: {
      defaultAction: 'Allow'
    }
    publicNetworkAccess: 'Enabled'
  }
  sku: {
    name: 'S0'
  }
}

@batchSize(1)
resource deployment 'Microsoft.CognitiveServices/accounts/deployments@2023-05-01' = [for deployment in openAiModelDeployments: {
  parent: openAi
  name: deployment.name
  properties: {
    model: deployment.model
  }
  sku: deployment.sku
}]
```

### ç’°å¢ƒè®Šæ•¸

è¨­å®šæ‚¨çš„æ‡‰ç”¨ç¨‹å¼ç’°å¢ƒï¼š

```bash
# .env configuration
AZURE_OPENAI_ENDPOINT=https://your-openai-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-02-15-preview
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o-mini
AZURE_OPENAI_EMBED_DEPLOYMENT=text-embedding-ada-002
```

## éƒ¨ç½²æ¨¡å¼

### æ¨¡å¼ 1ï¼šå–®å€åŸŸéƒ¨ç½²

```yaml
# azure.yaml - Single region
services:
  ai-app:
    project: ./src
    host: containerapp
    config:
      AZURE_OPENAI_ENDPOINT: ${AZURE_OPENAI_ENDPOINT}
      AZURE_OPENAI_CHAT_DEPLOYMENT: gpt-4o-mini
```

é©ç”¨æ–¼ï¼š
- é–‹ç™¼èˆ‡æ¸¬è©¦
- å–®ä¸€å¸‚å ´æ‡‰ç”¨
- æˆæœ¬å„ªåŒ–

### æ¨¡å¼ 2ï¼šå¤šå€åŸŸéƒ¨ç½²

```bicep
// Multi-region deployment
param regions array = ['eastus2', 'westus2', 'francecentral']

resource openAiMultiRegion 'Microsoft.CognitiveServices/accounts@2023-05-01' = [for region in regions: {
  name: '${openAiAccountName}-${region}'
  location: region
  // ... configuration
}]
```

é©ç”¨æ–¼ï¼š
- å…¨çƒæ‡‰ç”¨
- é«˜å¯ç”¨æ€§éœ€æ±‚
- è² è¼‰åˆ†é…

### æ¨¡å¼ 3ï¼šæ··åˆéƒ¨ç½²

çµåˆ Azure OpenAI èˆ‡å…¶ä»– AI æœå‹™ï¼š

```bicep
// Hybrid AI services
resource cognitiveServices 'Microsoft.CognitiveServices/accounts@2023-05-01' = {
  name: cognitiveServicesName
  location: location
  kind: 'CognitiveServices'
  properties: {
    customSubDomainName: cognitiveServicesName
  }
  sku: {
    name: 'S0'
  }
}

resource documentIntelligence 'Microsoft.CognitiveServices/accounts@2023-05-01' = {
  name: documentIntelligenceName
  location: location
  kind: 'FormRecognizer'
  properties: {
    customSubDomainName: documentIntelligenceName
  }
  sku: {
    name: 'S0'
  }
}
```

## æ¨¡å‹ç®¡ç†

### ç‰ˆæœ¬æ§åˆ¶

åœ¨ AZD è¨­å®šä¸­è¿½è¹¤æ¨¡å‹ç‰ˆæœ¬ï¼š

```json
{
  "models": {
    "chat": {
      "name": "gpt-4o-mini",
      "version": "2024-07-18",
      "fallback": "gpt-35-turbo"
    },
    "embedding": {
      "name": "text-embedding-ada-002",
      "version": "2"
    }
  }
}
```

### æ¨¡å‹æ›´æ–°

ä½¿ç”¨ AZD hooks é€²è¡Œæ¨¡å‹æ›´æ–°ï¼š

```bash
#!/bin/bash
# hooks/predeploy.sh

echo "Checking model availability..."
az cognitiveservices account list-models \
  --name $AZURE_OPENAI_ACCOUNT_NAME \
  --resource-group $AZURE_RESOURCE_GROUP \
  --query "[?name=='gpt-4o-mini']"
```

### A/B æ¸¬è©¦

éƒ¨ç½²å¤šå€‹æ¨¡å‹ç‰ˆæœ¬ï¼š

```bicep
param enableABTesting bool = false

resource chatDeployment 'Microsoft.CognitiveServices/accounts/deployments@2023-05-01' = {
  parent: openAi
  name: 'gpt-4o-mini-${enableABTesting ? 'v1' : 'prod'}'
  properties: {
    model: {
      format: 'OpenAI'
      name: 'gpt-4o-mini'
      version: '2024-07-18'
    }
  }
  sku: {
    name: 'Standard'
    capacity: enableABTesting ? 5 : 10
  }
}
```

## ç”Ÿç”¢ç’°å¢ƒè€ƒé‡

### å®¹é‡è¦åŠƒ

æ ¹æ“šä½¿ç”¨æ¨¡å¼è¨ˆç®—æ‰€éœ€å®¹é‡ï¼š

```python
# Capacity calculation example
def calculate_required_capacity(
    requests_per_minute: int,
    avg_prompt_tokens: int,
    avg_completion_tokens: int,
    safety_margin: float = 0.2
) -> int:
    """Calculate required TPM capacity."""
    total_tokens_per_request = avg_prompt_tokens + avg_completion_tokens
    total_tpm = requests_per_minute * total_tokens_per_request
    return int(total_tpm * (1 + safety_margin))

# Example usage
required_capacity = calculate_required_capacity(
    requests_per_minute=10,
    avg_prompt_tokens=500,
    avg_completion_tokens=200,
    safety_margin=0.3
)
print(f"Required capacity: {required_capacity} TPM")
```

### è‡ªå‹•èª¿æ•´è¨­å®š

ç‚º Container Apps è¨­å®šè‡ªå‹•èª¿æ•´ï¼š

```bicep
resource containerApp 'Microsoft.App/containerApps@2024-03-01' = {
  name: containerAppName
  properties: {
    template: {
      scale: {
        minReplicas: 1
        maxReplicas: 10
        rules: [
          {
            name: 'http-rule'
            http: {
              metadata: {
                concurrentRequests: '10'
              }
            }
          }
          {
            name: 'cpu-rule'
            custom: {
              type: 'cpu'
              metadata: {
                type: 'Utilization'
                value: '70'
              }
            }
          }
        ]
      }
    }
  }
}
```

### æˆæœ¬å„ªåŒ–

å¯¦æ–½æˆæœ¬æ§åˆ¶ï¼š

```bicep
@description('Enable cost management alerts')
param enableCostAlerts bool = true

resource budgetAlert 'Microsoft.Consumption/budgets@2023-05-01' = if (enableCostAlerts) {
  name: 'ai-budget-alert'
  properties: {
    timePeriod: {
      startDate: '2024-01-01'
      endDate: '2024-12-31'
    }
    timeGrain: 'Monthly'
    amount: 1000
    category: 'Cost'
    notifications: {
      Actual_GreaterThan_80_Percent: {
        enabled: true
        operator: 'GreaterThan'
        threshold: 80
        contactEmails: [
          'admin@yourcompany.com'
        ]
      }
    }
  }
}
```

## ç›£æ§èˆ‡å¯è§€å¯Ÿæ€§

### Application Insights æ•´åˆ

ç‚º AI å·¥ä½œè² è¼‰è¨­å®šç›£æ§ï¼š

```bicep
resource applicationInsights 'Microsoft.Insights/components@2020-02-02' = {
  name: applicationInsightsName
  location: location
  kind: 'web'
  properties: {
    Application_Type: 'web'
    WorkspaceResourceId: logAnalyticsWorkspace.id
  }
}

// Custom metrics for AI models
resource aiMetrics 'Microsoft.Insights/components/analyticsItems@2020-02-02' = {
  parent: applicationInsights
  name: 'ai-model-metrics'
  properties: {
    content: '''
      customEvents
      | where name == "AI_Model_Request"
      | extend model = tostring(customDimensions.model)
      | extend tokens = toint(customDimensions.tokens)
      | extend latency = toint(customDimensions.latency_ms)
      | summarize 
          requests = count(),
          avg_tokens = avg(tokens),
          avg_latency = avg(latency)
        by model, bin(timestamp, 5m)
    '''
    type: 'query'
    scope: 'shared'
  }
}
```

### è‡ªè¨‚æŒ‡æ¨™

è¿½è¹¤ AI ç‰¹å®šæŒ‡æ¨™ï¼š

```python
# Custom telemetry for AI models
import logging
from applicationinsights import TelemetryClient

class AITelemetry:
    def __init__(self, instrumentation_key: str):
        self.client = TelemetryClient(instrumentation_key)
    
    def track_model_request(self, model: str, tokens: int, latency_ms: int, success: bool):
        """Track AI model request metrics."""
        self.client.track_event(
            'AI_Model_Request',
            {
                'model': model,
                'tokens': str(tokens),
                'latency_ms': str(latency_ms),
                'success': str(success)
            }
        )
        
    def track_model_error(self, model: str, error_type: str, error_message: str):
        """Track AI model errors."""
        self.client.track_exception(
            type=error_type,
            value=error_message,
            properties={
                'model': model,
                'component': 'ai_model'
            }
        )
```

### å¥åº·æª¢æŸ¥

å¯¦æ–½ AI æœå‹™å¥åº·ç›£æ§ï¼š

```python
# Health check endpoints
from fastapi import FastAPI, HTTPException
import httpx

app = FastAPI()

@app.get("/health/ai-models")
async def check_ai_models():
    """Check AI model availability."""
    try:
        # Test OpenAI connection
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"{AZURE_OPENAI_ENDPOINT}/openai/deployments",
                headers={"api-key": AZURE_OPENAI_API_KEY}
            )
            
        if response.status_code == 200:
            return {"status": "healthy", "models": response.json()}
        else:
            raise HTTPException(status_code=503, detail="AI models unavailable")
            
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"Health check failed: {str(e)}")
```

## ä¸‹ä¸€æ­¥

1. **æª¢é–± [Microsoft Foundry æ•´åˆæŒ‡å—](microsoft-foundry-integration.md)**ï¼Œäº†è§£æœå‹™æ•´åˆæ¨¡å¼
2. **å®Œæˆ [AI å·¥ä½œåŠå¯¦é©—](ai-workshop-lab.md)**ï¼Œç²å¾—å¯¦ä½œç¶“é©—
3. **å¯¦æ–½ [ç”Ÿç”¢ AI å¯¦å‹™](production-ai-practices.md)**ï¼Œç”¨æ–¼ä¼æ¥­éƒ¨ç½²
4. **æ¢ç´¢ [AI ç–‘é›£æ’è§£æŒ‡å—](../troubleshooting/ai-troubleshooting.md)**ï¼Œè§£æ±ºå¸¸è¦‹å•é¡Œ

## è³‡æº

- [Azure OpenAI æ¨¡å‹å¯ç”¨æ€§](https://learn.microsoft.com/azure/ai-services/openai/concepts/models)
- [Azure Developer CLI æ–‡ä»¶](https://learn.microsoft.com/azure/developer/azure-developer-cli/)
- [Container Apps è‡ªå‹•èª¿æ•´](https://learn.microsoft.com/azure/container-apps/scale-app)
- [AI æ¨¡å‹æˆæœ¬å„ªåŒ–](https://learn.microsoft.com/azure/ai-services/openai/how-to/manage-costs)

---

**ç« ç¯€å°è¦½ï¼š**
- **ğŸ“š èª²ç¨‹é¦–é **ï¼š[AZD åˆå­¸è€…æŒ‡å—](../../README.md)
- **ğŸ“– æœ¬ç« å…§å®¹**ï¼šç¬¬ 2 ç«  - AI å„ªå…ˆé–‹ç™¼
- **â¬…ï¸ ä¸Šä¸€ç« **ï¼š[Microsoft Foundry æ•´åˆ](microsoft-foundry-integration.md)
- **â¡ï¸ ä¸‹ä¸€ç« **ï¼š[AI å·¥ä½œåŠå¯¦é©—](ai-workshop-lab.md)
- **ğŸš€ ä¸‹ä¸€ç« ç¯€**ï¼š[ç¬¬ 3 ç« ï¼šè¨­å®š](../getting-started/configuration.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**å…è²¬è²æ˜**ï¼š  
æœ¬æ–‡ä»¶å·²ä½¿ç”¨ AI ç¿»è­¯æœå‹™ [Co-op Translator](https://github.com/Azure/co-op-translator) é€²è¡Œç¿»è­¯ã€‚å„˜ç®¡æˆ‘å€‘è‡´åŠ›æ–¼æä¾›æº–ç¢ºçš„ç¿»è­¯ï¼Œè«‹æ³¨æ„è‡ªå‹•ç¿»è­¯å¯èƒ½åŒ…å«éŒ¯èª¤æˆ–ä¸æº–ç¢ºä¹‹è™•ã€‚åŸå§‹æ–‡ä»¶çš„æ¯èªç‰ˆæœ¬æ‡‰è¢«è¦–ç‚ºæ¬Šå¨ä¾†æºã€‚å°æ–¼é‡è¦è³‡è¨Šï¼Œå»ºè­°ä½¿ç”¨å°ˆæ¥­äººå·¥ç¿»è­¯ã€‚æˆ‘å€‘å°å› ä½¿ç”¨æ­¤ç¿»è­¯è€Œå¼•èµ·çš„ä»»ä½•èª¤è§£æˆ–èª¤é‡‹ä¸æ‰¿æ“”è²¬ä»»ã€‚
<!-- CO-OP TRANSLATOR DISCLAIMER END -->