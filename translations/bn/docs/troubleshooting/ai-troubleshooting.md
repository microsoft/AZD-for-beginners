<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b5ae13b6a245ab3a2e6dae923aab65bd",
  "translation_date": "2025-11-20T12:08:13+00:00",
  "source_file": "docs/troubleshooting/ai-troubleshooting.md",
  "language_code": "bn"
}
-->
# ржПржЖржЗ-ржирж┐рж░рзНржжрж┐рж╖рзНржЯ рж╕ржорж╕рзНржпрж╛ рж╕ржорж╛ржзрж╛ржирзЗрж░ ржЧрж╛ржЗржб

**ржЕржзрзНржпрж╛рзЯрзЗрж░ ржирзЗржнрж┐ржЧрзЗрж╢ржи:**
- **ЁЯУЪ ржХрзЛрж░рзНрж╕ рж╣рзЛржо**: [AZD For Beginners](../../README.md)
- **ЁЯУЦ ржмрж░рзНрждржорж╛ржи ржЕржзрзНржпрж╛рзЯ**: ржЕржзрзНржпрж╛рзЯ рзн - рж╕ржорж╕рзНржпрж╛ рж╕ржорж╛ржзрж╛ржи ржУ ржбрж┐ржмрж╛ржЧрж┐ржВ
- **тмЕя╕П ржкрзВрж░рзНржмржмрж░рзНрждрзА**: [ржбрж┐ржмрж╛ржЧрж┐ржВ ржЧрж╛ржЗржб](debugging.md)
- **тЮбя╕П ржкрж░ржмрж░рзНрждрзА ржЕржзрзНржпрж╛рзЯ**: [ржЕржзрзНржпрж╛рзЯ рзо: ржкрзНрж░рзЛржбрж╛ржХрж╢ржи ржУ ржПржирзНржЯрж╛рж░ржкрзНрж░рж╛ржЗржЬ ржкрзНржпрж╛ржЯрж╛рж░рзНржи](../microsoft-foundry/production-ai-practices.md)
- **ЁЯдЦ рж╕ржорзНржкрж░рзНржХрж┐ржд**: [ржЕржзрзНржпрж╛рзЯ рзи: ржПржЖржЗ-ржкрзНрж░ржержо ржЙржирзНржирзЯржи](../microsoft-foundry/microsoft-foundry-integration.md)

**ржкрзВрж░рзНржмржмрж░рзНрждрзА:** [Production AI Practices](../microsoft-foundry/production-ai-practices.md) | **ржкрж░ржмрж░рзНрждрзА:** [AZD ржжрж┐рзЯрзЗ рж╢рзБрж░рзБ ржХрж░рж╛](../getting-started/README.md)

ржПржЗ ржмрж┐рж╕рзНрждрзГржд рж╕ржорж╕рзНржпрж╛ рж╕ржорж╛ржзрж╛ржирзЗрж░ ржЧрж╛ржЗржбржЯрж┐ AZD ржжрж┐рзЯрзЗ ржПржЖржЗ рж╕ржорж╛ржзрж╛ржи ржбрж┐ржкрзНрж▓рзЯ ржХрж░рж╛рж░ рж╕ржорзЯ рж╕рж╛ржзрж╛рж░ржг рж╕ржорж╕рзНржпрж╛ржЧрзБрж▓рзЛ рж╕ржорж╛ржзрж╛ржи ржПржмржВ ржбрж┐ржмрж╛ржЧрж┐ржВ ржХрзМрж╢рж▓ рж╕рж░ржмрж░рж╛рж╣ ржХрж░рзЗ, ржпрж╛ Azure AI ржкрж░рж┐рж╖рзЗржмрж╛ржЧрзБрж▓рзЛрж░ ржЬржирзНржп ржирж┐рж░рзНржжрж┐рж╖рзНржЯред

## рж╕рзВржЪрж┐ржкрждрзНрж░

- [Azure OpenAI ржкрж░рж┐рж╖рзЗржмрж╛рж░ рж╕ржорж╕рзНржпрж╛](../../../../docs/troubleshooting)
- [Azure AI рж╕рж╛рж░рзНржЪ рж╕ржорж╕рзНржпрж╛ржЧрзБрж▓рзЛ](../../../../docs/troubleshooting)
- [ржХржирзНржЯрзЗржЗржирж╛рж░ ржЕрзНржпрж╛ржк ржбрж┐ржкрзНрж▓рзЯржорзЗржирзНржЯ рж╕ржорж╕рзНржпрж╛](../../../../docs/troubleshooting)
- [ржЕржерзЗржиржЯрж┐ржХрзЗрж╢ржи ржПржмржВ ржЕржирзБржорждрж┐ рждрзНрж░рзБржЯрж┐](../../../../docs/troubleshooting)
- [ржоржбрзЗрж▓ ржбрж┐ржкрзНрж▓рзЯржорзЗржирзНржЯ ржмрзНржпрж░рзНржерждрж╛](../../../../docs/troubleshooting)
- [ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржПржмржВ рж╕рзНржХрзЗрж▓рж┐ржВ рж╕ржорж╕рзНржпрж╛](../../../../docs/troubleshooting)
- [ржЦрж░ржЪ ржПржмржВ ржХрзЛржЯрж╛рж░ ржмрзНржпржмрж╕рзНржерж╛ржкржирж╛](../../../../docs/troubleshooting)
- [ржбрж┐ржмрж╛ржЧрж┐ржВ ржЯрзБрж▓рж╕ ржПржмржВ ржХрзМрж╢рж▓](../../../../docs/troubleshooting)

## Azure OpenAI ржкрж░рж┐рж╖рзЗржмрж╛рж░ рж╕ржорж╕рзНржпрж╛

### рж╕ржорж╕рзНржпрж╛: OpenAI ржкрж░рж┐рж╖рзЗржмрж╛ ржЕржЮрзНржЪрж▓рзЗ ржЙржкрж▓ржмрзНржз ржирзЯ

**рж▓ржХрзНрж╖ржг:**
```
Error: The requested resource type is not available in the location 'westus'
```

**ржХрж╛рж░ржг:**
- ржирж┐рж░рзНржмрж╛ржЪрж┐ржд ржЕржЮрзНржЪрж▓рзЗ Azure OpenAI ржЙржкрж▓ржмрзНржз ржирзЯ
- ржкржЫржирзНржжрзЗрж░ ржЕржЮрзНржЪрж▓рзЗ ржХрзЛржЯрж╛рж░ рж╕рзАржорж╛ рж╢рзЗрж╖
- ржЖржЮрзНржЪрж▓рж┐ржХ ржХрзНрж╖ржорждрж╛рж░ рж╕рзАржорж╛ржмржжрзНржзрждрж╛

**рж╕ржорж╛ржзрж╛ржи:**

1. **ржЕржЮрзНржЪрж▓ ржЙржкрж▓ржмрзНржзрждрж╛ ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи:**
```bash
# ржУржкрзЗржиржПржЖржЗ ржПрж░ ржЬржирзНржп ржЙржкрж▓ржмрзНржз ржЕржЮрзНржЪрж▓ржЧрзБрж▓рж┐рж░ рждрж╛рж▓рж┐ржХрж╛ ржХрж░рзБржи
az cognitiveservices account list-skus \
  --kind OpenAI \
  --query "[].locations[]" \
  --output table
```

2. **AZD ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржи ржЖржкржбрзЗржЯ ржХрж░рзБржи:**
```yaml
# azure.yaml - Force specific region
infra:
  provider: bicep
  path: infra
  module: main
parameters:
  location: "eastus2"  # Known working region
```

3. **ржмрж┐ржХрж▓рзНржк ржЕржЮрзНржЪрж▓ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи:**
```bicep
// infra/main.bicep - Multi-region fallback
@allowed([
  'eastus2'
  'francecentral'
  'canadaeast'
  'swedencentral'
])
param openAiLocation string = 'eastus2'
```

### рж╕ржорж╕рзНржпрж╛: ржоржбрзЗрж▓ ржбрж┐ржкрзНрж▓рзЯржорзЗржирзНржЯ ржХрзЛржЯрж╛рж░ рж╕рзАржорж╛ ржЕрждрж┐ржХрзНрж░ржо

**рж▓ржХрзНрж╖ржг:**
```
Error: Deployment failed due to insufficient quota
```

**рж╕ржорж╛ржзрж╛ржи:**

1. **ржмрж░рзНрждржорж╛ржи ржХрзЛржЯрж╛рж░ ржЕржмрж╕рзНржерж╛ ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи:**
```bash
# ржХрзЛржЯрж╛рж░ ржмрзНржпржмрж╣рж╛рж░ ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи
az cognitiveservices usage list \
  --name YOUR_OPENAI_RESOURCE \
  --resource-group YOUR_RG
```

2. **ржХрзЛржЯрж╛ ржмрзГржжрзНржзрж┐рж░ ржЬржирзНржп ржЕржирзБрж░рзЛржз ржХрж░рзБржи:**
```bash
# ржХрзЛржЯрж╛ ржмрзГржжрзНржзрж┐ ржЕржирзБрж░рзЛржз ржЬржорж╛ ржжрж┐ржи
az support tickets create \
  --ticket-name "OpenAI Quota Increase" \
  --description "Need increased quota for production deployment" \
  --severity "minimal" \
  --problem-classification "/providers/Microsoft.Support/services/quota_service_guid/problemClassifications/quota_service_problemClassification_guid"
```

3. **ржоржбрзЗрж▓рзЗрж░ ржХрзНрж╖ржорждрж╛ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬ ржХрж░рзБржи:**
```bicep
// Reduce initial capacity
resource deployment 'Microsoft.CognitiveServices/accounts/deployments@2023-05-01' = {
  properties: {
    model: {
      format: 'OpenAI'
      name: 'gpt-4o-mini'
      version: '2024-07-18'
    }
  }
  sku: {
    name: 'Standard'
    capacity: 1  // Start with minimal capacity
  }
}
```

### рж╕ржорж╕рзНржпрж╛: ржЕржмрзИржз API рж╕ржВрж╕рзНржХрж░ржг

**рж▓ржХрзНрж╖ржг:**
```
Error: The API version '2023-05-15' is not available for OpenAI
```

**рж╕ржорж╛ржзрж╛ржи:**

1. **рж╕ржорж░рзНржерж┐ржд API рж╕ржВрж╕рзНржХрж░ржг ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи:**
```python
# рж╕рж░рзНржмрж╢рзЗрж╖ рж╕ржорж░рзНржерж┐ржд рж╕ржВрж╕рзНржХрж░ржг ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи
AZURE_OPENAI_API_VERSION = "2024-02-15-preview"
```

2. **API рж╕ржВрж╕рзНржХрж░ржгрзЗрж░ рж╕рж╛ржоржЮрзНржЬрж╕рзНржп ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи:**
```bash
# рж╕ржорж░рзНржерж┐ржд API рж╕ржВрж╕рзНржХрж░ржгржЧрзБрж▓рж┐рж░ рждрж╛рж▓рж┐ржХрж╛
az rest --method get \
  --url "https://management.azure.com/providers/Microsoft.CognitiveServices/operations?api-version=2023-05-01" \
  --query "value[?name.value=='Microsoft.CognitiveServices/accounts/read'].properties.serviceSpecification.metricSpecifications[].supportedApiVersions[]"
```

## Azure AI рж╕рж╛рж░рзНржЪ рж╕ржорж╕рзНржпрж╛ржЧрзБрж▓рзЛ

### рж╕ржорж╕рзНржпрж╛: рж╕рж╛рж░рзНржЪ рж╕рж╛рж░рзНржнрж┐рж╕рзЗрж░ ржкрзНрж░рж╛ржЗрж╕рж┐ржВ ржЯрж┐рзЯрж╛рж░ ржЕржкрж░рзНржпрж╛ржкрзНржд

**рж▓ржХрзНрж╖ржг:**
```
Error: Semantic search requires Basic tier or higher
```

**рж╕ржорж╛ржзрж╛ржи:**

1. **ржкрзНрж░рж╛ржЗрж╕рж┐ржВ ржЯрж┐рзЯрж╛рж░ ржЖржкржЧрзНрж░рзЗржб ржХрж░рзБржи:**
```bicep
// infra/main.bicep - Use Basic tier
resource searchService 'Microsoft.Search/searchServices@2023-11-01' = {
  name: searchServiceName
  location: location
  sku: {
    name: 'basic'  // Minimum for semantic search
  }
  properties: {
    replicaCount: 1
    partitionCount: 1
    hostingMode: 'default'
    semanticSearch: 'standard'
  }
}
```

2. **рж╕рзЗржорж╛ржирзНржЯрж┐ржХ рж╕рж╛рж░рзНржЪ ржирж┐рж╖рзНржХрзНрж░рж┐рзЯ ржХрж░рзБржи (ржбрзЗржнрзЗрж▓ржкржорзЗржирзНржЯ):**
```bicep
// For development environments
resource searchService 'Microsoft.Search/searchServices@2023-11-01' = {
  name: searchServiceName
  sku: {
    name: 'free'
  }
  properties: {
    semanticSearch: 'disabled'
  }
}
```

### рж╕ржорж╕рзНржпрж╛: ржЗржиржбрзЗржХрзНрж╕ рждрзИрж░рж┐рж░ ржмрзНржпрж░рзНржерждрж╛

**рж▓ржХрзНрж╖ржг:**
```
Error: Cannot create index, insufficient permissions
```

**рж╕ржорж╛ржзрж╛ржи:**

1. **рж╕рж╛рж░рзНржЪ рж╕рж╛рж░рзНржнрж┐рж╕рзЗрж░ ржХрзА ржпрж╛ржЪрж╛ржЗ ржХрж░рзБржи:**
```bash
# ржЕржирзБрж╕ржирзНржзрж╛ржи ржкрж░рж┐рж╖рзЗржмрж╛ ржкрзНрж░рж╢рж╛рж╕ржХ ржХрзА ржкрж╛ржи
az search admin-key show \
  --service-name YOUR_SEARCH_SERVICE \
  --resource-group YOUR_RG
```

2. **ржЗржиржбрзЗржХрзНрж╕ рж╕рзНржХрж┐ржорж╛ ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи:**
```python
# рж╕рзВржЪржХрзЗрж░ рж╕рзНржХрж┐ржорж╛ ржпрж╛ржЪрж╛ржЗ ржХрж░рзБржи
from azure.search.documents.indexes import SearchIndexClient
from azure.search.documents.indexes.models import SearchIndex

def validate_index_schema(index_definition):
    """Validate index schema before creation."""
    required_fields = ['id', 'content']
    field_names = [field.name for field in index_definition.fields]
    
    for required in required_fields:
        if required not in field_names:
            raise ValueError(f"Missing required field: {required}")
```

3. **ржорзНржпрж╛ржирзЗржЬржб ржЖржЗржбрзЗржирзНржЯрж┐ржЯрж┐ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи:**
```bicep
// Grant search permissions to managed identity
resource searchContributor 'Microsoft.Authorization/roleAssignments@2022-04-01' = {
  scope: searchService
  name: guid(searchService.id, containerApp.id, searchIndexDataContributorRole)
  properties: {
    principalId: containerApp.identity.principalId
    roleDefinitionId: subscriptionResourceId('Microsoft.Authorization/roleDefinitions', '8ebe5a00-799e-43f5-93ac-243d3dce84a7')
    principalType: 'ServicePrincipal'
  }
}
```

## ржХржирзНржЯрзЗржЗржирж╛рж░ ржЕрзНржпрж╛ржк ржбрж┐ржкрзНрж▓рзЯржорзЗржирзНржЯ рж╕ржорж╕рзНржпрж╛

### рж╕ржорж╕рзНржпрж╛: ржХржирзНржЯрзЗржЗржирж╛рж░ ржмрж┐рж▓рзНржб ржмрзНржпрж░рзНржерждрж╛

**рж▓ржХрзНрж╖ржг:**
```
Error: Failed to build container image
```

**рж╕ржорж╛ржзрж╛ржи:**

1. **Dockerfile рж╕рж┐ржиржЯрзНржпрж╛ржХрзНрж╕ ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи:**
```dockerfile
# Dockerfile - Python AI app example
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first for better caching
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8000
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

2. **ржбрж┐ржкрзЗржиржбрзЗржирзНрж╕рж┐ ржпрж╛ржЪрж╛ржЗ ржХрж░рзБржи:**
```txt
# requirements.txt - Pin versions for stability
fastapi==0.104.1
uvicorn==0.24.0
openai==1.3.7
azure-identity==1.14.1
azure-keyvault-secrets==4.7.0
azure-search-documents==11.4.0
azure-cosmos==4.5.1
```

3. **рж╣рзЗрж▓рже ржЪрзЗржХ ржпрзЛржЧ ржХрж░рзБржи:**
```python
# main.py - рж╕рзНржмрж╛рж╕рзНржерзНржп ржкрж░рзАржХрзНрж╖рж╛ ржПржирзНржбржкржпрж╝рзЗржирзНржЯ ржпрзЛржЧ ржХрж░рзБржи
from fastapi import FastAPI

app = FastAPI()

@app.get("/health")
async def health_check():
    return {"status": "healthy"}
```

### рж╕ржорж╕рзНржпрж╛: ржХржирзНржЯрзЗржЗржирж╛рж░ ржЕрзНржпрж╛ржк рж╕рзНржЯрж╛рж░рзНржЯржЖржк ржмрзНржпрж░рзНржерждрж╛

**рж▓ржХрзНрж╖ржг:**
```
Error: Container failed to start within timeout period
```

**рж╕ржорж╛ржзрж╛ржи:**

1. **рж╕рзНржЯрж╛рж░рзНржЯржЖржк ржЯрж╛ржЗржоржЖржЙржЯ ржмрзГржжрзНржзрж┐ ржХрж░рзБржи:**
```bicep
resource containerApp 'Microsoft.App/containerApps@2024-03-01' = {
  properties: {
    template: {
      containers: [
        {
          name: 'main'
          image: containerImage
          resources: {
            cpu: json('0.5')
            memory: '1Gi'
          }
          probes: [
            {
              type: 'startup'
              httpGet: {
                path: '/health'
                port: 8000
              }
              initialDelaySeconds: 30
              periodSeconds: 10
              timeoutSeconds: 5
              failureThreshold: 10  // Allow more time for AI models to load
            }
          ]
        }
      ]
    }
  }
}
```

2. **ржоржбрзЗрж▓ рж▓рзЛржбрж┐ржВ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬ ржХрж░рзБржи:**
```python
# рж╕рзНржЯрж╛рж░рзНржЯржЖржк рж╕ржоржпрж╝ ржХржорж╛ржирзЛрж░ ржЬржирзНржп ржоржбрзЗрж▓ржЧрзБрж▓рж┐ рж▓рзЗржЬрж┐ рж▓рзЛржб ржХрж░рзБржи
import asyncio
from contextlib import asynccontextmanager

class ModelManager:
    def __init__(self):
        self._client = None
        
    async def get_client(self):
        if self._client is None:
            self._client = await self._initialize_client()
        return self._client
        
    async def _initialize_client(self):
        # ржПржЦрж╛ржирзЗ ржПржЖржЗ ржХрзНрж▓рж╛ржпрж╝рзЗржирзНржЯ ржЗржирж┐рж╢рж┐ржпрж╝рж╛рж▓рж╛ржЗржЬ ржХрж░рзБржи
        pass

@asynccontextmanager
async def lifespan(app: FastAPI):
    # рж╕рзНржЯрж╛рж░рзНржЯржЖржк
    app.state.model_manager = ModelManager()
    yield
    # рж╢рж╛ржЯржбрж╛ржЙржи
    pass

app = FastAPI(lifespan=lifespan)
```

## ржЕржерзЗржиржЯрж┐ржХрзЗрж╢ржи ржПржмржВ ржЕржирзБржорждрж┐ рждрзНрж░рзБржЯрж┐

### рж╕ржорж╕рзНржпрж╛: ржорзНржпрж╛ржирзЗржЬржб ржЖржЗржбрзЗржирзНржЯрж┐ржЯрж┐рж░ ржЕржирзБржорждрж┐ ржЕрж╕рзНржмрзАржХрзГржд

**рж▓ржХрзНрж╖ржг:**
```
Error: Authentication failed for Azure OpenAI Service
```

**рж╕ржорж╛ржзрж╛ржи:**

1. **рж░рзЛрж▓ ржЕрзНржпрж╛рж╕рж╛ржЗржиржорзЗржирзНржЯ ржпрж╛ржЪрж╛ржЗ ржХрж░рзБржи:**
```bash
# ржмрж░рзНрждржорж╛ржи ржнрзВржорж┐ржХрж╛ ржмрж░рж╛ржжрзНржжржЧрзБрж▓рж┐ ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи
az role assignment list \
  --assignee YOUR_MANAGED_IDENTITY_ID \
  --scope /subscriptions/YOUR_SUBSCRIPTION/resourceGroups/YOUR_RG
```

2. **ржкрзНрж░рзЯрзЛржЬржирзАрзЯ рж░рзЛрж▓ ржЕрзНржпрж╛рж╕рж╛ржЗржи ржХрж░рзБржи:**
```bicep
// Required role assignments for AI services
var cognitiveServicesOpenAIUserRole = subscriptionResourceId('Microsoft.Authorization/roleDefinitions', '5e0bd9bd-7b93-4f28-af87-19fc36ad61bd')
var searchIndexDataContributorRole = subscriptionResourceId('Microsoft.Authorization/roleDefinitions', '8ebe5a00-799e-43f5-93ac-243d3dce84a7')

resource openAiRoleAssignment 'Microsoft.Authorization/roleAssignments@2022-04-01' = {
  scope: openAi
  name: guid(openAi.id, containerApp.id, cognitiveServicesOpenAIUserRole)
  properties: {
    principalId: containerApp.identity.principalId
    roleDefinitionId: cognitiveServicesOpenAIUserRole
    principalType: 'ServicePrincipal'
  }
}
```

3. **ржЕржерзЗржиржЯрж┐ржХрзЗрж╢ржи ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи:**
```python
# ржкрж░рзАржХрзНрж╖рж┐ржд ржкрж░рж┐ржЪрж╛рж▓рж┐ржд ржкрж░рж┐ржЪржпрж╝ ржкрзНрж░ржорж╛ржгрзАржХрж░ржг
from azure.identity import DefaultAzureCredential
from azure.core.exceptions import ClientAuthenticationError

async def test_authentication():
    try:
        credential = DefaultAzureCredential()
        token = await credential.get_token("https://cognitiveservices.azure.com/.default")
        print(f"Authentication successful: {token.token[:10]}...")
    except ClientAuthenticationError as e:
        print(f"Authentication failed: {e}")
```

### рж╕ржорж╕рзНржпрж╛: ржХрзА ржнрж▓рзНржЯ ржЕрзНржпрж╛ржХрзНрж╕рзЗрж╕ ржЕрж╕рзНржмрзАржХрзГржд

**рж▓ржХрзНрж╖ржг:**
```
Error: The user, group or application does not have secrets get permission
```

**рж╕ржорж╛ржзрж╛ржи:**

1. **ржХрзА ржнрж▓рзНржЯ ржЕржирзБржорждрж┐ ржкрзНрж░ржжрж╛ржи ржХрж░рзБржи:**
```bicep
resource keyVaultAccessPolicy 'Microsoft.KeyVault/vaults/accessPolicies@2023-07-01' = {
  parent: keyVault
  name: 'add'
  properties: {
    accessPolicies: [
      {
        tenantId: subscription().tenantId
        objectId: containerApp.identity.principalId
        permissions: {
          secrets: ['get', 'list']
        }
      }
    ]
  }
}
```

2. **RBAC ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи ржЕрзНржпрж╛ржХрзНрж╕рзЗрж╕ ржкрж▓рж┐рж╕рж┐рж░ ржкрж░рж┐ржмрж░рзНрждрзЗ:**
```bicep
resource keyVaultSecretsUserRole 'Microsoft.Authorization/roleAssignments@2022-04-01' = {
  scope: keyVault
  name: guid(keyVault.id, containerApp.id, 'Key Vault Secrets User')
  properties: {
    principalId: containerApp.identity.principalId
    roleDefinitionId: subscriptionResourceId('Microsoft.Authorization/roleDefinitions', '4633458b-17de-408a-b874-0445c86b69e6')
    principalType: 'ServicePrincipal'
  }
}
```

## ржоржбрзЗрж▓ ржбрж┐ржкрзНрж▓рзЯржорзЗржирзНржЯ ржмрзНржпрж░рзНржерждрж╛

### рж╕ржорж╕рзНржпрж╛: ржоржбрзЗрж▓ рж╕ржВрж╕рзНржХрж░ржг ржЙржкрж▓ржмрзНржз ржирзЯ

**рж▓ржХрзНрж╖ржг:**
```
Error: Model version 'gpt-4-32k' is not available
```

**рж╕ржорж╛ржзрж╛ржи:**

1. **ржЙржкрж▓ржмрзНржз ржоржбрзЗрж▓ ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи:**
```bash
# ржЙржкрж▓ржмрзНржз ржоржбрзЗрж▓ржЧрзБрж▓рж┐рж░ рждрж╛рж▓рж┐ржХрж╛
az cognitiveservices account list-models \
  --name YOUR_OPENAI_RESOURCE \
  --resource-group YOUR_RG \
  --query "[].{name:model.name, version:model.version}" \
  --output table
```

2. **ржоржбрзЗрж▓ ржлрж▓рзЛржмрзНржпрж╛ржХ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи:**
```bicep
// Model deployment with fallback
@description('Primary model configuration')
param primaryModel object = {
  name: 'gpt-4o-mini'
  version: '2024-07-18'
}

@description('Fallback model configuration')
param fallbackModel object = {
  name: 'gpt-35-turbo'
  version: '0125'
}

// Try primary model first, fallback if unavailable
resource primaryDeployment 'Microsoft.CognitiveServices/accounts/deployments@2023-05-01' = {
  parent: openAi
  name: 'chat-model'
  properties: {
    model: primaryModel
  }
  sku: {
    name: 'Standard'
    capacity: 10
  }
}
```

3. **ржбрж┐ржкрзНрж▓рзЯржорзЗржирзНржЯрзЗрж░ ржЖржЧрзЗ ржоржбрзЗрж▓ ржпрж╛ржЪрж╛ржЗ ржХрж░рзБржи:**
```python
# ржкрзВрж░рзНржм-ржкрзНрж░ржХрж╛рж╢ ржоржбрзЗрж▓ ржпрж╛ржЪрж╛ржЗржХрж░ржг
import httpx

async def validate_model_availability(model_name: str, version: str) -> bool:
    """Check if model is available before deployment."""
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"{AZURE_OPENAI_ENDPOINT}/openai/models",
                headers={"api-key": AZURE_OPENAI_API_KEY}
            )
            models = response.json()
            return any(
                model["id"] == f"{model_name}-{version}"
                for model in models.get("data", [])
            )
    except Exception:
        return False
```

## ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржПржмржВ рж╕рзНржХрзЗрж▓рж┐ржВ рж╕ржорж╕рзНржпрж╛

### рж╕ржорж╕рзНржпрж╛: ржЙржЪрзНржЪ рж▓рзЗржЯрзЗржирзНрж╕рж┐ ржкрзНрж░рждрж┐ржХрзНрж░рж┐рзЯрж╛

**рж▓ржХрзНрж╖ржг:**
- ржкрзНрж░рждрж┐ржХрзНрж░рж┐рзЯрж╛ рж╕ржорзЯ > рзйрзж рж╕рзЗржХрзЗржирзНржб
- ржЯрж╛ржЗржоржЖржЙржЯ рждрзНрж░рзБржЯрж┐
- ржжрзБрж░рзНржмрж▓ ржмрзНржпржмрж╣рж╛рж░ржХрж╛рж░рзАрж░ ржЕржнрж┐ржЬрзНржЮрждрж╛

**рж╕ржорж╛ржзрж╛ржи:**

1. **рж░рж┐ржХрзЛрзЯрзЗрж╕рзНржЯ ржЯрж╛ржЗржоржЖржЙржЯ ржкрзНрж░рзЯрзЛржЧ ржХрж░рзБржи:**
```python
# рж╕ржарж┐ржХ ржЯрж╛ржЗржоржЖржЙржЯ ржХржиржлрж┐ржЧрж╛рж░ ржХрж░рзБржи
import httpx

client = httpx.AsyncClient(
    timeout=httpx.Timeout(
        connect=5.0,
        read=30.0,
        write=10.0,
        pool=10.0
    )
)
```

2. **рж░рзЗрж╕ржкржирзНрж╕ ржХрзНржпрж╛рж╢рж┐ржВ ржпрзЛржЧ ржХрж░рзБржи:**
```python
# ржкрзНрж░рждрж┐ржХрзНрж░рж┐ржпрж╝рж╛рж░ ржЬржирзНржп рж░рзЗржбрж┐рж╕ ржХрзНржпрж╛рж╢
import redis.asyncio as redis
import json

class ResponseCache:
    def __init__(self, redis_url: str):
        self.redis = redis.from_url(redis_url)
        
    async def get_cached_response(self, query_hash: str) -> str | None:
        """Get cached response if available."""
        cached = await self.redis.get(f"ai_response:{query_hash}")
        return cached.decode() if cached else None
        
    async def cache_response(self, query_hash: str, response: str, ttl: int = 3600):
        """Cache AI response with TTL."""
        await self.redis.setex(f"ai_response:{query_hash}", ttl, response)
```

3. **ржЕржЯрзЛ-рж╕рзНржХрзЗрж▓рж┐ржВ ржХржиржлрж┐ржЧрж╛рж░ ржХрж░рзБржи:**
```bicep
resource containerApp 'Microsoft.App/containerApps@2024-03-01' = {
  properties: {
    template: {
      scale: {
        minReplicas: 2
        maxReplicas: 20
        rules: [
          {
            name: 'http-requests'
            http: {
              metadata: {
                concurrentRequests: '5'  // Scale aggressively for AI workloads
              }
            }
          }
          {
            name: 'cpu-utilization'
            custom: {
              type: 'cpu'
              metadata: {
                type: 'Utilization'
                value: '60'  // Lower threshold for AI apps
              }
            }
          }
        ]
      }
    }
  }
}
```

### рж╕ржорж╕рзНржпрж╛: ржорзЗржорзЛрж░рж┐ ржЖржЙржЯ ржЕржл рждрзНрж░рзБржЯрж┐

**рж▓ржХрзНрж╖ржг:**
```
Error: Container killed due to memory limit exceeded
```

**рж╕ржорж╛ржзрж╛ржи:**

1. **ржорзЗржорзЛрж░рж┐ ржмрж░рж╛ржжрзНржж ржмрзГржжрзНржзрж┐ ржХрж░рзБржи:**
```bicep
resource containerApp 'Microsoft.App/containerApps@2024-03-01' = {
  properties: {
    template: {
      containers: [
        {
          name: 'main'
          resources: {
            cpu: json('1.0')
            memory: '2Gi'  // Increase for AI workloads
          }
        }
      ]
    }
  }
}
```

2. **ржорзЗржорзЛрж░рж┐ ржмрзНржпржмрж╣рж╛рж░рзЗрж░ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬ ржХрж░рзБржи:**
```python
# ржорзЗржорж░рж┐-ржжржХрзНрж╖ ржоржбрзЗрж▓ ржкрж░рж┐ржЪрж╛рж▓ржирж╛
import gc
import psutil

class MemoryOptimizedAI:
    def __init__(self):
        self.max_memory_percent = 80
        
    async def process_request(self, request):
        """Process request with memory monitoring."""
        # ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛ржХрж░ржгрзЗрж░ ржЖржЧрзЗ ржорзЗржорж░рж┐ ржмрзНржпржмрж╣рж╛рж░ ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи
        memory_percent = psutil.virtual_memory().percent
        if memory_percent > self.max_memory_percent:
            gc.collect()  # ржЧрж╛рж░рзНржмрзЗржЬ рж╕ржВржЧрзНрж░рж╣ ржмрж╛ржзрзНржп ржХрж░рзБржи
            
        result = await self._process_ai_request(request)
        
        # ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛ржХрж░ржгрзЗрж░ ржкрж░рзЗ ржкрж░рж┐рж╖рзНржХрж╛рж░ ржХрж░рзБржи
        gc.collect()
        return result
```

## ржЦрж░ржЪ ржПржмржВ ржХрзЛржЯрж╛рж░ ржмрзНржпржмрж╕рзНржерж╛ржкржирж╛

### рж╕ржорж╕рзНржпрж╛: ржЕржкрзНрж░рждрзНржпрж╛рж╢рж┐ржд ржЙржЪрзНржЪ ржЦрж░ржЪ

**рж▓ржХрзНрж╖ржг:**
- Azure ржмрж┐рж▓ ржкрзНрж░рждрзНржпрж╛рж╢рж╛рж░ ржЪрзЗрзЯрзЗ ржмрзЗрж╢рж┐
- ржЯрзЛржХрзЗржи ржмрзНржпржмрж╣рж╛рж░рзЗрж░ ржЕржирзБржорж╛ржи ржЕрждрж┐ржХрзНрж░ржо
- ржмрж╛ржЬрзЗржЯ ржЕрзНржпрж╛рж▓рж╛рж░рзНржЯ рж╕ржХрзНрж░рж┐рзЯ

**рж╕ржорж╛ржзрж╛ржи:**

1. **ржЦрж░ржЪ ржирж┐рзЯржирзНрждрзНрж░ржг ржкрзНрж░рзЯрзЛржЧ ржХрж░рзБржи:**
```python
# ржЯрзЛржХрзЗржи ржмрзНржпржмрж╣рж╛рж░рзЗрж░ ржЯрзНрж░рзНржпрж╛ржХрж┐ржВ
class TokenTracker:
    def __init__(self, monthly_limit: int = 100000):
        self.monthly_limit = monthly_limit
        self.current_usage = 0
        
    async def track_usage(self, prompt_tokens: int, completion_tokens: int):
        """Track token usage with limits."""
        total_tokens = prompt_tokens + completion_tokens
        self.current_usage += total_tokens
        
        if self.current_usage > self.monthly_limit:
            raise Exception("Monthly token limit exceeded")
            
        return total_tokens
```

2. **ржЦрж░ржЪ ржЕрзНржпрж╛рж▓рж╛рж░рзНржЯ рж╕рзЗржЯ ржХрж░рзБржи:**
```bicep
resource budgetAlert 'Microsoft.Consumption/budgets@2023-05-01' = {
  name: 'ai-workload-budget'
  properties: {
    timePeriod: {
      startDate: '2024-01-01'
      endDate: '2024-12-31'
    }
    timeGrain: 'Monthly'
    amount: 500  // $500 monthly limit
    category: 'Cost'
    notifications: {
      Actual_GreaterThan_80_Percent: {
        enabled: true
        operator: 'GreaterThan'
        threshold: 80
        contactEmails: ['admin@company.com']
        contactRoles: ['Owner']
      }
    }
  }
}
```

3. **ржоржбрзЗрж▓ ржирж┐рж░рзНржмрж╛ржЪржи ржЕржкрзНржЯрж┐ржорж╛ржЗржЬ ржХрж░рзБржи:**
```python
# ржЦрж░ржЪ-рж╕ржЪрзЗрждржи ржоржбрзЗрж▓ ржирж┐рж░рзНржмрж╛ржЪржи
MODEL_COSTS = {
    'gpt-4o-mini': 0.00015,  # ржкрзНрж░рждрж┐ рззржХрзЗ ржЯрзЛржХрзЗржи
    'gpt-4': 0.03,          # ржкрзНрж░рждрж┐ рззржХрзЗ ржЯрзЛржХрзЗржи
    'gpt-35-turbo': 0.0015  # ржкрзНрж░рждрж┐ рззржХрзЗ ржЯрзЛржХрзЗржи
}

def select_model_by_cost(complexity: str, budget_remaining: float) -> str:
    """Select model based on complexity and budget."""
    if complexity == 'simple' or budget_remaining < 10:
        return 'gpt-4o-mini'
    elif complexity == 'medium':
        return 'gpt-35-turbo'
    else:
        return 'gpt-4'
```

## ржбрж┐ржмрж╛ржЧрж┐ржВ ржЯрзБрж▓рж╕ ржПржмржВ ржХрзМрж╢рж▓

### AZD ржбрж┐ржмрж╛ржЧрж┐ржВ ржХржорж╛ржирзНржб

```bash
# ржмрж┐рж╕рзНрждрж╛рж░рж┐ржд рж▓ржЧрж┐ржВ рж╕ржХрзНрж░рж┐ржпрж╝ ржХрж░рзБржи
azd up --debug

# ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯ рж╕рзНржЯрзНржпрж╛ржЯрж╛рж╕ ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи
azd show

# ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯ рж▓ржЧ ржжрзЗржЦрзБржи
azd logs --follow

# ржкрж░рж┐ржмрзЗрж╢ ржнрзЗрж░рж┐ржпрж╝рзЗржмрж▓ ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи
azd env get-values
```

### ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржи ржбрж┐ржмрж╛ржЧрж┐ржВ

1. **рж╕рзНржЯрзНрж░рж╛ржХржЪрж╛рж░рзНржб рж▓ржЧрж┐ржВ:**
```python
import logging
import json

# ржПржЖржЗ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржирзЗрж░ ржЬржирзНржп ржХрж╛ржарж╛ржорзЛржЧржд рж▓ржЧрж┐ржВ ржХржиржлрж┐ржЧрж╛рж░ ржХрж░рзБржи
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

def log_ai_request(model: str, tokens: int, latency: float, success: bool):
    """Log AI request details."""
    logger.info(json.dumps({
        'event': 'ai_request',
        'model': model,
        'tokens': tokens,
        'latency_ms': latency,
        'success': success
    }))
```

2. **рж╣рзЗрж▓рже ржЪрзЗржХ ржПржирзНржбржкрзЯрзЗржирзНржЯ:**
```python
@app.get("/debug/health")
async def detailed_health_check():
    """Comprehensive health check for debugging."""
    checks = {}
    
    # ржУржкрзЗржиржПржЖржЗ рж╕ржВржпрзЛржЧ ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи
    try:
        client = AsyncOpenAI(azure_endpoint=AZURE_OPENAI_ENDPOINT)
        await client.models.list()
        checks['openai'] = {'status': 'healthy'}
    except Exception as e:
        checks['openai'] = {'status': 'unhealthy', 'error': str(e)}
    
    # рж╕рж╛рж░рзНржЪ ржкрж░рж┐рж╖рзЗржмрж╛ ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи
    try:
        search_client = SearchIndexClient(
            endpoint=AZURE_SEARCH_ENDPOINT,
            credential=DefaultAzureCredential()
        )
        indexes = await search_client.list_index_names()
        checks['search'] = {'status': 'healthy', 'indexes': list(indexes)}
    except Exception as e:
        checks['search'] = {'status': 'unhealthy', 'error': str(e)}
    
    return checks
```

3. **ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржоржирж┐ржЯрж░рж┐ржВ:**
```python
import time
from functools import wraps

def monitor_performance(func):
    """Decorator to monitor function performance."""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            success = True
        except Exception as e:
            result = None
            success = False
            raise
        finally:
            end_time = time.time()
            latency = (end_time - start_time) * 1000
            
            logger.info(json.dumps({
                'function': func.__name__,
                'latency_ms': latency,
                'success': success
            }))
        
        return result
    return wrapper
```

## рж╕рж╛ржзрж╛рж░ржг рждрзНрж░рзБржЯрж┐ ржХрзЛржб ржПржмржВ рж╕ржорж╛ржзрж╛ржи

| рждрзНрж░рзБржЯрж┐ ржХрзЛржб | ржмрж░рзНржгржирж╛ | рж╕ржорж╛ржзрж╛ржи |
|------------|-------------|----------|
| 401 | ржЕржирзБржорзЛржжрж┐ржд ржирзЯ | API ржХрзА ржПржмржВ ржорзНржпрж╛ржирзЗржЬржб ржЖржЗржбрзЗржирзНржЯрж┐ржЯрж┐ ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржи ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи |
| 403 | ржирж┐рж╖рж┐ржжрзНржз | RBAC рж░рзЛрж▓ ржЕрзНржпрж╛рж╕рж╛ржЗржиржорзЗржирзНржЯ ржпрж╛ржЪрж╛ржЗ ржХрж░рзБржи |
| 429 | рж░рзЗржЯ рж╕рзАржорж┐ржд | ржПржХрзНрж╕ржкрзЛржирзЗржирж╢рж┐рзЯрж╛рж▓ ржмрзНржпрж╛ржХржЕржл рж╕рж╣ рж░рж┐ржЯрзНрж░рж╛ржЗ рж▓ржЬрж┐ржХ ржкрзНрж░рзЯрзЛржЧ ржХрж░рзБржи |
| 500 | ржЕржнрзНржпржирзНрждрж░рзАржг рж╕рж╛рж░рзНржнрж╛рж░ рждрзНрж░рзБржЯрж┐ | ржоржбрзЗрж▓ ржбрж┐ржкрзНрж▓рзЯржорзЗржирзНржЯ рж╕рзНржЯрзНржпрж╛ржЯрж╛рж╕ ржПржмржВ рж▓ржЧ ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи |
| 503 | ржкрж░рж┐рж╖рзЗржмрж╛ ржЕржкрзНрж░рж╛ржкрзНржп | ржкрж░рж┐рж╖рзЗржмрж╛рж░ рж╕рзНржмрж╛рж╕рзНржерзНржп ржПржмржВ ржЖржЮрзНржЪрж▓рж┐ржХ ржЙржкрж▓ржмрзНржзрждрж╛ ржпрж╛ржЪрж╛ржЗ ржХрж░рзБржи |

## ржкрж░ржмрж░рзНрждрзА ржкржжржХрзНрж╖рзЗржк

1. **[AI ржоржбрзЗрж▓ ржбрж┐ржкрзНрж▓рзЯржорзЗржирзНржЯ ржЧрж╛ржЗржб](ai-model-deployment.md)** ржкрж░рзНржпрж╛рж▓рзЛржЪржирж╛ ржХрж░рзБржи ржбрж┐ржкрзНрж▓рзЯржорзЗржирзНржЯрзЗрж░ рж╕рзЗрж░рж╛ ржЕржирзБрж╢рзАрж▓ржирзЗрж░ ржЬржирзНржп
2. **[Production AI Practices](production-ai-practices.md)** рж╕ржорзНржкрзВрж░рзНржг ржХрж░рзБржи ржПржирзНржЯрж╛рж░ржкрзНрж░рж╛ржЗржЬ-ржкрзНрж░рж╕рзНрждрзБржд рж╕ржорж╛ржзрж╛ржирзЗрж░ ржЬржирзНржп
3. **[Microsoft Foundry Discord](https://aka.ms/foundry/discord)**-ржП ржпрзЛржЧ ржжрж┐ржи ржХржорж┐ржЙржирж┐ржЯрж┐ рж╕рж╛ржкрзЛрж░рзНржЯрзЗрж░ ржЬржирзНржп
4. **рж╕ржорж╕рзНржпрж╛ ржЬржорж╛ ржжрж┐ржи** [AZD GitHub рж░рж┐ржкрзЛржЬрж┐ржЯрж░рж┐рждрзЗ](https://github.com/Azure/azure-dev) AZD-ржирж┐рж░рзНржжрж┐рж╖рзНржЯ рж╕ржорж╕рзНржпрж╛рж░ ржЬржирзНржп

## рж░рж┐рж╕рзЛрж░рзНрж╕

- [Azure OpenAI ржкрж░рж┐рж╖рзЗржмрж╛ рж╕ржорж╕рзНржпрж╛ рж╕ржорж╛ржзрж╛ржи](https://learn.microsoft.com/azure/ai-services/openai/troubleshooting)
- [ржХржирзНржЯрзЗржЗржирж╛рж░ ржЕрзНржпрж╛ржк рж╕ржорж╕рзНржпрж╛ рж╕ржорж╛ржзрж╛ржи](https://learn.microsoft.com/azure/container-apps/troubleshooting)
- [Azure AI рж╕рж╛рж░рзНржЪ рж╕ржорж╕рзНржпрж╛ рж╕ржорж╛ржзрж╛ржи](https://learn.microsoft.com/azure/search/search-monitor-logs)

---

**ржЕржзрзНржпрж╛рзЯрзЗрж░ ржирзЗржнрж┐ржЧрзЗрж╢ржи:**
- **ЁЯУЪ ржХрзЛрж░рзНрж╕ рж╣рзЛржо**: [AZD For Beginners](../../README.md)
- **ЁЯУЦ ржмрж░рзНрждржорж╛ржи ржЕржзрзНржпрж╛рзЯ**: ржЕржзрзНржпрж╛рзЯ рзн - рж╕ржорж╕рзНржпрж╛ рж╕ржорж╛ржзрж╛ржи ржУ ржбрж┐ржмрж╛ржЧрж┐ржВ
- **тмЕя╕П ржкрзВрж░рзНржмржмрж░рзНрждрзА**: [ржбрж┐ржмрж╛ржЧрж┐ржВ ржЧрж╛ржЗржб](debugging.md)
- **тЮбя╕П ржкрж░ржмрж░рзНрждрзА ржЕржзрзНржпрж╛рзЯ**: [ржЕржзрзНржпрж╛рзЯ рзо: ржкрзНрж░рзЛржбрж╛ржХрж╢ржи ржУ ржПржирзНржЯрж╛рж░ржкрзНрж░рж╛ржЗржЬ ржкрзНржпрж╛ржЯрж╛рж░рзНржи](../microsoft-foundry/production-ai-practices.md)
- [Azure Developer CLI рж╕ржорж╕рзНржпрж╛ рж╕ржорж╛ржзрж╛ржи](https://learn.microsoft.com/azure/developer/azure-developer-cli/troubleshoot)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**ржЕрж╕рзНржмрзАржХрзГрждрж┐**:  
ржПржЗ ржиржерж┐ржЯрж┐ AI ржЕржирзБржмрж╛ржж ржкрж░рж┐рж╖рзЗржмрж╛ [Co-op Translator](https://github.com/Azure/co-op-translator) ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ ржЕржирзБржмрж╛ржж ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗред ржЖржорж░рж╛ ржпржерж╛рж╕рж╛ржзрзНржп рж╕ржарж┐ржХрждрж╛рж░ ржЬржирзНржп ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рж┐, рждржмрзЗ ржЕржирзБржЧрзНрж░рж╣ ржХрж░рзЗ ржоржирзЗ рж░рж╛ржЦржмрзЗржи ржпрзЗ рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ ржЕржирзБржмрж╛ржжрзЗ рждрзНрж░рзБржЯрж┐ ржмрж╛ ржЕрж╕ржЩрзНржЧрждрж┐ ржерж╛ржХрждрзЗ ржкрж╛рж░рзЗред ржорзВрж▓ ржнрж╛рж╖рж╛ржпрж╝ ржерж╛ржХрж╛ ржиржерж┐ржЯрж┐ржХрзЗ ржкрзНрж░рж╛ржорж╛ржгрж┐ржХ ржЙрзОрж╕ рж╣рж┐рж╕рзЗржмрзЗ ржмрж┐ржмрзЗржЪржирж╛ ржХрж░рж╛ ржЙржЪрж┐рждред ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг рждржерзНржпрзЗрж░ ржЬржирзНржп, ржкрзЗрж╢рж╛ржжрж╛рж░ ржорж╛ржиржм ржЕржирзБржмрж╛ржж рж╕рзБржкрж╛рж░рж┐рж╢ ржХрж░рж╛ рж╣ржпрж╝ред ржПржЗ ржЕржирзБржмрж╛ржж ржмрзНржпржмрж╣рж╛рж░рзЗрж░ ржлрж▓рзЗ ржХрзЛржирзЛ ржнрзБрж▓ ржмрзЛржЭрж╛ржмрзБржЭрж┐ ржмрж╛ ржнрзБрж▓ ржмрзНржпрж╛ржЦрзНржпрж╛ рж╣рж▓рзЗ ржЖржорж░рж╛ ржжрж╛ржпрж╝ржмржжрзНржз ржерж╛ржХржм ржирж╛ред
<!-- CO-OP TRANSLATOR DISCLAIMER END -->