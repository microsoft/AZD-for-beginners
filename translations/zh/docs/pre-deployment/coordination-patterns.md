<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bcefbd5d0107691ef3e6e33ba694d6f4",
  "translation_date": "2025-11-19T16:29:35+00:00",
  "source_file": "docs/pre-deployment/coordination-patterns.md",
  "language_code": "zh"
}
-->
# å¤šä»£ç†åè°ƒæ¨¡å¼

â±ï¸ **é¢„è®¡æ—¶é—´**ï¼š60-75 åˆ†é’Ÿ | ğŸ’° **é¢„è®¡æˆæœ¬**ï¼š~$100-300/æœˆ | â­ **å¤æ‚åº¦**ï¼šé«˜çº§

**ğŸ“š å­¦ä¹ è·¯å¾„ï¼š**
- â† ä¸Šä¸€èŠ‚ï¼š[å®¹é‡è§„åˆ’](capacity-planning.md) - èµ„æºå¤§å°å’Œæ‰©å±•ç­–ç•¥
- ğŸ¯ **å½“å‰ä½ç½®**ï¼šå¤šä»£ç†åè°ƒæ¨¡å¼ï¼ˆç¼–æ’ã€é€šä¿¡ã€çŠ¶æ€ç®¡ç†ï¼‰
- â†’ ä¸‹ä¸€èŠ‚ï¼š[SKU é€‰æ‹©](sku-selection.md) - é€‰æ‹©åˆé€‚çš„ Azure æœåŠ¡
- ğŸ  [è¯¾ç¨‹ä¸»é¡µ](../../README.md)

---

## ä½ å°†å­¦åˆ°ä»€ä¹ˆ

å®Œæˆæœ¬è¯¾ç¨‹åï¼Œä½ å°†èƒ½å¤Ÿï¼š
- ç†è§£**å¤šä»£ç†æ¶æ„**æ¨¡å¼åŠå…¶é€‚ç”¨åœºæ™¯
- å®ç°**ç¼–æ’æ¨¡å¼**ï¼ˆé›†ä¸­å¼ã€åˆ†å¸ƒå¼ã€åˆ†å±‚å¼ï¼‰
- è®¾è®¡**ä»£ç†é€šä¿¡**ç­–ç•¥ï¼ˆåŒæ­¥ã€å¼‚æ­¥ã€äº‹ä»¶é©±åŠ¨ï¼‰
- ç®¡ç†åˆ†å¸ƒå¼ä»£ç†çš„**å…±äº«çŠ¶æ€**
- åœ¨ Azure ä¸Šä½¿ç”¨ AZD éƒ¨ç½²**å¤šä»£ç†ç³»ç»Ÿ**
- å°†**åè°ƒæ¨¡å¼**åº”ç”¨äºå®é™… AI åœºæ™¯
- ç›‘æ§å’Œè°ƒè¯•åˆ†å¸ƒå¼ä»£ç†ç³»ç»Ÿ

## ä¸ºä»€ä¹ˆå¤šä»£ç†åè°ƒå¾ˆé‡è¦

### æ¼”å˜ï¼šä»å•ä»£ç†åˆ°å¤šä»£ç†

**å•ä»£ç†ï¼ˆç®€å•ï¼‰ï¼š**
```
User â†’ Agent â†’ Response
```

- âœ… æ˜“äºç†è§£å’Œå®ç°
- âœ… ç®€å•ä»»åŠ¡æ‰§è¡Œå¿«é€Ÿ
- âŒ å—é™äºå•ä¸€æ¨¡å‹çš„èƒ½åŠ›
- âŒ æ— æ³•å¹¶è¡Œå¤„ç†å¤æ‚ä»»åŠ¡
- âŒ æ— ä¸“ä¸šåŒ–

**å¤šä»£ç†ç³»ç»Ÿï¼ˆé«˜çº§ï¼‰ï¼š**
```
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Orchestratorâ”‚
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚         â”‚         â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”
    â”‚Agent1â”‚  â”‚Agent2â”‚  â”‚Agent3 â”‚
    â”‚(Plan)â”‚  â”‚(Code)â”‚  â”‚(Review)â”‚
    â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜
```

- âœ… ä¸“ä¸šåŒ–ä»£ç†å¤„ç†ç‰¹å®šä»»åŠ¡
- âœ… å¹¶è¡Œæ‰§è¡Œæé«˜é€Ÿåº¦
- âœ… æ¨¡å—åŒ–ä¸”æ˜“äºç»´æŠ¤
- âœ… æ›´é€‚åˆå¤æ‚å·¥ä½œæµ
- âš ï¸ éœ€è¦åè°ƒé€»è¾‘

**ç±»æ¯”**ï¼šå•ä»£ç†å°±åƒä¸€ä¸ªäººå®Œæˆæ‰€æœ‰ä»»åŠ¡ï¼›å¤šä»£ç†å°±åƒä¸€ä¸ªå›¢é˜Ÿï¼Œæ¯ä¸ªæˆå‘˜éƒ½æœ‰ä¸“é•¿ï¼ˆç ”ç©¶å‘˜ã€ç¨‹åºå‘˜ã€å®¡ç¨¿äººã€ä½œè€…ï¼‰ï¼Œå…±åŒåä½œå®Œæˆä»»åŠ¡ã€‚

---

## æ ¸å¿ƒåè°ƒæ¨¡å¼

### æ¨¡å¼ 1ï¼šé¡ºåºåè°ƒï¼ˆè´£ä»»é“¾ï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šä»»åŠ¡å¿…é¡»æŒ‰ç‰¹å®šé¡ºåºå®Œæˆï¼Œæ¯ä¸ªä»£ç†åŸºäºå‰ä¸€ä¸ªçš„è¾“å‡ºã€‚

```mermaid
sequenceDiagram
    participant User
    participant Orchestrator
    participant Agent1 as ç ”ç©¶ä»£ç†
    participant Agent2 as æ’°å†™ä»£ç†
    participant Agent3 as ç¼–è¾‘ä»£ç†
    
    User->>Orchestrator: "æ’°å†™å…³äºäººå·¥æ™ºèƒ½çš„æ–‡ç« "
    Orchestrator->>Agent1: ç ”ç©¶ä¸»é¢˜
    Agent1-->>Orchestrator: ç ”ç©¶ç»“æœ
    Orchestrator->>Agent2: æ’°å†™åˆç¨¿ï¼ˆä½¿ç”¨ç ”ç©¶ç»“æœï¼‰
    Agent2-->>Orchestrator: åˆç¨¿æ–‡ç« 
    Orchestrator->>Agent3: ç¼–è¾‘å’Œæ”¹è¿›
    Agent3-->>Orchestrator: æœ€ç»ˆæ–‡ç« 
    Orchestrator-->>User: ç²¾ä¿®æ–‡ç« 
    
    Note over User,Agent3: é¡ºåºï¼šæ¯ä¸€æ­¥ç­‰å¾…å‰ä¸€æ­¥å®Œæˆ
```
**ä¼˜ç‚¹ï¼š**
- âœ… æ•°æ®æµæ¸…æ™°
- âœ… æ˜“äºè°ƒè¯•
- âœ… æ‰§è¡Œé¡ºåºå¯é¢„æµ‹

**å±€é™æ€§ï¼š**
- âŒ è¾ƒæ…¢ï¼ˆæ— å¹¶è¡Œæ€§ï¼‰
- âŒ ä¸€ä¸ªå¤±è´¥ä¼šé˜»å¡æ•´ä¸ªé“¾æ¡
- âŒ æ— æ³•å¤„ç†ç›¸äº’ä¾èµ–çš„ä»»åŠ¡

**ç¤ºä¾‹ç”¨ä¾‹ï¼š**
- å†…å®¹åˆ›å»ºæµæ°´çº¿ï¼ˆç ”ç©¶ â†’ å†™ä½œ â†’ ç¼–è¾‘ â†’ å‘å¸ƒï¼‰
- ä»£ç ç”Ÿæˆï¼ˆè§„åˆ’ â†’ å®ç° â†’ æµ‹è¯• â†’ éƒ¨ç½²ï¼‰
- æŠ¥å‘Šç”Ÿæˆï¼ˆæ•°æ®æ”¶é›† â†’ åˆ†æ â†’ å¯è§†åŒ– â†’ æ€»ç»“ï¼‰

---

### æ¨¡å¼ 2ï¼šå¹¶è¡Œåè°ƒï¼ˆæ‰‡å‡º/æ‰‡å…¥ï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šç‹¬ç«‹ä»»åŠ¡å¯åŒæ—¶è¿è¡Œï¼Œç»“æœåœ¨æœ€ååˆå¹¶ã€‚

```mermaid
graph TB
    User[ç”¨æˆ·è¯·æ±‚]
    Orchestrator[åè°ƒå™¨]
    Agent1[åˆ†æä»£ç†]
    Agent2[ç ”ç©¶ä»£ç†]
    Agent3[æ•°æ®ä»£ç†]
    Aggregator[ç»“æœèšåˆå™¨]
    Response[ç»„åˆå“åº”]
    
    User --> Orchestrator
    Orchestrator --> Agent1
    Orchestrator --> Agent2
    Orchestrator --> Agent3
    Agent1 --> Aggregator
    Agent2 --> Aggregator
    Agent3 --> Aggregator
    Aggregator --> Response
    
    style Orchestrator fill:#2196F3,stroke:#1976D2,stroke-width:3px,color:#fff
    style Aggregator fill:#4CAF50,stroke:#388E3C,stroke-width:3px,color:#fff
```
**ä¼˜ç‚¹ï¼š**
- âœ… å¿«é€Ÿï¼ˆå¹¶è¡Œæ‰§è¡Œï¼‰
- âœ… å®¹é”™æ€§å¼ºï¼ˆå¯æ¥å—éƒ¨åˆ†ç»“æœï¼‰
- âœ… æ°´å¹³æ‰©å±•æ€§å¥½

**å±€é™æ€§ï¼š**
- âš ï¸ ç»“æœå¯èƒ½æ— åºåˆ°è¾¾
- âš ï¸ éœ€è¦èšåˆé€»è¾‘
- âš ï¸ çŠ¶æ€ç®¡ç†å¤æ‚

**ç¤ºä¾‹ç”¨ä¾‹ï¼š**
- å¤šæºæ•°æ®æ”¶é›†ï¼ˆAPI + æ•°æ®åº“ + ç½‘é¡µæŠ“å–ï¼‰
- ç«äº‰æ€§åˆ†æï¼ˆå¤šä¸ªæ¨¡å‹ç”Ÿæˆè§£å†³æ–¹æ¡ˆï¼Œé€‰æ‹©æœ€ä½³ï¼‰
- ç¿»è¯‘æœåŠ¡ï¼ˆåŒæ—¶ç¿»è¯‘æˆå¤šç§è¯­è¨€ï¼‰

---

### æ¨¡å¼ 3ï¼šåˆ†å±‚åè°ƒï¼ˆç®¡ç†è€…-å·¥ä½œè€…ï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šå¤æ‚å·¥ä½œæµåŒ…å«å­ä»»åŠ¡ï¼Œéœ€è¦å§”æ´¾ã€‚

```mermaid
graph TB
    Master[ä¸»åè°ƒå™¨]
    Manager1[ç ”ç©¶ç»ç†]
    Manager2[å†…å®¹ç»ç†]
    W1[ç½‘é¡µæŠ“å–å™¨]
    W2[è®ºæ–‡åˆ†æå™¨]
    W3[å†™ä½œè€…]
    W4[ç¼–è¾‘]
    
    Master --> Manager1
    Master --> Manager2
    Manager1 --> W1
    Manager1 --> W2
    Manager2 --> W3
    Manager2 --> W4
    
    style Master fill:#FF9800,stroke:#F57C00,stroke-width:3px,color:#fff
    style Manager1 fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff
    style Manager2 fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff
```
**ä¼˜ç‚¹ï¼š**
- âœ… å¤„ç†å¤æ‚å·¥ä½œæµ
- âœ… æ¨¡å—åŒ–ä¸”æ˜“äºç»´æŠ¤
- âœ… èŒè´£è¾¹ç•Œæ¸…æ™°

**å±€é™æ€§ï¼š**
- âš ï¸ æ¶æ„æ›´å¤æ‚
- âš ï¸ å»¶è¿Ÿæ›´é«˜ï¼ˆå¤šå±‚åè°ƒï¼‰
- âš ï¸ éœ€è¦å¤æ‚çš„ç¼–æ’

**ç¤ºä¾‹ç”¨ä¾‹ï¼š**
- ä¼ä¸šæ–‡æ¡£å¤„ç†ï¼ˆåˆ†ç±» â†’ è·¯ç”± â†’ å¤„ç† â†’ å­˜æ¡£ï¼‰
- å¤šé˜¶æ®µæ•°æ®ç®¡é“ï¼ˆæ‘„å– â†’ æ¸…æ´— â†’ è½¬æ¢ â†’ åˆ†æ â†’ æŠ¥å‘Šï¼‰
- å¤æ‚è‡ªåŠ¨åŒ–å·¥ä½œæµï¼ˆè§„åˆ’ â†’ èµ„æºåˆ†é… â†’ æ‰§è¡Œ â†’ ç›‘æ§ï¼‰

---

### æ¨¡å¼ 4ï¼šäº‹ä»¶é©±åŠ¨åè°ƒï¼ˆå‘å¸ƒ-è®¢é˜…ï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šä»£ç†éœ€è¦å¯¹äº‹ä»¶ä½œå‡ºååº”ï¼Œä¸”éœ€è¦æ¾è€¦åˆã€‚

```mermaid
sequenceDiagram
    participant Agent1 as æ•°æ®æ”¶é›†å™¨
    participant EventBus as Azure æœåŠ¡æ€»çº¿
    participant Agent2 as åˆ†æå™¨
    participant Agent3 as é€šçŸ¥å™¨
    participant Agent4 as å­˜æ¡£å™¨
    
    Agent1->>EventBus: å‘å¸ƒ "æ•°æ®æ¥æ”¶" äº‹ä»¶
    EventBus->>Agent2: è®¢é˜…: åˆ†ææ•°æ®
    EventBus->>Agent3: è®¢é˜…: å‘é€é€šçŸ¥
    EventBus->>Agent4: è®¢é˜…: å­˜æ¡£æ•°æ®
    
    Note over Agent1,Agent4: æ‰€æœ‰è®¢é˜…è€…ç‹¬ç«‹å¤„ç†
    
    Agent2->>EventBus: å‘å¸ƒ "åˆ†æå®Œæˆ" äº‹ä»¶
    EventBus->>Agent3: è®¢é˜…: å‘é€åˆ†ææŠ¥å‘Š
```
**ä¼˜ç‚¹ï¼š**
- âœ… ä»£ç†ä¹‹é—´æ¾è€¦åˆ
- âœ… æ˜“äºæ·»åŠ æ–°ä»£ç†ï¼ˆåªéœ€è®¢é˜…ï¼‰
- âœ… å¼‚æ­¥å¤„ç†
- âœ… é«˜å¼¹æ€§ï¼ˆæ¶ˆæ¯æŒä¹…åŒ–ï¼‰

**å±€é™æ€§ï¼š**
- âš ï¸ æœ€ç»ˆä¸€è‡´æ€§
- âš ï¸ è°ƒè¯•å¤æ‚
- âš ï¸ æ¶ˆæ¯æ’åºé—®é¢˜

**ç¤ºä¾‹ç”¨ä¾‹ï¼š**
- å®æ—¶ç›‘æ§ç³»ç»Ÿï¼ˆè­¦æŠ¥ã€ä»ªè¡¨ç›˜ã€æ—¥å¿—ï¼‰
- å¤šæ¸ é“é€šçŸ¥ï¼ˆç”µå­é‚®ä»¶ã€çŸ­ä¿¡ã€æ¨é€ã€Slackï¼‰
- æ•°æ®å¤„ç†ç®¡é“ï¼ˆåŒä¸€æ•°æ®çš„å¤šä¸ªæ¶ˆè´¹è€…ï¼‰

---

### æ¨¡å¼ 5ï¼šåŸºäºå…±è¯†çš„åè°ƒï¼ˆæŠ•ç¥¨/æ³•å®šäººæ•°ï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šéœ€è¦å¤šä¸ªä»£ç†è¾¾æˆä¸€è‡´åæ‰èƒ½ç»§ç»­ã€‚

```mermaid
graph TB
    Input[è¾“å…¥ä»»åŠ¡]
    Agent1[ä»£ç† 1: GPT-4]
    Agent2[ä»£ç† 2: Claude]
    Agent3[ä»£ç† 3: Gemini]
    Voter[å…±è¯†æŠ•ç¥¨è€…]
    Output[ä¸€è‡´è¾“å‡º]
    
    Input --> Agent1
    Input --> Agent2
    Input --> Agent3
    Agent1 --> Voter
    Agent2 --> Voter
    Agent3 --> Voter
    Voter --> Output
    
    style Voter fill:#9C27B0,stroke:#7B1FA2,stroke-width:3px,color:#fff
```
**ä¼˜ç‚¹ï¼š**
- âœ… æ›´é«˜çš„å‡†ç¡®æ€§ï¼ˆå¤šæ–¹æ„è§ï¼‰
- âœ… å®¹é”™æ€§å¼ºï¼ˆå°‘æ•°å¤±è´¥å¯æ¥å—ï¼‰
- âœ… å†…ç½®è´¨é‡ä¿è¯

**å±€é™æ€§ï¼š**
- âŒ æˆæœ¬é«˜ï¼ˆå¤šæ¬¡æ¨¡å‹è°ƒç”¨ï¼‰
- âŒ è¾ƒæ…¢ï¼ˆéœ€ç­‰å¾…æ‰€æœ‰ä»£ç†ï¼‰
- âš ï¸ éœ€è¦å†²çªè§£å†³æœºåˆ¶

**ç¤ºä¾‹ç”¨ä¾‹ï¼š**
- å†…å®¹å®¡æ ¸ï¼ˆå¤šä¸ªæ¨¡å‹å®¡æŸ¥å†…å®¹ï¼‰
- ä»£ç å®¡æŸ¥ï¼ˆå¤šä¸ªé™æ€åˆ†æå·¥å…·ï¼‰
- åŒ»å­¦è¯Šæ–­ï¼ˆå¤šä¸ª AI æ¨¡å‹ï¼Œä¸“å®¶éªŒè¯ï¼‰

---

## æ¶æ„æ¦‚è§ˆ

### Azure ä¸Šå®Œæ•´çš„å¤šä»£ç†ç³»ç»Ÿ

```mermaid
graph TB
    User[ç”¨æˆ·/API å®¢æˆ·ç«¯]
    APIM[Azure API ç®¡ç†]
    Orchestrator[åè°ƒæœåŠ¡<br/>å®¹å™¨åº”ç”¨]
    ServiceBus[Azure æœåŠ¡æ€»çº¿<br/>äº‹ä»¶ä¸­å¿ƒ]
    
    Agent1[ç ”ç©¶ä»£ç†<br/>å®¹å™¨åº”ç”¨]
    Agent2[å†™ä½œä»£ç†<br/>å®¹å™¨åº”ç”¨]
    Agent3[åˆ†æä»£ç†<br/>å®¹å™¨åº”ç”¨]
    Agent4[å®¡æŸ¥ä»£ç†<br/>å®¹å™¨åº”ç”¨]
    
    CosmosDB[(Cosmos DB<br/>å…±äº«çŠ¶æ€)]
    Storage[Azure å­˜å‚¨<br/>å·¥ä»¶]
    AppInsights[åº”ç”¨ç¨‹åºæ´å¯Ÿ<br/>ç›‘æ§]
    
    User --> APIM
    APIM --> Orchestrator
    
    Orchestrator --> ServiceBus
    ServiceBus --> Agent1
    ServiceBus --> Agent2
    ServiceBus --> Agent3
    ServiceBus --> Agent4
    
    Agent1 --> CosmosDB
    Agent2 --> CosmosDB
    Agent3 --> CosmosDB
    Agent4 --> CosmosDB
    
    Agent1 --> Storage
    Agent2 --> Storage
    Agent3 --> Storage
    Agent4 --> Storage
    
    Orchestrator -.-> AppInsights
    Agent1 -.-> AppInsights
    Agent2 -.-> AppInsights
    Agent3 -.-> AppInsights
    Agent4 -.-> AppInsights
    
    style Orchestrator fill:#FF9800,stroke:#F57C00,stroke-width:3px,color:#fff
    style ServiceBus fill:#9C27B0,stroke:#7B1FA2,stroke-width:3px,color:#fff
    style CosmosDB fill:#4CAF50,stroke:#388E3C,stroke-width:3px,color:#fff
```
**å…³é”®ç»„ä»¶ï¼š**

| ç»„ä»¶ | ç›®çš„ | Azure æœåŠ¡ |
|------|------|------------|
| **API ç½‘å…³** | å…¥å£ç‚¹ã€é€Ÿç‡é™åˆ¶ã€è®¤è¯ | API Management |
| **ç¼–æ’å™¨** | åè°ƒä»£ç†å·¥ä½œæµ | Container Apps |
| **æ¶ˆæ¯é˜Ÿåˆ—** | å¼‚æ­¥é€šä¿¡ | Service Bus / Event Hubs |
| **ä»£ç†** | ä¸“ä¸šåŒ– AI å·¥ä½œè€… | Container Apps / Functions |
| **çŠ¶æ€å­˜å‚¨** | å…±äº«çŠ¶æ€ã€ä»»åŠ¡è·Ÿè¸ª | Cosmos DB |
| **å·¥ä»¶å­˜å‚¨** | æ–‡æ¡£ã€ç»“æœã€æ—¥å¿— | Blob Storage |
| **ç›‘æ§** | åˆ†å¸ƒå¼è·Ÿè¸ªã€æ—¥å¿— | Application Insights |

---

## å‰ç½®æ¡ä»¶

### æ‰€éœ€å·¥å…·

```bash
# éªŒè¯ Azure å¼€å‘è€… CLI
azd version
# âœ… é¢„æœŸï¼šazd ç‰ˆæœ¬ 1.0.0 æˆ–æ›´é«˜

# éªŒè¯ Azure CLI
az --version
# âœ… é¢„æœŸï¼šazure-cli 2.50.0 æˆ–æ›´é«˜

# éªŒè¯ Dockerï¼ˆç”¨äºæœ¬åœ°æµ‹è¯•ï¼‰
docker --version
# âœ… é¢„æœŸï¼šDocker ç‰ˆæœ¬ 20.10 æˆ–æ›´é«˜
```

### Azure è¦æ±‚

- æ´»è·ƒçš„ Azure è®¢é˜…
- åˆ›å»ºä»¥ä¸‹èµ„æºçš„æƒé™ï¼š
  - Container Apps
  - Service Bus å‘½åç©ºé—´
  - Cosmos DB è´¦æˆ·
  - å­˜å‚¨è´¦æˆ·
  - Application Insights

### çŸ¥è¯†å‰æ

ä½ åº”è¯¥å·²å®Œæˆï¼š
- [é…ç½®ç®¡ç†](../getting-started/configuration.md)
- [è®¤è¯ä¸å®‰å…¨](../getting-started/authsecurity.md)
- [å¾®æœåŠ¡ç¤ºä¾‹](../../../../examples/microservices)

---

## å®ç°æŒ‡å—

### é¡¹ç›®ç»“æ„

```
multi-agent-system/
â”œâ”€â”€ azure.yaml                    # AZD configuration
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ main.bicep               # Main infrastructure
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ servicebus.bicep     # Message queue
â”‚   â”‚   â”œâ”€â”€ cosmos.bicep         # State store
â”‚   â”‚   â”œâ”€â”€ storage.bicep        # Artifact storage
â”‚   â”‚   â””â”€â”€ monitoring.bicep     # Application Insights
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ orchestrator.bicep   # Orchestrator service
â”‚       â””â”€â”€ agent.bicep          # Agent template
â””â”€â”€ src/
    â”œâ”€â”€ orchestrator/            # Orchestration logic
    â”‚   â”œâ”€â”€ app.py
    â”‚   â”œâ”€â”€ workflows.py
    â”‚   â””â”€â”€ Dockerfile
    â”œâ”€â”€ agents/
    â”‚   â”œâ”€â”€ research/            # Research agent
    â”‚   â”œâ”€â”€ writer/              # Writer agent
    â”‚   â”œâ”€â”€ analyst/             # Analyst agent
    â”‚   â””â”€â”€ reviewer/            # Reviewer agent
    â””â”€â”€ shared/
        â”œâ”€â”€ state_manager.py     # Shared state logic
        â””â”€â”€ message_handler.py   # Message handling
```

---

## è¯¾ç¨‹ 1ï¼šé¡ºåºåè°ƒæ¨¡å¼

### å®ç°ï¼šå†…å®¹åˆ›å»ºæµæ°´çº¿

æˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªé¡ºåºæµæ°´çº¿ï¼šç ”ç©¶ â†’ å†™ä½œ â†’ ç¼–è¾‘ â†’ å‘å¸ƒ

### 1. AZD é…ç½®

**æ–‡ä»¶ï¼š`azure.yaml`**

```yaml
name: content-pipeline
metadata:
  template: multi-agent-sequential@1.0.0

services:
  orchestrator:
    project: ./src/orchestrator
    language: python
    host: containerapp
  
  research-agent:
    project: ./src/agents/research
    language: python
    host: containerapp
  
  writer-agent:
    project: ./src/agents/writer
    language: python
    host: containerapp
  
  editor-agent:
    project: ./src/agents/editor
    language: python
    host: containerapp
```

### 2. åŸºç¡€è®¾æ–½ï¼šç”¨äºåè°ƒçš„ Service Bus

**æ–‡ä»¶ï¼š`infra/core/servicebus.bicep`**

```bicep
param name string
param location string
param tags object = {}

resource serviceBusNamespace 'Microsoft.ServiceBus/namespaces@2022-10-01-preview' = {
  name: name
  location: location
  tags: tags
  sku: {
    name: 'Standard'
    tier: 'Standard'
  }
  properties: {
    minimumTlsVersion: '1.2'
  }
}

// Queue for orchestrator â†’ research agent
resource researchQueue 'Microsoft.ServiceBus/namespaces/queues@2022-10-01-preview' = {
  parent: serviceBusNamespace
  name: 'research-tasks'
  properties: {
    maxDeliveryCount: 3
    lockDuration: 'PT5M'
    deadLetteringOnMessageExpiration: true
  }
}

// Queue for research agent â†’ writer agent
resource writerQueue 'Microsoft.ServiceBus/namespaces/queues@2022-10-01-preview' = {
  parent: serviceBusNamespace
  name: 'writer-tasks'
  properties: {
    maxDeliveryCount: 3
    lockDuration: 'PT5M'
  }
}

// Queue for writer agent â†’ editor agent
resource editorQueue 'Microsoft.ServiceBus/namespaces/queues@2022-10-01-preview' = {
  parent: serviceBusNamespace
  name: 'editor-tasks'
  properties: {
    maxDeliveryCount: 3
    lockDuration: 'PT5M'
  }
}

output namespace string = serviceBusNamespace.name
output connectionString string = listKeys('${serviceBusNamespace.id}/AuthorizationRules/RootManageSharedAccessKey', serviceBusNamespace.apiVersion).primaryConnectionString
```

### 3. å…±äº«çŠ¶æ€ç®¡ç†å™¨

**æ–‡ä»¶ï¼š`src/shared/state_manager.py`**

```python
from azure.cosmos import CosmosClient, PartitionKey
from datetime import datetime
import os

class StateManager:
    """Manages shared state across agents using Cosmos DB"""
    
    def __init__(self):
        endpoint = os.environ['COSMOS_ENDPOINT']
        key = os.environ['COSMOS_KEY']
        
        self.client = CosmosClient(endpoint, key)
        self.database = self.client.get_database_client('agent-state')
        self.container = self.database.get_container_client('tasks')
    
    def create_task(self, task_id: str, task_type: str, input_data: dict):
        """Create a new task"""
        task = {
            'id': task_id,
            'type': task_type,
            'status': 'pending',
            'input': input_data,
            'created_at': datetime.utcnow().isoformat(),
            'steps': []
        }
        self.container.create_item(task)
        return task
    
    def update_task_step(self, task_id: str, step_name: str, result: dict):
        """Update task with completed step"""
        task = self.container.read_item(task_id, partition_key=task_id)
        
        task['steps'].append({
            'name': step_name,
            'completed_at': datetime.utcnow().isoformat(),
            'result': result
        })
        
        self.container.replace_item(task_id, task)
        return task
    
    def complete_task(self, task_id: str, final_result: dict):
        """Mark task as complete"""
        task = self.container.read_item(task_id, partition_key=task_id)
        task['status'] = 'completed'
        task['result'] = final_result
        task['completed_at'] = datetime.utcnow().isoformat()
        self.container.replace_item(task_id, task)
        return task
    
    def get_task(self, task_id: str):
        """Retrieve task state"""
        return self.container.read_item(task_id, partition_key=task_id)
```

### 4. ç¼–æ’æœåŠ¡

**æ–‡ä»¶ï¼š`src/orchestrator/app.py`**

```python
from flask import Flask, request, jsonify
from azure.servicebus import ServiceBusClient, ServiceBusMessage
import json
import uuid
import os
from shared.state_manager import StateManager

app = Flask(__name__)
state_manager = StateManager()

# æœåŠ¡æ€»çº¿è¿æ¥
servicebus_connection_str = os.environ['SERVICEBUS_CONNECTION_STRING']
servicebus_client = ServiceBusClient.from_connection_string(servicebus_connection_str)

@app.route('/health', methods=['GET'])
def health():
    return jsonify({'status': 'healthy', 'service': 'orchestrator'})

@app.route('/create-content', methods=['POST'])
def create_content():
    """
    Sequential workflow: Research â†’ Write â†’ Edit â†’ Publish
    """
    data = request.json
    topic = data.get('topic')
    
    if not topic:
        return jsonify({'error': 'Topic required'}), 400
    
    # åœ¨çŠ¶æ€å­˜å‚¨ä¸­åˆ›å»ºä»»åŠ¡
    task_id = str(uuid.uuid4())
    task = state_manager.create_task(
        task_id=task_id,
        task_type='content_creation',
        input_data={'topic': topic}
    )
    
    # å‘é€æ¶ˆæ¯ç»™ç ”ç©¶ä»£ç†ï¼ˆç¬¬ä¸€æ­¥ï¼‰
    sender = servicebus_client.get_queue_sender('research-tasks')
    message = ServiceBusMessage(
        body=json.dumps({
            'task_id': task_id,
            'topic': topic,
            'next_queue': 'writer-tasks'  # å‘é€ç»“æœçš„åœ°æ–¹
        }),
        content_type='application/json'
    )
    
    with sender:
        sender.send_messages(message)
    
    return jsonify({
        'task_id': task_id,
        'status': 'started',
        'workflow': 'sequential',
        'steps': ['research', 'write', 'edit', 'publish'],
        'message': 'Content creation pipeline initiated'
    }), 202

@app.route('/task/<task_id>', methods=['GET'])
def get_task_status(task_id):
    """Check task status"""
    try:
        task = state_manager.get_task(task_id)
        return jsonify(task)
    except Exception as e:
        return jsonify({'error': str(e)}), 404

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
```

### 5. ç ”ç©¶ä»£ç†

**æ–‡ä»¶ï¼š`src/agents/research/app.py`**

```python
from azure.servicebus import ServiceBusClient, ServiceBusMessage
from openai import AzureOpenAI
import json
import os
import time
from shared.state_manager import StateManager

# åˆå§‹åŒ–å®¢æˆ·ç«¯
state_manager = StateManager()
servicebus_client = ServiceBusClient.from_connection_string(
    os.environ['SERVICEBUS_CONNECTION_STRING']
)

openai_client = AzureOpenAI(
    api_key=os.environ['AZURE_OPENAI_API_KEY'],
    api_version="2024-02-01",
    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT']
)

def process_research_task(message_data):
    """Process research request and pass to writer"""
    task_id = message_data['task_id']
    topic = message_data['topic']
    next_queue = message_data['next_queue']
    
    print(f"ğŸ”¬ Researching: {topic}")
    
    # è°ƒç”¨ Azure OpenAI è¿›è¡Œç ”ç©¶
    response = openai_client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are a research assistant. Provide comprehensive research on the given topic."},
            {"role": "user", "content": f"Research this topic thoroughly: {topic}"}
        ],
        max_tokens=1500
    )
    
    research_results = response.choices[0].message.content
    
    # æ›´æ–°çŠ¶æ€
    state_manager.update_task_step(
        task_id=task_id,
        step_name='research',
        result={'research': research_results}
    )
    
    # å‘é€åˆ°ä¸‹ä¸€ä¸ªä»£ç†ï¼ˆå†™å…¥è€…ï¼‰
    sender = servicebus_client.get_queue_sender(next_queue)
    message = ServiceBusMessage(
        body=json.dumps({
            'task_id': task_id,
            'topic': topic,
            'research': research_results,
            'next_queue': 'editor-tasks'
        }),
        content_type='application/json'
    )
    
    with sender:
        sender.send_messages(message)
    
    print(f"âœ… Research complete for task {task_id}")

def main():
    """Listen to research queue"""
    receiver = servicebus_client.get_queue_receiver('research-tasks')
    
    print("ğŸ”¬ Research Agent started, listening for tasks...")
    
    with receiver:
        while True:
            messages = receiver.receive_messages(max_wait_time=5)
            for message in messages:
                try:
                    message_data = json.loads(str(message))
                    process_research_task(message_data)
                    receiver.complete_message(message)
                except Exception as e:
                    print(f"âŒ Error processing message: {e}")
                    receiver.abandon_message(message)

if __name__ == '__main__':
    main()
```

### 6. å†™ä½œä»£ç†

**æ–‡ä»¶ï¼š`src/agents/writer/app.py`**

```python
from azure.servicebus import ServiceBusClient, ServiceBusMessage
from openai import AzureOpenAI
import json
import os
from shared.state_manager import StateManager

state_manager = StateManager()
servicebus_client = ServiceBusClient.from_connection_string(
    os.environ['SERVICEBUS_CONNECTION_STRING']
)

openai_client = AzureOpenAI(
    api_key=os.environ['AZURE_OPENAI_API_KEY'],
    api_version="2024-02-01",
    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT']
)

def process_writing_task(message_data):
    """Write article based on research"""
    task_id = message_data['task_id']
    topic = message_data['topic']
    research = message_data['research']
    next_queue = message_data['next_queue']
    
    print(f"âœï¸ Writing article: {topic}")
    
    # è°ƒç”¨ Azure OpenAI æ’°å†™æ–‡ç« 
    response = openai_client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are a professional writer. Write engaging, well-structured articles."},
            {"role": "user", "content": f"Based on this research:\n\n{research}\n\nWrite a comprehensive article about: {topic}"}
        ],
        max_tokens=2000
    )
    
    article_draft = response.choices[0].message.content
    
    # æ›´æ–°çŠ¶æ€
    state_manager.update_task_step(
        task_id=task_id,
        step_name='writing',
        result={'draft': article_draft}
    )
    
    # å‘é€ç»™ç¼–è¾‘
    sender = servicebus_client.get_queue_sender(next_queue)
    message = ServiceBusMessage(
        body=json.dumps({
            'task_id': task_id,
            'topic': topic,
            'draft': article_draft
        }),
        content_type='application/json'
    )
    
    with sender:
        sender.send_messages(message)
    
    print(f"âœ… Article draft complete for task {task_id}")

def main():
    """Listen to writer queue"""
    receiver = servicebus_client.get_queue_receiver('writer-tasks')
    
    print("âœï¸ Writer Agent started, listening for tasks...")
    
    with receiver:
        while True:
            messages = receiver.receive_messages(max_wait_time=5)
            for message in messages:
                try:
                    message_data = json.loads(str(message))
                    process_writing_task(message_data)
                    receiver.complete_message(message)
                except Exception as e:
                    print(f"âŒ Error: {e}")
                    receiver.abandon_message(message)

if __name__ == '__main__':
    main()
```

### 7. ç¼–è¾‘ä»£ç†

**æ–‡ä»¶ï¼š`src/agents/editor/app.py`**

```python
from azure.servicebus import ServiceBusClient
from openai import AzureOpenAI
import json
import os
from shared.state_manager import StateManager

state_manager = StateManager()
servicebus_client = ServiceBusClient.from_connection_string(
    os.environ['SERVICEBUS_CONNECTION_STRING']
)

openai_client = AzureOpenAI(
    api_key=os.environ['AZURE_OPENAI_API_KEY'],
    api_version="2024-02-01",
    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT']
)

def process_editing_task(message_data):
    """Edit and finalize article"""
    task_id = message_data['task_id']
    topic = message_data['topic']
    draft = message_data['draft']
    
    print(f"ğŸ“ Editing article: {topic}")
    
    # è°ƒç”¨ Azure OpenAI è¿›è¡Œç¼–è¾‘
    response = openai_client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are an expert editor. Improve grammar, clarity, and structure."},
            {"role": "user", "content": f"Edit and improve this article:\n\n{draft}"}
        ],
        max_tokens=2000
    )
    
    final_article = response.choices[0].message.content
    
    # æ ‡è®°ä»»åŠ¡ä¸ºå®Œæˆ
    state_manager.complete_task(
        task_id=task_id,
        final_result={
            'topic': topic,
            'final_article': final_article,
            'word_count': len(final_article.split())
        }
    )
    
    print(f"âœ… Article finalized for task {task_id}")

def main():
    """Listen to editor queue"""
    receiver = servicebus_client.get_queue_receiver('editor-tasks')
    
    print("ğŸ“ Editor Agent started, listening for tasks...")
    
    with receiver:
        while True:
            messages = receiver.receive_messages(max_wait_time=5)
            for message in messages:
                try:
                    message_data = json.loads(str(message))
                    process_editing_task(message_data)
                    receiver.complete_message(message)
                except Exception as e:
                    print(f"âŒ Error: {e}")
                    receiver.abandon_message(message)

if __name__ == '__main__':
    main()
```

### 8. éƒ¨ç½²å’Œæµ‹è¯•

```bash
# åˆå§‹åŒ–å¹¶éƒ¨ç½²
azd init
azd up

# è·å–ç¼–æ’å™¨URL
ORCHESTRATOR_URL=$(azd env get-values | grep ORCHESTRATOR_URL | cut -d '=' -f2 | tr -d '"')

# åˆ›å»ºå†…å®¹
curl -X POST $ORCHESTRATOR_URL/create-content \
  -H "Content-Type: application/json" \
  -d '{"topic": "The Future of AI in Healthcare"}'
```

**âœ… é¢„æœŸè¾“å‡ºï¼š**
```json
{
  "task_id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "status": "started",
  "workflow": "sequential",
  "steps": ["research", "write", "edit", "publish"],
  "message": "Content creation pipeline initiated"
}
```

**æ£€æŸ¥ä»»åŠ¡è¿›åº¦ï¼š**
```bash
TASK_ID="a1b2c3d4-e5f6-7890-abcd-ef1234567890"
curl $ORCHESTRATOR_URL/task/$TASK_ID
```

**âœ… é¢„æœŸè¾“å‡ºï¼ˆå®Œæˆï¼‰ï¼š**
```json
{
  "id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "type": "content_creation",
  "status": "completed",
  "steps": [
    {
      "name": "research",
      "completed_at": "2025-11-19T10:30:00Z",
      "result": {"research": "..."}
    },
    {
      "name": "writing",
      "completed_at": "2025-11-19T10:32:00Z",
      "result": {"draft": "..."}
    }
  ],
  "result": {
    "topic": "The Future of AI in Healthcare",
    "final_article": "...",
    "word_count": 1500
  }
}
```

---

## è¯¾ç¨‹ 2ï¼šå¹¶è¡Œåè°ƒæ¨¡å¼

### å®ç°ï¼šå¤šæºç ”ç©¶èšåˆå™¨

æˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªå¹¶è¡Œç³»ç»Ÿï¼ŒåŒæ—¶ä»å¤šä¸ªæ¥æºæ”¶é›†ä¿¡æ¯ã€‚

### å¹¶è¡Œç¼–æ’å™¨

**æ–‡ä»¶ï¼š`src/orchestrator/parallel_workflow.py`**

```python
from flask import Flask, request, jsonify
from azure.servicebus import ServiceBusClient, ServiceBusMessage
import json
import uuid
import os
from shared.state_manager import StateManager

app = Flask(__name__)
state_manager = StateManager()

servicebus_client = ServiceBusClient.from_connection_string(
    os.environ['SERVICEBUS_CONNECTION_STRING']
)

@app.route('/research-parallel', methods=['POST'])
def research_parallel():
    """
    Parallel workflow: Multiple agents work simultaneously
    """
    data = request.json
    query = data.get('query')
    
    task_id = str(uuid.uuid4())
    task = state_manager.create_task(
        task_id=task_id,
        task_type='parallel_research',
        input_data={
            'query': query,
            'agents': ['web', 'academic', 'news', 'social']
        }
    )
    
    # æ‰‡å‡ºï¼šåŒæ—¶å‘é€ç»™æ‰€æœ‰ä»£ç†
    agents = [
        ('web-research-queue', 'web'),
        ('academic-research-queue', 'academic'),
        ('news-research-queue', 'news'),
        ('social-research-queue', 'social')
    ]
    
    for queue_name, agent_type in agents:
        sender = servicebus_client.get_queue_sender(queue_name)
        message = ServiceBusMessage(
            body=json.dumps({
                'task_id': task_id,
                'query': query,
                'agent_type': agent_type,
                'result_queue': 'aggregation-queue'
            }),
            content_type='application/json'
        )
        
        with sender:
            sender.send_messages(message)
    
    return jsonify({
        'task_id': task_id,
        'status': 'started',
        'workflow': 'parallel',
        'agents_dispatched': 4,
        'message': 'Parallel research initiated'
    }), 202

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
```

### èšåˆé€»è¾‘

**æ–‡ä»¶ï¼š`src/agents/aggregator/app.py`**

```python
from azure.servicebus import ServiceBusClient
import json
import os
from collections import defaultdict
from shared.state_manager import StateManager

state_manager = StateManager()
servicebus_client = ServiceBusClient.from_connection_string(
    os.environ['SERVICEBUS_CONNECTION_STRING']
)

# è·Ÿè¸ªæ¯ä¸ªä»»åŠ¡çš„ç»“æœ
task_results = defaultdict(list)
expected_agents = 4  # ç½‘ç»œã€å­¦æœ¯ã€æ–°é—»ã€ç¤¾äº¤

def process_result(message_data):
    """Aggregate results from parallel agents"""
    task_id = message_data['task_id']
    agent_type = message_data['agent_type']
    result = message_data['result']
    
    # å­˜å‚¨ç»“æœ
    task_results[task_id].append({
        'agent': agent_type,
        'data': result
    })
    
    print(f"ğŸ“Š Received result from {agent_type} agent ({len(task_results[task_id])}/{expected_agents})")
    
    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä»£ç†å·²å®Œæˆï¼ˆæ±‡èšï¼‰
    if len(task_results[task_id]) == expected_agents:
        print(f"âœ… All agents completed for task {task_id}. Aggregating...")
        
        # åˆå¹¶ç»“æœ
        aggregated = {
            'query': message_data['query'],
            'sources': task_results[task_id],
            'summary': generate_summary(task_results[task_id])
        }
        
        # æ ‡è®°å®Œæˆ
        state_manager.complete_task(task_id, aggregated)
        
        # æ¸…ç†
        del task_results[task_id]
        
        print(f"âœ… Aggregation complete for task {task_id}")

def generate_summary(results):
    """Generate summary from all sources"""
    summaries = [r['data'].get('summary', '') for r in results]
    return '\n\n'.join(summaries)

def main():
    """Listen to aggregation queue"""
    receiver = servicebus_client.get_queue_receiver('aggregation-queue')
    
    print("ğŸ“Š Aggregator started, listening for results...")
    
    with receiver:
        while True:
            messages = receiver.receive_messages(max_wait_time=5)
            for message in messages:
                try:
                    message_data = json.loads(str(message))
                    process_result(message_data)
                    receiver.complete_message(message)
                except Exception as e:
                    print(f"âŒ Error: {e}")
                    receiver.abandon_message(message)

if __name__ == '__main__':
    main()
```

**å¹¶è¡Œæ¨¡å¼çš„ä¼˜ç‚¹ï¼š**
- âš¡ **é€Ÿåº¦æå‡ 4 å€**ï¼ˆä»£ç†åŒæ—¶è¿è¡Œï¼‰
- ğŸ”„ **å®¹é”™æ€§å¼º**ï¼ˆå¯æ¥å—éƒ¨åˆ†ç»“æœï¼‰
- ğŸ“ˆ **å¯æ‰©å±•æ€§å¼º**ï¼ˆè½»æ¾æ·»åŠ æ›´å¤šä»£ç†ï¼‰

---

## å®è·µç»ƒä¹ 

### ç»ƒä¹  1ï¼šæ·»åŠ è¶…æ—¶å¤„ç† â­â­ï¼ˆä¸­ç­‰ï¼‰

**ç›®æ ‡**ï¼šå®ç°è¶…æ—¶é€»è¾‘ï¼Œç¡®ä¿èšåˆå™¨ä¸ä¼šæ— é™ç­‰å¾…æ…¢é€Ÿä»£ç†ã€‚

**æ­¥éª¤**ï¼š

1. **åœ¨èšåˆå™¨ä¸­æ·»åŠ è¶…æ—¶è·Ÿè¸ªï¼š**

```python
from datetime import datetime, timedelta

task_timeouts = {}  # ä»»åŠ¡ID -> åˆ°æœŸæ—¶é—´

def process_result(message_data):
    task_id = message_data['task_id']
    
    # è®¾ç½®ç¬¬ä¸€ä¸ªç»“æœçš„è¶…æ—¶æ—¶é—´
    if task_id not in task_timeouts:
        task_timeouts[task_id] = datetime.utcnow() + timedelta(seconds=30)
    
    task_results[task_id].append({
        'agent': message_data['agent_type'],
        'data': message_data['result']
    })
    
    # æ£€æŸ¥æ˜¯å¦å®Œæˆæˆ–è¶…æ—¶
    if len(task_results[task_id]) == expected_agents or \
       datetime.utcnow() > task_timeouts[task_id]:
        
        print(f"ğŸ“Š Aggregating with {len(task_results[task_id])}/{expected_agents} results")
        
        aggregated = {
            'query': message_data['query'],
            'sources': task_results[task_id],
            'completed_agents': len(task_results[task_id]),
            'timed_out': len(task_results[task_id]) < expected_agents
        }
        
        state_manager.complete_task(task_id, aggregated)
        
        # æ¸…ç†
        del task_results[task_id]
        del task_timeouts[task_id]
```

2. **ä½¿ç”¨äººå·¥å»¶è¿Ÿè¿›è¡Œæµ‹è¯•ï¼š**

```python
# åœ¨ä¸€ä¸ªä»£ç†ä¸­æ·»åŠ å»¶è¿Ÿä»¥æ¨¡æ‹Ÿç¼“æ…¢å¤„ç†
import time
time.sleep(35)  # è¶…è¿‡30ç§’è¶…æ—¶
```

3. **éƒ¨ç½²å¹¶éªŒè¯ï¼š**

```bash
azd deploy aggregator

# æäº¤ä»»åŠ¡
curl -X POST $ORCHESTRATOR_URL/research-parallel \
  -H "Content-Type: application/json" \
  -d '{"query": "AI safety research"}'

# 30ç§’åæ£€æŸ¥ç»“æœ
curl $ORCHESTRATOR_URL/task/$TASK_ID
```

**âœ… æˆåŠŸæ ‡å‡†ï¼š**
- âœ… å³ä½¿ä»£ç†æœªå®Œæˆï¼Œä»»åŠ¡ä¹Ÿåœ¨ 30 ç§’åå®Œæˆ
- âœ… å“åº”æŒ‡ç¤ºéƒ¨åˆ†ç»“æœï¼ˆ`"timed_out": true`ï¼‰
- âœ… è¿”å›å¯ç”¨ç»“æœï¼ˆ4 ä¸ªä»£ç†ä¸­ 3 ä¸ªå®Œæˆï¼‰

**æ—¶é—´**ï¼š20-25 åˆ†é’Ÿ

---

### ç»ƒä¹  2ï¼šå®ç°é‡è¯•é€»è¾‘ â­â­â­ï¼ˆé«˜çº§ï¼‰

**ç›®æ ‡**ï¼šåœ¨æ”¾å¼ƒä¹‹å‰è‡ªåŠ¨é‡è¯•å¤±è´¥çš„ä»£ç†ä»»åŠ¡ã€‚

**æ­¥éª¤**ï¼š

1. **åœ¨ç¼–æ’å™¨ä¸­æ·»åŠ é‡è¯•è·Ÿè¸ªï¼š**

```python
from dataclasses import dataclass
from typing import Dict

@dataclass
class RetryConfig:
    max_retries: int = 3
    backoff_seconds: int = 5

retry_counts: Dict[str, int] = {}  # æ¶ˆæ¯ID -> é‡è¯•è®¡æ•°

def send_with_retry(queue_name: str, message_data: dict, retry_config: RetryConfig):
    """Send message with retry metadata"""
    message_id = message_data.get('message_id', str(uuid.uuid4()))
    message_data['message_id'] = message_id
    message_data['retry_count'] = retry_counts.get(message_id, 0)
    message_data['max_retries'] = retry_config.max_retries
    
    sender = servicebus_client.get_queue_sender(queue_name)
    message = ServiceBusMessage(
        body=json.dumps(message_data),
        content_type='application/json',
        message_id=message_id
    )
    
    with sender:
        sender.send_messages(message)
```

2. **åœ¨ä»£ç†ä¸­æ·»åŠ é‡è¯•å¤„ç†ç¨‹åºï¼š**

```python
def process_with_retry(message, receiver, process_func):
    """Process message with automatic retry on failure"""
    try:
        message_data = json.loads(str(message))
        
        # å¤„ç†æ¶ˆæ¯
        process_func(message_data)
        
        # æˆåŠŸ - å®Œæˆ
        receiver.complete_message(message)
        
    except Exception as e:
        message_id = message.message_id
        retry_count = message_data.get('retry_count', 0)
        max_retries = message_data.get('max_retries', 3)
        
        if retry_count < max_retries:
            # é‡è¯•ï¼šæ”¾å¼ƒå¹¶é‡æ–°æ’é˜Ÿï¼Œè®¡æ•°åŠ ä¸€
            print(f"âš ï¸ Retry {retry_count + 1}/{max_retries} for message {message_id}")
            
            message_data['retry_count'] = retry_count + 1
            
            # å‘é€å›åŒä¸€é˜Ÿåˆ—å¹¶å»¶è¿Ÿ
            time.sleep(5 * (retry_count + 1))  # æŒ‡æ•°é€€é¿
            send_with_retry(queue_name, message_data, RetryConfig())
            
            receiver.complete_message(message)  # ç§»é™¤åŸå§‹å†…å®¹
        else:
            # è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•° - ç§»è‡³æ­»ä¿¡é˜Ÿåˆ—
            print(f"âŒ Max retries exceeded for message {message_id}")
            receiver.dead_letter_message(
                message,
                reason="MaxRetriesExceeded",
                error_description=str(e)
            )
```

3. **ç›‘æ§æ­»ä¿¡é˜Ÿåˆ—ï¼š**

```python
def monitor_dead_letters():
    """Check dead letter queue for failed messages"""
    receiver = servicebus_client.get_queue_receiver(
        'research-queue',
        sub_queue='deadletter'
    )
    
    with receiver:
        messages = receiver.receive_messages(max_wait_time=5)
        for message in messages:
            print(f"â˜ ï¸ Dead letter: {message.message_id}")
            print(f"Reason: {message.dead_letter_reason}")
            print(f"Description: {message.dead_letter_error_description}")
```

**âœ… æˆåŠŸæ ‡å‡†ï¼š**
- âœ… å¤±è´¥ä»»åŠ¡è‡ªåŠ¨é‡è¯•ï¼ˆæœ€å¤š 3 æ¬¡ï¼‰
- âœ… é‡è¯•é—´éš”æŒ‡æ•°é€’å¢ï¼ˆ5 ç§’ã€10 ç§’ã€15 ç§’ï¼‰
- âœ… è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°åï¼Œæ¶ˆæ¯è¿›å…¥æ­»ä¿¡é˜Ÿåˆ—
- âœ… å¯ç›‘æ§å¹¶é‡æ”¾æ­»ä¿¡é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯

**æ—¶é—´**ï¼š30-40 åˆ†é’Ÿ

---

### ç»ƒä¹  3ï¼šå®ç°æ–­è·¯å™¨ â­â­â­ï¼ˆé«˜çº§ï¼‰

**ç›®æ ‡**ï¼šé€šè¿‡åœæ­¢å‘å¤±è´¥çš„ä»£ç†å‘é€è¯·æ±‚ï¼Œé˜²æ­¢çº§è”æ•…éšœã€‚

**æ­¥éª¤**ï¼š

1. **åˆ›å»ºæ–­è·¯å™¨ç±»ï¼š**

```python
from enum import Enum
from datetime import datetime, timedelta

class CircuitState(Enum):
    CLOSED = "closed"      # æ­£å¸¸è¿è¡Œ
    OPEN = "open"          # å¤±è´¥ï¼Œæ‹’ç»è¯·æ±‚
    HALF_OPEN = "half_open"  # æµ‹è¯•æ˜¯å¦å·²æ¢å¤

class CircuitBreaker:
    def __init__(self, failure_threshold=5, timeout_seconds=60):
        self.failure_threshold = failure_threshold
        self.timeout_seconds = timeout_seconds
        self.failure_count = 0
        self.last_failure_time = None
        self.state = CircuitState.CLOSED
    
    def call(self, func):
        """Execute function with circuit breaker protection"""
        if self.state == CircuitState.OPEN:
            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            if datetime.utcnow() - self.last_failure_time > timedelta(seconds=self.timeout_seconds):
                self.state = CircuitState.HALF_OPEN
                print("ğŸ”„ Circuit breaker: HALF_OPEN (testing)")
            else:
                raise Exception(f"Circuit breaker OPEN for agent. Try again in {self.timeout_seconds}s")
        
        try:
            result = func()
            
            # æˆåŠŸ
            if self.state == CircuitState.HALF_OPEN:
                self.state = CircuitState.CLOSED
                self.failure_count = 0
                print("âœ… Circuit breaker: CLOSED (recovered)")
            
            return result
            
        except Exception as e:
            self.failure_count += 1
            self.last_failure_time = datetime.utcnow()
            
            if self.failure_count >= self.failure_threshold:
                self.state = CircuitState.OPEN
                print(f"ğŸ”´ Circuit breaker: OPEN (too many failures)")
            
            raise e
```

2. **åº”ç”¨äºä»£ç†è°ƒç”¨ï¼š**

```python
# åœ¨åè°ƒå™¨ä¸­
agent_circuits = {
    'web': CircuitBreaker(failure_threshold=5, timeout_seconds=60),
    'academic': CircuitBreaker(failure_threshold=5, timeout_seconds=60),
    'news': CircuitBreaker(failure_threshold=5, timeout_seconds=60),
    'social': CircuitBreaker(failure_threshold=5, timeout_seconds=60)
}

def send_to_agent(agent_type, message_data):
    """Send with circuit breaker protection"""
    circuit = agent_circuits[agent_type]
    
    try:
        circuit.call(lambda: send_message(agent_type, message_data))
    except Exception as e:
        print(f"âš ï¸ Skipping {agent_type} agent: {e}")
        # ç»§ç»­ä¸å…¶ä»–ä»£ç†
```

3. **æµ‹è¯•æ–­è·¯å™¨ï¼š**

```bash
# æ¨¡æ‹Ÿé‡å¤å¤±è´¥ï¼ˆåœæ­¢ä¸€ä¸ªä»£ç†ï¼‰
az containerapp stop --name web-research-agent --resource-group rg-agents

# å‘é€å¤šä¸ªè¯·æ±‚
for i in {1..10}; do
  curl -X POST $ORCHESTRATOR_URL/research-parallel \
    -H "Content-Type: application/json" \
    -d '{"query": "test query '$i'"}'
  sleep 2
done

# æ£€æŸ¥æ—¥å¿— - åº”è¯¥åœ¨5æ¬¡å¤±è´¥åçœ‹åˆ°æ–­è·¯æ‰“å¼€
azd logs orchestrator --tail 50
```

**âœ… æˆåŠŸæ ‡å‡†ï¼š**
- âœ… å‘ç”Ÿ 5 æ¬¡å¤±è´¥åï¼Œæ–­è·¯å™¨æ‰“å¼€ï¼ˆæ‹’ç»è¯·æ±‚ï¼‰
- âœ… 60 ç§’åï¼Œæ–­è·¯å™¨è¿›å…¥åŠå¼€çŠ¶æ€ï¼ˆæµ‹è¯•æ¢å¤æƒ…å†µï¼‰
- âœ… å…¶ä»–ä»£ç†æ­£å¸¸å·¥ä½œ
- âœ… ä»£ç†æ¢å¤åï¼Œæ–­è·¯å™¨è‡ªåŠ¨å…³é—­

**æ—¶é—´**ï¼š40-50 åˆ†é’Ÿ

---

## ç›‘æ§å’Œè°ƒè¯•

### ä½¿ç”¨ Application Insights è¿›è¡Œåˆ†å¸ƒå¼è·Ÿè¸ª

**æ–‡ä»¶ï¼š`src/shared/tracing.py`**

```python
from opencensus.ext.azure.log_exporter import AzureLogHandler
from opencensus.ext.azure.trace_exporter import AzureExporter
from opencensus.trace import config_integration
from opencensus.trace.tracer import Tracer
from opencensus.trace.samplers import AlwaysOnSampler
import logging
import os

# é…ç½®è¿½è¸ª
config_integration.trace_integrations(['requests', 'logging'])

connection_string = os.environ.get('APPLICATIONINSIGHTS_CONNECTION_STRING')

# åˆ›å»ºè¿½è¸ªå™¨
tracer = Tracer(
    exporter=AzureExporter(connection_string=connection_string),
    sampler=AlwaysOnSampler()
)

# é…ç½®æ—¥å¿—è®°å½•
logger = logging.getLogger(__name__)
logger.addHandler(AzureLogHandler(connection_string=connection_string))
logger.setLevel(logging.INFO)

def trace_agent_call(agent_name, task_id, operation):
    """Trace agent operations"""
    with tracer.span(name=f'{agent_name}.{operation}') as span:
        span.add_attribute('agent', agent_name)
        span.add_attribute('task_id', task_id)
        span.add_attribute('operation', operation)
        
        try:
            result = operation()
            span.add_attribute('status', 'success')
            return result
        except Exception as e:
            span.add_attribute('status', 'error')
            span.add_attribute('error', str(e))
            raise
```

### Application Insights æŸ¥è¯¢

**è·Ÿè¸ªå¤šä»£ç†å·¥ä½œæµï¼š**

```kusto
// Trace complete workflow for a task
traces
| where customDimensions.task_id == "a1b2c3d4-..."
| project timestamp, message, customDimensions.agent, customDimensions.operation
| order by timestamp asc
```

**ä»£ç†æ€§èƒ½æ¯”è¾ƒï¼š**

```kusto
// Compare agent execution times
dependencies
| where name contains "agent"
| summarize 
    avg_duration = avg(duration),
    p95_duration = percentile(duration, 95),
    count = count()
  by agent = tostring(customDimensions.agent)
| order by avg_duration desc
```

**æ•…éšœåˆ†æï¼š**

```kusto
// Find which agents fail most
exceptions
| where customDimensions.agent != ""
| summarize 
    failure_count = count(),
    unique_errors = dcount(outerMessage)
  by agent = tostring(customDimensions.agent)
| order by failure_count desc
```

---

## æˆæœ¬åˆ†æ

### å¤šä»£ç†ç³»ç»Ÿæˆæœ¬ï¼ˆæ¯æœˆä¼°ç®—ï¼‰

| ç»„ä»¶ | é…ç½® | æˆæœ¬ |
|------|------|------|
| **ç¼–æ’å™¨** | 1 ä¸ª Container Appï¼ˆ1 vCPUï¼Œ2GBï¼‰ | $30-50 |
| **4 ä¸ªä»£ç†** | 4 ä¸ª Container Appsï¼ˆæ¯ä¸ª 0.5 vCPUï¼Œ1GBï¼‰ | $60-120 |
| **Service Bus** | æ ‡å‡†å±‚ï¼Œ1000 ä¸‡æ¡æ¶ˆæ¯ | $10-20 |
| **Cosmos DB** | æ— æœåŠ¡å™¨ï¼Œ5GB å­˜å‚¨ï¼Œ100 ä¸‡ RUs | $25-50 |
| **Blob å­˜å‚¨** | 10GB å­˜å‚¨ï¼Œ10 ä¸‡æ¬¡æ“ä½œ | $5-10 |
| **Application Insights** | 5GB æ•°æ®æ‘„å– | $10-15 |
| **Azure OpenAI** | GPT-4ï¼Œ1000 ä¸‡ tokens | $100-300 |
| **æ€»è®¡** | | **$240-565/æœˆ** |

### æˆæœ¬ä¼˜åŒ–ç­–ç•¥

1. **å°½å¯èƒ½ä½¿ç”¨æ— æœåŠ¡å™¨ï¼š**
   ```bicep
   // Cosmos DB serverless (no minimum cost)
   properties: {
     databaseAccountOfferType: 'Standard'
     capabilities: [{ name: 'EnableServerless' }]
   }
   ```

2. **åœ¨ç©ºé—²æ—¶å°†ä»£ç†ç¼©å‡ä¸ºé›¶ï¼š**
   ```bicep
   scale: {
     minReplicas: 0  // Scale to zero when no messages
     maxReplicas: 10
   }
   ```

3. **ä¸º Service Bus ä½¿ç”¨æ‰¹å¤„ç†ï¼š**
   ```python
   # æ‰¹é‡å‘é€æ¶ˆæ¯ï¼ˆæ›´ä¾¿å®œï¼‰
   sender.send_messages([message1, message2, message3])
   ```

4. **ç¼“å­˜å¸¸ç”¨ç»“æœï¼š**
   ```python
   # ä½¿ç”¨ Azure Cache for Redis
   if cache.exists(query_hash):
       return cache.get(query_hash)
   ```

---

## æœ€ä½³å®è·µ

### âœ… åº”è¯¥åšï¼š

1. **ä½¿ç”¨å¹‚ç­‰æ“ä½œ**
   ```python
   # ä»£ç†å¯ä»¥å®‰å…¨åœ°å¤šæ¬¡å¤„ç†ç›¸åŒçš„æ¶ˆæ¯
   def process_task(task_id):
       if state_manager.task_exists(task_id):
           print(f"Task {task_id} already processed, skipping")
           return
       # å¤„ç†ä»»åŠ¡...
   ```

2. **å®ç°å…¨é¢çš„æ—¥å¿—è®°å½•**
   ```python
   logger.info(f"Agent: {agent_name}, Task: {task_id}, Action: {action}")
   ```

3. **ä½¿ç”¨å…³è” ID**
   ```python
   # åœ¨æ•´ä¸ªå·¥ä½œæµç¨‹ä¸­ä¼ é€’ task_id
   message_data = {
       'task_id': task_id,  # å…³è” ID
       'timestamp': datetime.utcnow().isoformat()
   }
   ```

4. **è®¾ç½®æ¶ˆæ¯ TTLï¼ˆç”Ÿå­˜æ—¶é—´ï¼‰**
   ```bicep
   properties: {
     defaultMessageTimeToLive: 'PT1H'  // 1 hour max
   }
   ```

5. **ç›‘æ§æ­»ä¿¡é˜Ÿåˆ—**
   ```python
   # å®šæœŸç›‘æ§å¤±è´¥çš„æ¶ˆæ¯
   monitor_dead_letters()
   ```

### âŒ ä¸åº”è¯¥åšï¼š

1. **ä¸è¦åˆ›å»ºå¾ªç¯ä¾èµ–**
   ```python
   # âŒ é”™è¯¯: ä»£ç† A â†’ ä»£ç† B â†’ ä»£ç† Aï¼ˆæ— é™å¾ªç¯ï¼‰
   # âœ… å¥½: å®šä¹‰æ¸…æ™°çš„æœ‰å‘æ— ç¯å›¾ (DAG)
   ```

2. **ä¸è¦é˜»å¡ä»£ç†çº¿ç¨‹**
   ```python
   # âŒ ä¸å¥½ï¼šåŒæ­¥ç­‰å¾…
   while not task_complete:
       time.sleep(1)
   
   # âœ… å¥½ï¼šä½¿ç”¨æ¶ˆæ¯é˜Ÿåˆ—å›è°ƒ
   ```

3. **ä¸è¦å¿½ç•¥éƒ¨åˆ†å¤±è´¥**
   ```python
   # âŒ é”™è¯¯ï¼šå¦‚æœä¸€ä¸ªä»£ç†å¤±è´¥ï¼Œåˆ™æ•´ä¸ªå·¥ä½œæµç¨‹å¤±è´¥
   # âœ… å¥½ï¼šè¿”å›å¸¦æœ‰é”™è¯¯æŒ‡ç¤ºçš„éƒ¨åˆ†ç»“æœ
   ```

4. **ä¸è¦ä½¿ç”¨æ— é™é‡è¯•**
   ```python
   # âŒ é”™è¯¯ï¼šæ— é™é‡è¯•
   # âœ… å¥½ï¼šæœ€å¤§é‡è¯•æ¬¡æ•° = 3ï¼Œç„¶åå‘é€åˆ°æ­»ä¿¡é˜Ÿåˆ—
   ```

---
## æ•…éšœæ’æŸ¥æŒ‡å—

### é—®é¢˜ï¼šæ¶ˆæ¯å¡åœ¨é˜Ÿåˆ—ä¸­

**ç—‡çŠ¶ï¼š**
- æ¶ˆæ¯åœ¨é˜Ÿåˆ—ä¸­ç§¯ç´¯
- ä»£ç†æœªå¤„ç†
- ä»»åŠ¡çŠ¶æ€åœç•™åœ¨â€œå¾…å¤„ç†â€

**è¯Šæ–­ï¼š**
```bash
# æ£€æŸ¥é˜Ÿåˆ—æ·±åº¦
az servicebus queue show \
  --namespace-name mybus \
  --name research-tasks \
  --query "countDetails"

# æ£€æŸ¥ä»£ç†å¥åº·çŠ¶å†µ
azd logs research-agent --tail 50
```

**è§£å†³æ–¹æ¡ˆï¼š**

1. **å¢åŠ ä»£ç†å‰¯æœ¬ï¼š**
   ```bash
   az containerapp update \
     --name research-agent \
     --min-replicas 3 \
     --max-replicas 10
   ```

2. **æ£€æŸ¥æ­»ä¿¡é˜Ÿåˆ—ï¼š**
   ```bash
   az servicebus queue show \
     --namespace-name mybus \
     --name research-tasks \
     --query "countDetails.deadLetterMessageCount"
   ```

---

### é—®é¢˜ï¼šä»»åŠ¡è¶…æ—¶/æ— æ³•å®Œæˆ

**ç—‡çŠ¶ï¼š**
- ä»»åŠ¡çŠ¶æ€ä¿æŒä¸ºâ€œè¿›è¡Œä¸­â€
- éƒ¨åˆ†ä»£ç†å®Œæˆï¼Œéƒ¨åˆ†æœªå®Œæˆ
- æ— é”™è¯¯æ¶ˆæ¯

**è¯Šæ–­ï¼š**
```bash
# æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
curl $ORCHESTRATOR_URL/task/$TASK_ID

# æ£€æŸ¥åº”ç”¨ç¨‹åºæ´å¯Ÿ
# è¿è¡ŒæŸ¥è¯¢ï¼štraces | where customDimensions.task_id == "..."
```

**è§£å†³æ–¹æ¡ˆï¼š**

1. **åœ¨èšåˆå™¨ä¸­å®ç°è¶…æ—¶æœºåˆ¶ï¼ˆç»ƒä¹  1ï¼‰**

2. **æ£€æŸ¥ä»£ç†æ•…éšœï¼š**
   ```bash
   azd logs --follow | grep "ERROR\|FAIL"
   ```

3. **éªŒè¯æ‰€æœ‰ä»£ç†æ˜¯å¦æ­£åœ¨è¿è¡Œï¼š**
   ```bash
   az containerapp list \
     --resource-group rg-agents \
     --query "[].{name:name, status:properties.runningStatus}"
   ```

---

## äº†è§£æ›´å¤š

### å®˜æ–¹æ–‡æ¡£
- [Azure Service Bus](https://learn.microsoft.com/azure/service-bus-messaging/service-bus-messaging-overview)
- [Cosmos DB](https://learn.microsoft.com/azure/cosmos-db/introduction)
- [Container Apps DAPR](https://learn.microsoft.com/azure/container-apps/dapr-overview)
- [å¤šä»£ç†è®¾è®¡æ¨¡å¼](https://learn.microsoft.com/azure/architecture/guide/ai/multi-agent-systems)

### æœ¬è¯¾ç¨‹çš„ä¸‹ä¸€æ­¥
- â† ä¸Šä¸€èŠ‚ï¼š[å®¹é‡è§„åˆ’](capacity-planning.md)
- â†’ ä¸‹ä¸€èŠ‚ï¼š[SKU é€‰æ‹©](sku-selection.md)
- ğŸ  [è¯¾ç¨‹ä¸»é¡µ](../../README.md)

### ç›¸å…³ç¤ºä¾‹
- [å¾®æœåŠ¡ç¤ºä¾‹](../../../../examples/microservices) - æœåŠ¡é€šä¿¡æ¨¡å¼
- [Azure OpenAI ç¤ºä¾‹](../../../../examples/azure-openai-chat) - AI é›†æˆ

---

## æ€»ç»“

**æ‚¨å·²å­¦ä¹ ï¼š**
- âœ… äº”ç§åè°ƒæ¨¡å¼ï¼ˆé¡ºåºã€å¹¶è¡Œã€å±‚æ¬¡åŒ–ã€äº‹ä»¶é©±åŠ¨ã€å…±è¯†ï¼‰
- âœ… Azure ä¸Šçš„å¤šä»£ç†æ¶æ„ï¼ˆService Busã€Cosmos DBã€Container Appsï¼‰
- âœ… åˆ†å¸ƒå¼ä»£ç†çš„çŠ¶æ€ç®¡ç†
- âœ… è¶…æ—¶å¤„ç†ã€é‡è¯•å’Œæ–­è·¯å™¨
- âœ… åˆ†å¸ƒå¼ç³»ç»Ÿçš„ç›‘æ§å’Œè°ƒè¯•
- âœ… æˆæœ¬ä¼˜åŒ–ç­–ç•¥

**å…³é”®è¦ç‚¹ï¼š**
1. **é€‰æ‹©åˆé€‚çš„æ¨¡å¼** - é¡ºåºæ¨¡å¼é€‚ç”¨äºæœ‰åºå·¥ä½œæµï¼Œå¹¶è¡Œæ¨¡å¼é€‚ç”¨äºé€Ÿåº¦ï¼Œäº‹ä»¶é©±åŠ¨æ¨¡å¼é€‚ç”¨äºçµæ´»æ€§
2. **è°¨æ…ç®¡ç†çŠ¶æ€** - ä½¿ç”¨ Cosmos DB æˆ–ç±»ä¼¼å·¥å…·è¿›è¡Œå…±äº«çŠ¶æ€ç®¡ç†
3. **ä¼˜é›…å¤„ç†æ•…éšœ** - è¶…æ—¶ã€é‡è¯•ã€æ–­è·¯å™¨ã€æ­»ä¿¡é˜Ÿåˆ—
4. **ç›‘æ§ä¸€åˆ‡** - åˆ†å¸ƒå¼è¿½è¸ªæ˜¯è°ƒè¯•çš„å…³é”®
5. **ä¼˜åŒ–æˆæœ¬** - é›¶æ‰©å±•ã€ä½¿ç”¨æ— æœåŠ¡å™¨æ¶æ„ã€å®æ–½ç¼“å­˜

**ä¸‹ä¸€æ­¥ï¼š**
1. å®Œæˆå®è·µç»ƒä¹ 
2. ä¸ºæ‚¨çš„ä½¿ç”¨åœºæ™¯æ„å»ºä¸€ä¸ªå¤šä»£ç†ç³»ç»Ÿ
3. å­¦ä¹  [SKU é€‰æ‹©](sku-selection.md) ä»¥ä¼˜åŒ–æ€§èƒ½å’Œæˆæœ¬

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**å…è´£å£°æ˜**ï¼š  
æœ¬æ–‡æ¡£ä½¿ç”¨AIç¿»è¯‘æœåŠ¡[Co-op Translator](https://github.com/Azure/co-op-translator)è¿›è¡Œç¿»è¯‘ã€‚å°½ç®¡æˆ‘ä»¬åŠªåŠ›ç¡®ä¿ç¿»è¯‘çš„å‡†ç¡®æ€§ï¼Œä½†è¯·æ³¨æ„ï¼Œè‡ªåŠ¨ç¿»è¯‘å¯èƒ½åŒ…å«é”™è¯¯æˆ–ä¸å‡†ç¡®ä¹‹å¤„ã€‚åŸå§‹è¯­è¨€çš„æ–‡æ¡£åº”è¢«è§†ä¸ºæƒå¨æ¥æºã€‚å¯¹äºé‡è¦ä¿¡æ¯ï¼Œå»ºè®®ä½¿ç”¨ä¸“ä¸šäººå·¥ç¿»è¯‘ã€‚æˆ‘ä»¬å¯¹å› ä½¿ç”¨æ­¤ç¿»è¯‘è€Œäº§ç”Ÿçš„ä»»ä½•è¯¯è§£æˆ–è¯¯è¯»ä¸æ‰¿æ‹…è´£ä»»ã€‚
<!-- CO-OP TRANSLATOR DISCLAIMER END -->